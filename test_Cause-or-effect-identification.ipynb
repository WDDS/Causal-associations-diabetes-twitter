{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "613b53ad",
   "metadata": {},
   "source": [
    "## A model build using TweetBERT to identify cause-effect pairs in sentences of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8cb4d8",
   "metadata": {},
   "source": [
    "The cause-effect pair sentence prediction model will be trained on the dataset which got augmented in an active learning approach in 5 steps.\n",
    "\n",
    "Load already preprocessed file with sentence containing either cause or effect or both. Sentences labeled as Jokes, questions or having negations are removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e908c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from tqdm import tqdm, trange\n",
    "from utils import normalizeTweet, split_into_sentences, bio_tagging, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "%matplotlib inline\n",
    "\n",
    "########################### Check if cuda available ############################\n",
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "########################### DATA FILE ###################################\n",
    "dataPath = \"data/cause_effect_sentences_with_BIO_tags.csv\"\n",
    "#dataPath = \"data/Causality_tweets_data.xlsx\"\n",
    "#dataPath = \"Causality_tweets_data.xlsx\"\n",
    "\n",
    "\n",
    "########################### MODEL PARAMETERS ############################\n",
    "lr = 1e-5 # earlier 1e-3    \n",
    "adam_eps = 1e-8\n",
    "epochs = 55\n",
    "num_warmup_steps = 0\n",
    "early_patience = 10 # earlier 5, how long to wait after last time validation loss improved\n",
    "\n",
    "train_batch_size = 1#8\n",
    "val_batch_size = 8\n",
    "test_batch_size = 8\n",
    "train_to_test_ratio = 0.9 # 10% test and 90% train\n",
    "val_to_train_ratio = 0.2\n",
    "type_ = \"cause-or-effect\"\n",
    "attempt_ = \"test\"\n",
    "\n",
    "\n",
    "# if True, only sentences containing both cause and effect are considered.\n",
    "# if False, all sentences containing either cause or effect are considered\n",
    "requireCauseAndEffect = True \n",
    "\n",
    "# Each token has its associated BIO tag (\"O\", \"B-C\", \"I-C\", \"B-E\", \"I-E\").\n",
    "# The Bertweet tokenizer splits words into sub-words\n",
    "# if True => assign BIO tag of word to all sub-words\n",
    "# if False => assign BIO tag of word to first sub-word and all other sub-words get -100 (loss function ignores this index)\n",
    "subwordTagEqualFirstwordTag = False \n",
    "\n",
    "metric_choice = \"weighted\"\n",
    "# metrics_average = \"binary\" # this will give measure for class_1,i.e., causal class\n",
    "\n",
    "# saveModelName = \"./model-causal-span/cause-and-effect_model_1_finetuned-{}-epochs-lr_{}.pth\".format(epochs, lr) # it should be epoch so that the name shows at what epoch teh mdel ws saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b9de264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2490, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Causal association</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER Additionally the medicines are being char...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medicines are being charged at MRP</td>\n",
       "      <td>costing much higher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, Additionally, the, medicines, are, bein...</td>\n",
       "      <td>[O, O, O, B-C, I-C, I-C, I-C, I-C, I-C, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hear \" I hate being a diabetic \" .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diabetic</td>\n",
       "      <td>hate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[I, hear, \", I, hate, being, a, diabetic, \", .]</td>\n",
       "      <td>[O, O, O, O, B-E, O, O, B-C, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got lime for my glucose test , was n't that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glucose test</td>\n",
       "      <td>nauseous</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, got, lime, for, my, glucose, test, ,, was,...</td>\n",
       "      <td>[O, O, O, O, O, B-C, I-C, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sounds like Willow 's blood sugar level is rea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blood sugar level is real low</td>\n",
       "      <td>reduce her insulin shots</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sounds, like, Willow, 's, blood, sugar, level...</td>\n",
       "      <td>[O, O, O, O, B-C, I-C, I-C, I-C, I-C, I-C, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER I 've always found it too sweet mustvsay ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaded diabetes</td>\n",
       "      <td>sauces are used sparingly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, I, 've, always, found, it, too, sweet, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-E, I-E,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Intent  \\\n",
       "0  USER Additionally the medicines are being char...    NaN   \n",
       "1               I hear \" I hate being a diabetic \" .    NaN   \n",
       "2  i got lime for my glucose test , was n't that ...    NaN   \n",
       "3  Sounds like Willow 's blood sugar level is rea...    NaN   \n",
       "4  USER I 've always found it too sweet mustvsay ...    NaN   \n",
       "\n",
       "                                Cause                     Effect  \\\n",
       "0  medicines are being charged at MRP        costing much higher   \n",
       "1                            diabetic                       hate   \n",
       "2                        glucose test                   nauseous   \n",
       "3       blood sugar level is real low   reduce her insulin shots   \n",
       "4                    dreaded diabetes  sauces are used sparingly   \n",
       "\n",
       "   Causal association                                          tokenized  \\\n",
       "0                 1.0  [USER, Additionally, the, medicines, are, bein...   \n",
       "1                 1.0    [I, hear, \", I, hate, being, a, diabetic, \", .]   \n",
       "2                 1.0  [i, got, lime, for, my, glucose, test, ,, was,...   \n",
       "3                 1.0  [Sounds, like, Willow, 's, blood, sugar, level...   \n",
       "4                 1.0  [USER, I, 've, always, found, it, too, sweet, ...   \n",
       "\n",
       "                                            bio_tags  \n",
       "0  [O, O, O, B-C, I-C, I-C, I-C, I-C, I-C, O, O, ...  \n",
       "1                 [O, O, O, O, B-E, O, O, B-C, O, O]  \n",
       "2  [O, O, O, O, O, B-C, I-C, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, B-C, I-C, I-C, I-C, I-C, I-C, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-E, I-E,...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### DATA TO LOAD ######\n",
    "\n",
    "data = pd.read_csv(dataPath, sep=\";\", converters={\"tokenized\":literal_eval, \"bio_tags\":literal_eval})\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39f416",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "030e6162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Causal association</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER Additionally the medicines are being char...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medicines are being charged at MRP</td>\n",
       "      <td>costing much higher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, Additionally, the, medicines, are, bein...</td>\n",
       "      <td>[O, O, O, B-C, I-C, I-C, I-C, I-C, I-C, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hear \" I hate being a diabetic \" .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diabetic</td>\n",
       "      <td>hate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[I, hear, \", I, hate, being, a, diabetic, \", .]</td>\n",
       "      <td>[O, O, O, O, B-E, O, O, B-C, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got lime for my glucose test , was n't that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glucose test</td>\n",
       "      <td>nauseous</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, got, lime, for, my, glucose, test, ,, was,...</td>\n",
       "      <td>[O, O, O, O, O, B-C, I-C, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sounds like Willow 's blood sugar level is rea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blood sugar level is real low</td>\n",
       "      <td>reduce her insulin shots</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sounds, like, Willow, 's, blood, sugar, level...</td>\n",
       "      <td>[O, O, O, O, B-C, I-C, I-C, I-C, I-C, I-C, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER I 've always found it too sweet mustvsay ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaded diabetes</td>\n",
       "      <td>sauces are used sparingly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, I, 've, always, found, it, too, sweet, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-E, I-E,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Intent  \\\n",
       "0  USER Additionally the medicines are being char...    NaN   \n",
       "1               I hear \" I hate being a diabetic \" .    NaN   \n",
       "2  i got lime for my glucose test , was n't that ...    NaN   \n",
       "3  Sounds like Willow 's blood sugar level is rea...    NaN   \n",
       "4  USER I 've always found it too sweet mustvsay ...    NaN   \n",
       "\n",
       "                                Cause                     Effect  \\\n",
       "0  medicines are being charged at MRP        costing much higher   \n",
       "1                            diabetic                       hate   \n",
       "2                        glucose test                   nauseous   \n",
       "3       blood sugar level is real low   reduce her insulin shots   \n",
       "4                    dreaded diabetes  sauces are used sparingly   \n",
       "\n",
       "   Causal association                                          tokenized  \\\n",
       "0                 1.0  [USER, Additionally, the, medicines, are, bein...   \n",
       "1                 1.0    [I, hear, \", I, hate, being, a, diabetic, \", .]   \n",
       "2                 1.0  [i, got, lime, for, my, glucose, test, ,, was,...   \n",
       "3                 1.0  [Sounds, like, Willow, 's, blood, sugar, level...   \n",
       "4                 1.0  [USER, I, 've, always, found, it, too, sweet, ...   \n",
       "\n",
       "                                            bio_tags  \n",
       "0  [O, O, O, B-C, I-C, I-C, I-C, I-C, I-C, O, O, ...  \n",
       "1                 [O, O, O, O, B-E, O, O, B-C, O, O]  \n",
       "2  [O, O, O, O, O, B-C, I-C, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, B-C, I-C, I-C, I-C, I-C, I-C, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-E, I-E,...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Choose only sentences with both cause and effect or only sentences with either cause or effect (or both) #######\n",
    "\n",
    "\n",
    "if requireCauseAndEffect: # cause and effect in sentence\n",
    "    dataSentFiltered = data[(data[\"Cause\"].notnull()) & (data[\"Effect\"].notnull())]\n",
    "else: # cause or effect or both in sentence\n",
    "    dataSentFiltered = data[(data[\"Cause\"].notnull()) | (data[\"Effect\"].notnull())]\n",
    "\n",
    "print(dataSentFiltered.shape)\n",
    "dataSentFiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2046890c-1b7d-469d-a202-4cd77fc524d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([136., 493., 671., 402., 179., 115.,  79.,  30.,   9.,   1.]),\n",
       " array([ 3. , 10.2, 17.4, 24.6, 31.8, 39. , 46.2, 53.4, 60.6, 67.8, 75. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## Distribution of sentences length ########################\n",
    "\n",
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in dataSentFiltered[\"sentence\"]]\n",
    "plt.hist(seq_len)\n",
    "#pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ea773",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31d3e1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (72, 7)\n",
      "Validate: (18, 7)\n",
      "Test: (10, 7)\n"
     ]
    }
   ],
   "source": [
    "trainingDataSample = dataSentFiltered#.sample(n=100)   # Only for testing\n",
    "train = trainingDataSample.sample(frac=train_to_test_ratio, random_state=0)\n",
    "test = trainingDataSample.drop(train.index)\n",
    "validate = train.sample(frac=val_to_train_ratio, random_state=0)\n",
    "train = train.drop(validate.index)\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Validate:\", validate.shape)\n",
    "print(\"Test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9547ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:20: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<ipython-input-67-6457e0ab2ca7>:20: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(ids[idx]) == len(bio_tags_extended), \"token ids and BIO tags lengths do not match!\")\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "18\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "######### BERTWEET TOKENIZER + PYTORCH DATASET/DATALOADER STRUCTURE ##################\n",
    "\n",
    "class TweetDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, labels, bio_tags, tokenizer):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bio_tags = bio_tags\n",
    "        self.tag2id = {label: idx for idx, label in enumerate([\"O\", \"B-C\", \"I-C\", \"B-E\", \"I-E\"])}\n",
    "        self.tag2id[-100] = -100\n",
    "        self.id2tag = {id:tag for tag,id in self.tag2id.items()}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.text, padding=True, truncation=True, return_token_type_ids=True)\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        bio_tags_extended = self.extend_tags(self.text[idx], self.bio_tags[idx], ids[idx])\n",
    "        \n",
    "        assert(len(ids[idx]) == len(bio_tags_extended), \"token ids and BIO tags lengths do not match!\")\n",
    "        return {\n",
    "                \"input_ids\" : torch.tensor(ids[idx], dtype=torch.long)\n",
    "              , \"attention_mask\" : torch.tensor(mask[idx], dtype=torch.long)\n",
    "              , \"token_type_ids\" : torch.tensor(token_type_ids[idx], dtype=torch.long)\n",
    "              , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "              , \"bio_tags\" : torch.tensor(list(map(lambda bioTags: self.tag2id[bioTags], bio_tags_extended))\n",
    ", dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    def extend_tags(self, tokens_old, tags_old, ids_tokenized_padded):\n",
    "        \"\"\" \n",
    "            Each token has a BIO tag label. \n",
    "            However BERT's tokenization splits tokens into subwords. How to label those subwords?\n",
    "            \n",
    "            Option 1:\n",
    "            ---------\n",
    "            \n",
    "            add the same label to each subword than the first subword. Only replace \"B\" by \"I\"\n",
    "            Ex. \n",
    "            #lowbloodsugar => '#low@@', 'blood@@', 'sugar@@'\n",
    "               \"B-C\"       =>   \"B-C\" ,   \"I-C\"  ,   \"I-C\"\n",
    "            \n",
    "            Option 2:      \n",
    "            ---------\n",
    "            \n",
    "            From : https://huggingface.co/transformers/custom_datasets.html#token-classification-with-w-nut-emerging-entities\n",
    "            A common obstacle with using pre-trained models for token-level classification: many of the tokens in\n",
    "            the W-NUT corpus are not in DistilBertâ€™s vocabulary. Bert and many models like it use a method called \n",
    "            WordPiece Tokenization, meaning that single words are split into multiple tokens such that each token\n",
    "            is likely to be in the vocabulary. For example, DistilBertâ€™s tokenizer would split the Twitter \n",
    "            handle @huggingface into the tokens ['@', 'hugging', '##face']. This is a problem for us because we \n",
    "            have exactly one tag per token. If the tokenizer splits a token into multiple sub-tokens, then we will\n",
    "            end up with a mismatch between our tokens and our labels.\n",
    "\n",
    "            One way to handle this is to only train on the tag labels for the first subtoken of a split token. \n",
    "            We can do this in ðŸ¤— Transformers by setting the labels we wish to ignore to -100. \n",
    "            In the example above, if the label for @HuggingFace is 3 (indexing B-corporation), we would set \n",
    "            the labels of ['@', 'hugging', '##face'] to [3, -100, -100].\n",
    "        \"\"\"\n",
    "        tags = [-100] # add for start token <CLS>\n",
    "        for token_old, tag in zip(tokens_old.split(\" \"), tags_old):\n",
    "            #print(F\"\\ntoken_old: {token_old};    tag: {tag}\")\n",
    "            for i, sub_token in enumerate(self.tokenizer.tokenize(token_old)):\n",
    "                if (i == 0): # first sub token of a word keeps the original bio tag\n",
    "                    firstTag = tag\n",
    "                    tags.append(tag)\n",
    "                    #print(F\"\\tsubToken: {sub_token};    tag: {tag}\")\n",
    "                else: \n",
    "                    if subwordTagEqualFirstwordTag: # the other sub tokens get the first bio tag than the first sub token\n",
    "                        tags.append(firstTag)\n",
    "                        #print(F\"\\tsubToken: {sub_token};    tag: {firstTag}\")\n",
    "                    else: # to other sub tokens get the tag -100 (ignored in loss function)\n",
    "                        tags.append(-100)\n",
    "                        #print(F\"\\tsubToken: {sub_token};    tag: {-100}\")\n",
    "\n",
    "        tags.append(-100) # 0 for end of sentence token\n",
    "    \n",
    "        # append -100 for all padded elements\n",
    "        padded_elements = ids_tokenized_padded.count(1) # id 1 is <PAD> ; Alternative: where attention_mask == 0 add -100\n",
    "        tags.extend([-100]*padded_elements)\n",
    "        \n",
    "        return tags\n",
    "        \n",
    "        \n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", padding = \"max_length\", truncation = True, max_length = 60 )\n",
    "\n",
    "train_dataset = TweetDataSet(train[\"sentence\"].values.tolist()\n",
    "                           , train[\"Causal association\"].values.tolist()\n",
    "                           , train[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "val_dataset = TweetDataSet(validate[\"sentence\"].values.tolist()\n",
    "                           , validate[\"Causal association\"].values.tolist()\n",
    "                           , validate[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "test_dataset = TweetDataSet(test[\"sentence\"].values.tolist()\n",
    "                           , test[\"Causal association\"].values.tolist()\n",
    "                           , test[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "# put data to batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f3991a4-cbc3-4cfb-af45-60f38435853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_bio_tags: [1 0 0 ... 1 2 0]\n",
      "train_bio_tags_count_info: 0    0.824387\n",
      "4    0.048425\n",
      "3    0.046091\n",
      "1    0.044924\n",
      "2    0.036173\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.242604\n",
       "1    4.451948\n",
       "2    5.529032\n",
       "3    4.339241\n",
       "4    4.130120\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ class weights #####################\n",
    "\n",
    "# Since -100 will anyway be ignored by loss func, drop it\n",
    "train_bio_tags = np.hstack([t[\"bio_tags\"][t[\"bio_tags\"]!=-100].numpy() for t in train_dataset])\n",
    "print(\"train_bio_tags:\", train_bio_tags)\n",
    "\n",
    "train_bio_tags_count_info = (pd.Series(train_bio_tags).value_counts(normalize=True))\n",
    "print(\"train_bio_tags_count_info:\", train_bio_tags_count_info)\n",
    "\n",
    "# for class-imbalanced dataset, the class weight for a ith class\n",
    "# to be specified for balancing in the loss function is given by:\n",
    "# weight[i] = num_samples / (num_classes * num_samples[i])\n",
    "# since train_bio_tags_count_info obtained above has fraction of \n",
    "# samples for ith class, hence the corresponding weight calculation is:\n",
    "class_weight = (1/train_bio_tags_count_info)/len(train_bio_tags_count_info)\n",
    "class_weight = class_weight[sorted(class_weight.index)]\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01947bbb",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76fc4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, labels):\n",
    "    \"\"\"\n",
    "        Dataset is unbalanced -> measure weighted metrics\n",
    "        Calculate metrics for each label, and find their average wieghted by support (Number of true instances for each label)\n",
    "        This alters 'macro' to account for label imbalance;\n",
    "        it can result in an F-Score taht is not between precision and recall\n",
    "    \"\"\"\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average= metric_choice) # TODO: check weightin\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3ffc4",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dadc9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalNER(torch.nn.Module):\n",
    "    \"\"\" Model Bert\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CausalNER, self).__init__()\n",
    "        self.num_labels = 5 # B-C, I-C, B-E, I-E, O\n",
    "        self.bert = transformers.BertModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear1 = torch.nn.Linear(768, 256)\n",
    "        self.linear2 = torch.nn.Linear(256, self.num_labels)\n",
    "        self.softmax = torch.nn.Softmax(-1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "#        _, output_1 = self.bert(input_ids, attention_mask = attention_mask, token_type_ids=token_type_ids, return_dict=False) # if output 1 is our cls token\n",
    "        output_seq, _ = self.bert(input_ids, attention_mask = attention_mask, token_type_ids=token_type_ids, return_dict=False) # if output 1 is our cls token\n",
    "        output_2 = self.dropout(output_seq)\n",
    "        output_3 = self.linear1(output_2)\n",
    "        output_4 = self.dropout(output_3)\n",
    "        output_5 = self.linear2(output_4)\n",
    "        return output_5 # 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06931619",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing BertModel: ['roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'lm_head.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['encoder.layer.11.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'pooler.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CausalNER()\n",
    "model.to(device)\n",
    "\n",
    "# fine-tune only the task-specific parameters \n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "#     param[:-1].requires_grad = False\n",
    "#     param[-1].requires_grad = True\n",
    "\n",
    "num_training_steps = np.ceil(len(train_dataset)/train_batch_size)*epochs\n",
    "optim = AdamW(model.parameters(), lr=lr, eps=adam_eps)\n",
    "# scheduler with a linearly decreasing learning rate from the initial lr set in the optimizer to 0;\n",
    "# after a warmup period during which it increases linearly from to the initial lr set in the optimizer\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps) \n",
    "\n",
    "\n",
    "## adding weight to the loss function \n",
    "loss_fn = CrossEntropyLoss(\n",
    "    weight=torch.tensor(class_weight.to_list()).to(device),\n",
    "    ignore_index=-100 # ignore subwords/tokens with label -100 \n",
    ")\n",
    "\n",
    "#loss_fn = CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed958bdd-cefa-49f7-8a37-4ec6523b0b92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/55 [00:00<?, ?it/s]\n",
      "  0%|          | 0/72 [00:00<?, ?it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n",
      "loss: tensor(1.5530, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  1%|â–         | 1/72 [00:01<02:10,  1.84s/it]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  3%|â–Ž         | 2/72 [00:01<00:59,  1.18it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  4%|â–         | 3/72 [00:02<00:36,  1.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.3641, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7836, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  6%|â–Œ         | 4/72 [00:02<00:25,  2.63it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9993, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.8496, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  7%|â–‹         | 5/72 [00:02<00:21,  3.19it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  8%|â–Š         | 6/72 [00:02<00:17,  3.73it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 10%|â–‰         | 7/72 [00:02<00:14,  4.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7087, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.8896, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 11%|â–ˆ         | 8/72 [00:02<00:13,  4.76it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 12%|â–ˆâ–Ž        | 9/72 [00:03<00:12,  4.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.5336, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.5799, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 14%|â–ˆâ–        | 10/72 [00:03<00:11,  5.37it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 15%|â–ˆâ–Œ        | 11/72 [00:03<00:11,  5.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.5522, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.5586, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 17%|â–ˆâ–‹        | 12/72 [00:03<00:10,  5.47it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 18%|â–ˆâ–Š        | 13/72 [00:03<00:10,  5.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7708, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.6781, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 19%|â–ˆâ–‰        | 14/72 [00:03<00:09,  6.06it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 21%|â–ˆâ–ˆ        | 15/72 [00:04<00:09,  6.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8103, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.9724, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–       | 16/72 [00:04<00:08,  6.33it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–Ž       | 17/72 [00:04<00:09,  6.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6982, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7119, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 18/72 [00:04<00:09,  5.71it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–‹       | 19/72 [00:04<00:08,  6.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6832, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.9840, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 28%|â–ˆâ–ˆâ–Š       | 20/72 [00:04<00:08,  6.22it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–‰       | 21/72 [00:05<00:07,  6.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6049, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7730, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 22/72 [00:05<00:07,  6.30it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 23/72 [00:05<00:07,  6.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7604, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.3097, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24/72 [00:05<00:07,  6.19it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 25/72 [00:05<00:07,  6.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9506, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.4419, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/72 [00:05<00:07,  6.56it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 27/72 [00:06<00:06,  6.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7412, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.6906, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 28/72 [00:06<00:06,  6.68it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 29/72 [00:06<00:06,  6.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7374, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7069, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/72 [00:06<00:06,  6.75it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 31/72 [00:06<00:06,  6.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6138, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.6132, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/72 [00:06<00:06,  6.60it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9412, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/72 [00:06<00:06,  5.98it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7826, grad_fn=<NllLossBackward>)\n",
      "loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/72 [00:07<00:06,  5.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5642, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/72 [00:07<00:06,  5.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7005, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 36/72 [00:07<00:07,  4.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7266, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/72 [00:07<00:07,  4.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8347, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 38/72 [00:08<00:07,  4.59it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/72 [00:08<00:06,  5.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6549, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7319, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 40/72 [00:08<00:06,  5.31it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 41/72 [00:08<00:05,  5.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6369, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7353, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/72 [00:08<00:05,  5.58it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/72 [00:08<00:04,  5.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8155, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.4727, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/72 [00:09<00:04,  6.12it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 45/72 [00:09<00:04,  6.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7731, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.8291, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/72 [00:09<00:04,  6.17it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 47/72 [00:09<00:03,  6.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7337, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.5246, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 48/72 [00:09<00:03,  6.25it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 49/72 [00:09<00:03,  5.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.4749, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.6207, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 50/72 [00:10<00:03,  6.09it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 51/72 [00:10<00:03,  6.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.4472, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.5650, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 52/72 [00:10<00:03,  6.17it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 53/72 [00:10<00:02,  6.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7185, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.4592, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 54/72 [00:10<00:02,  6.30it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 55/72 [00:10<00:02,  6.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6691, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.8170, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 56/72 [00:10<00:02,  6.33it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 57/72 [00:11<00:02,  6.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.5819, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7804, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 58/72 [00:11<00:02,  6.26it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 59/72 [00:11<00:02,  6.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8188, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7117, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 60/72 [00:11<00:01,  6.48it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/72 [00:11<00:01,  6.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7918, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.1854, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 62/72 [00:11<00:01,  6.26it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 63/72 [00:12<00:01,  6.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7994, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.6851, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 64/72 [00:12<00:01,  6.13it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 65/72 [00:12<00:01,  6.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6950, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.7493, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 66/72 [00:12<00:00,  6.27it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8903, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.5127, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 67/72 [00:12<00:00,  5.80it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/72 [00:12<00:00,  5.55it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 69/72 [00:13<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6441, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.5181, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 70/72 [00:13<00:00,  5.32it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 71/72 [00:13<00:00,  5.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7688, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.8841, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:13<00:00,  5.27it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8263, grad_fn=<NllLossBackward>)\n",
      "\n",
      "\tTraining Loss: 1.6902376148435805\n",
      "\n",
      "\tTraining acc: 0.1876921912142402\n",
      "\n",
      "\tTraining prec: 0.18778003360111203\n",
      "\n",
      "\tTraining rec: 0.16951613795970838\n",
      "\n",
      "\tTraining f1: 0.1081031924781348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.94it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.95it/s]\u001b[A<ipython-input-67-6457e0ab2ca7>:25: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.47it/s]\u001b[A\n",
      "Epoch:   0%|          | 0/55 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Loss: 1.6109243631362915\n",
      "\n",
      "\tValidation acc: 0.20231455461147663\n",
      "\n",
      "\tValidation prec: 0.24528736127882236\n",
      "\n",
      "\tValidation rec: 0.2377974727974728\n",
      "\n",
      "\tValidation f1: 0.13656712389921524\n",
      "Validation loss decreased (inf --> 1.610924).  Saving model ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model-causal-span/cause-or-effect_model_test_finetuned--9-epochs-lr_1e-05.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-ba6f14b15144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0msaveModelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./model-causal-span/{}_model_{}_finetuned-{}-epochs-lr_{}.pth\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trained_epochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mearly_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mearly_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveModelName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mearly_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/causality/Causal-associations-diabetes-twitter/utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, val_loss, model)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/causality/Causal-associations-diabetes-twitter/utils.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, val_loss, model)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model-causal-span/cause-or-effect_model_test_finetuned--9-epochs-lr_1e-05.pth'"
     ]
    }
   ],
   "source": [
    "################ TRAINING ######################\n",
    "\n",
    "# initialise the early_stopping object\n",
    "early_stopping = EarlyStopping(patience=early_patience, verbose=True)\n",
    "\n",
    "train_avg_loss = [] # avg training loss per epoch\n",
    "val_avg_loss = [] # avg validation loss per epoch\n",
    "train_avg_acc = [] # avg training accuracy per epoch\n",
    "val_avg_acc = [] # avg val accuracy per epoch\n",
    "n_trained_epochs = 0\n",
    "\n",
    "N_bio_tags = 5 # \"O\", \"B-C\", \"I-C\", \"B-E\", \"I-C\"\n",
    "for epoch in trange(1, epochs+1, desc='Epoch'):\n",
    "    print(\"<\" + \"=\"*22 + F\" Epoch {epoch} \"+ \"=\"*22 + \">\")\n",
    "\n",
    "    \n",
    "    ############ training eval metrics ######################\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    train_prec = []\n",
    "    train_rec = []\n",
    "    train_f1 = []\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad() # gradients get accumulated by default -> clear previous accumulated gradients\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        bio_tags = batch['bio_tags'].to(device)\n",
    "        \n",
    "        ################################################\n",
    "        model.train() # set model to training mode\n",
    "        logits = model(**{\"input_ids\":input_ids, \"attention_mask\":attention_mask, \"token_type_ids\":token_type_ids}) # forward pass\n",
    "\n",
    "        ################################################ \n",
    "        # similar to the class RobertaForToken classification in transformers: https://github.com/huggingface/transformers/blob/master/src/transformers/models/roberta/modeling_roberta.py\n",
    "        active_loss = attention_mask.view(-1) == 1  # either based on attention_mask (includes <CLS>, <SEP> token)\n",
    "        active_logits = logits.view(-1, N_bio_tags)[active_loss] # N_bio_tags=5 \n",
    "        active_tags = bio_tags.view(-1)[active_loss]\n",
    "        loss = loss_fn(active_logits, active_tags)             \n",
    "        print(\"loss:\", loss)       ## TODO VIVEK: check loss function calculation\n",
    "        loss.backward() # backward pass\n",
    "        ## gradient clipping to control the exploding gradient problem \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optim.step()    # update parameters and take a steup using the computed gradient\n",
    "        scheduler.step()# update learning rate scheduler\n",
    "        train_loss.append(loss.item())\n",
    "            \n",
    "            \n",
    "        ################## Training Performance Measures ##########\n",
    "        logits = logits.detach().to('cpu').numpy()\n",
    "        tags_ids = bio_tags.to('cpu').numpy()\n",
    "\n",
    "        # calculate performance measures only on tokens and not subwords or special tokens\n",
    "        tags_mask = tags_ids != -100 # only get token labels and not labels from subwords or special tokens\n",
    "        pred = np.argmax(logits, axis=2)[tags_mask] #.flatten() # convert logits to list of predicted labels\n",
    "        tags = tags_ids[tags_mask]                      \n",
    "                \n",
    "        metrics = compute_metrics(pred, tags)\n",
    "        train_acc.append(metrics[\"accuracy\"])\n",
    "        train_prec.append(metrics[\"precision\"])\n",
    "        train_rec.append(metrics[\"recall\"])\n",
    "        train_f1.append(metrics[\"f1\"])\n",
    "                          \n",
    "    train_avg_loss.append(np.mean(train_loss))\n",
    "    train_avg_acc.append(np.mean(train_acc))           \n",
    "    print(F'\\n\\tTraining Loss: {np.mean(train_loss)}')\n",
    "    print(F'\\n\\tTraining acc: {np.mean(train_acc)}')\n",
    "    print(F'\\n\\tTraining prec: {np.mean(train_prec)}')\n",
    "    print(F'\\n\\tTraining rec: {np.mean(train_rec)}')\n",
    "    print(F'\\n\\tTraining f1: {np.mean(train_f1)}')\n",
    "\n",
    "    n_trained_epochs += 1\n",
    "\n",
    "                          \n",
    "    ###################################################################################\n",
    "\n",
    "    \n",
    "    ## ---- Validation ------    \n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    val_prec = []\n",
    "    val_rec = []\n",
    "    val_f1 = []\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in tqdm(validation_loader):\n",
    "        batch = tuple(batch[t].to(device) for t in batch)      # batch to GPU\n",
    "        v_input_ids, v_input_mask, v_token_type_ids, v_labels, v_bio_tags = batch  # unpack inputs from dataloader\n",
    "        \n",
    "        with torch.no_grad(): # tell model not to compute or store gradients -> saves memory + speeds up validation\n",
    "            model.eval() # put model in evaluation mode for validation set\n",
    "            logits = model(**{\"input_ids\":v_input_ids, \"attention_mask\":v_input_mask, \"token_type_ids\":v_token_type_ids}) # forward pass, calculates logit predictions\n",
    "\n",
    "        ######################################################\n",
    "        \n",
    "        # similar to the class RobertaForToken classification in transformers: https://github.com/huggingface/transformers/blob/master/src/transformers/models/roberta/modeling_roberta.py\n",
    "        v_active_loss = v_input_mask.view(-1) == 1  # either based on attention_mask (includes <CLS>, <SEP> token)\n",
    "        v_active_logits = logits.view(-1, N_bio_tags)[v_active_loss] # 5 \n",
    "        v_active_tags = v_bio_tags.view(-1)[v_active_loss]\n",
    "        v_loss = loss_fn(v_active_logits, v_active_tags)             \n",
    "        val_loss.append(v_loss.item())\n",
    "              \n",
    "        #########################################################\n",
    "        logits = logits.detach().to('cpu').numpy()\n",
    "        tags_ids = v_bio_tags.to('cpu').numpy()\n",
    "\n",
    "        # calculate performance measures only on tokens and not subwords or special tokens\n",
    "        tags_mask = tags_ids != -100 # only get token labels and not labels from subwords or special tokens\n",
    "        pred = np.argmax(logits, axis=2)[tags_mask] #.flatten() # convert logits to list of predicted labels\n",
    "        tags = tags_ids[tags_mask]#.flatten()        \n",
    "        \n",
    "        metrics = compute_metrics(pred, tags)\n",
    "        val_acc.append(metrics[\"accuracy\"])\n",
    "        val_prec.append(metrics[\"precision\"])\n",
    "        val_rec.append(metrics[\"recall\"])\n",
    "        val_f1.append(metrics[\"f1\"])\n",
    "                              \n",
    "    val_avg_loss.append(np.mean(val_loss))\n",
    "    val_avg_acc.append(np.mean(val_acc))        \n",
    "    print(F'\\n\\tValidation Loss: {np.mean(val_loss)}')\n",
    "    print(F'\\n\\tValidation acc: {np.mean(val_acc)}')\n",
    "    print(F'\\n\\tValidation prec: {np.mean(val_prec)}')\n",
    "    print(F'\\n\\tValidation rec: {np.mean(val_rec)}')\n",
    "    print(F'\\n\\tValidation f1: {np.mean(val_f1)}')\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decreased,\n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    saveModelName = \"./model-causal-span/{}_model_{}_finetuned-{}-epochs-lr_{}.pth\".format(type_, attempt_, n_trained_epochs-early_patience, lr) \n",
    "    early_stopping.path = saveModelName\n",
    "    early_stopping(np.average(val_loss), model)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6c981af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "[0.9860931566331239, 0.7748585237865955, 0.7627220232929803, 0.7514180171806201, 0.7388605401579258, 0.7344493966186996, 0.7289819751693084, 0.728067301543413, 0.7205865027102749, 0.7147404287768676, 0.7108584120210293, 0.7081724260233145, 0.7082123308055168, 0.7040135311869393, 0.7003486641740377, 0.7012603889524409, 0.6979538953937261, 0.6969578147461984, 0.6933906199657811, 0.6937635962942005, 0.6902595497338118, 0.6909854955377832, 0.6913510439670192, 0.6915490236957517, 0.6881245401053302, 0.690502608244398, 0.6894153578091512, 0.6871375697376454, 0.6837012461856403, 0.6864190502504331, 0.6846767793186997, 0.6856337411213765, 0.6831474789475973, 0.6858171074263817, 0.6808900870053114, 0.6839531501837536, 0.6812291928624685, 0.6816793345244585, 0.6822962056746525, 0.6838202360457024, 0.6767028601823655, 0.6785629713429814, 0.6762848179952233, 0.6803720804442347, 0.6766749541316412, 0.6782342657051256, 0.6778008104425616, 0.6783298370057502, 0.6784081327176728, 0.6790280758807089, 0.673988236262735, 0.675842805773811]\n",
      "[0.7962200767115543, 0.7742176672868561, 0.7641009505380664, 0.7575223874627498, 0.7415830607999835, 0.7371104694249337, 0.7126765920404803, 0.727908973631106, 0.7128904493231523, 0.7090832873394615, 0.7135610752984097, 0.7070705571718383, 0.7024267922367966, 0.6972871495966326, 0.7003283913721118, 0.707442476561195, 0.6923846863863761, 0.6952599553685439, 0.6813055329155504, 0.6793533955749712, 0.6809980304617631, 0.6801805679212537, 0.6910117310390138, 0.6808200536067026, 0.6794170041879019, 0.6831958440312168, 0.677386633659664, 0.6708834317692539, 0.6701730840038835, 0.6723708954819462, 0.671809467830156, 0.6791185004669323, 0.667177101499156, 0.6715885630825109, 0.671106906836493, 0.668324528556121, 0.667960060270209, 0.6635946950368714, 0.6765330752782654, 0.6634055898900617, 0.6681917158135197, 0.6588015368110255, 0.6662936404085996, 0.6712314873410944, 0.6690088897420648, 0.6687921520910765, 0.666617985357318, 0.6689068319504721, 0.6609949511394166, 0.6626387991403279, 0.6642958249962121, 0.6640718427666447]\n"
     ]
    }
   ],
   "source": [
    "print(n_trained_epochs)\n",
    "print(train_avg_loss)\n",
    "print(val_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc7e6305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, n_trained_epochs+1), train_avg_loss, label=\"train loss\")\n",
    "plt.plot(range(1, n_trained_epochs+1), val_avg_loss, label=\"val loss\")\n",
    "plt.title(\"Training Curve (lr={})\".format(lr))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d70f7715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, n_trained_epochs+1), train_avg_acc, label=\"train acc\")\n",
    "plt.plot(range(1, n_trained_epochs+1), val_avg_acc, label=\"val acc\")\n",
    "plt.title(\"Training Curve (lr={})\".format(lr))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Train/val Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99266dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### save model ###########\n",
    "# torch.save(model.state_dict(), \"finetuned-35-epochs-1e3-lr-with-weighted-loss.pth\") # early stopping saves model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e74dcb",
   "metadata": {},
   "source": [
    "### Evaluation on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec61fa60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  3%|â–Ž         | 1/32 [00:00<00:04,  6.98it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  6%|â–‹         | 2/32 [00:00<00:04,  7.31it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  9%|â–‰         | 3/32 [00:00<00:03,  7.49it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 12%|â–ˆâ–Ž        | 4/32 [00:00<00:03,  7.56it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 16%|â–ˆâ–Œ        | 5/32 [00:00<00:03,  7.62it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 19%|â–ˆâ–‰        | 6/32 [00:00<00:03,  7.59it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 22%|â–ˆâ–ˆâ–       | 7/32 [00:00<00:03,  7.63it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 8/32 [00:01<00:03,  7.63it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 28%|â–ˆâ–ˆâ–Š       | 9/32 [00:01<00:03,  7.61it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [00:01<00:02,  7.60it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [00:01<00:02,  7.58it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [00:01<00:02,  7.59it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [00:01<00:02,  7.58it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [00:01<00:02,  7.59it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [00:01<00:02,  7.60it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [00:02<00:02,  7.62it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [00:02<00:01,  7.59it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [00:02<00:01,  7.57it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [00:02<00:02,  5.42it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [00:02<00:02,  5.91it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [00:02<00:01,  6.32it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [00:03<00:01,  6.65it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [00:03<00:01,  6.82it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [00:03<00:01,  6.99it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [00:03<00:00,  7.13it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [00:03<00:00,  7.22it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [00:03<00:00,  7.19it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [00:03<00:00,  7.20it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [00:04<00:00,  7.23it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [00:04<00:00,  7.23it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [00:04<00:00,  7.28it/s]<ipython-input-46-7efa34a63f7d>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:04<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTest Loss: 0.664925342425704\n",
      "\n",
      "\tTest acc: 0.8092617529719808\n",
      "\n",
      "\tTest prec: 0.3019195068197559\n",
      "\n",
      "\tTest rec: 0.2601959079997759\n",
      "\n",
      "\tTest f1: 0.2594905194955265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############ test eval metrics ######################\n",
    "test_true_labels = []\n",
    "test_predict_labels = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "test_prec = []\n",
    "test_rec = []\n",
    "test_f1 = []\n",
    "\n",
    "########################################################\n",
    "for batch in tqdm(test_loader):\n",
    "    batch = tuple(batch[t].to(device) for t in batch)      # batch to GPU\n",
    "    t_input_ids, t_input_mask, t_token_type_ids, t_labels, t_bio_tags = batch     # unpack inputs from dataloader\n",
    "\n",
    "    with torch.no_grad(): # tell model not to compute or store gradients -> saves memory + speeds up validation\n",
    "        model.eval() # put model in evaluation mode for validation set\n",
    "        logits = model(**{\"input_ids\":t_input_ids, \"attention_mask\":t_input_mask, \"token_type_ids\":t_token_type_ids}) # forward pass, calculates logit predictions\n",
    "\n",
    "    ######################################################\n",
    "\n",
    "    # similar to the class RobertaForToken classification in transformers: https://github.com/huggingface/transformers/blob/master/src/transformers/models/roberta/modeling_roberta.py\n",
    "    t_active_loss = t_input_mask.view(-1) == 1  # either based on attention_mask (includes <CLS>, <SEP> token)\n",
    "    t_active_logits = logits.view(-1, N_bio_tags)[t_active_loss] # 5 \n",
    "    t_active_tags = t_bio_tags.view(-1)[t_active_loss]\n",
    "    t_loss = loss_fn(t_active_logits, t_active_tags)             \n",
    "    test_loss.append(t_loss.item())\n",
    "\n",
    "    #########################################################\n",
    "    logits = logits.detach().to('cpu').numpy()\n",
    "    tags_ids = t_bio_tags.to('cpu').numpy()\n",
    "\n",
    "    # calculate performance measures only on tokens and not subwords or special tokens\n",
    "    tags_mask = tags_ids != -100 # only get token labels and not labels from subwords or special tokens\n",
    "    pred = np.argmax(logits, axis=2)[tags_mask] #.flatten() # convert logits to list of predicted labels\n",
    "    tags = tags_ids[tags_mask]#.flatten()                          \n",
    "    test_true_labels.append(tags) # appends true labels for batch\n",
    "    test_predict_labels.append(pred) # # appends predicted labels for batch\n",
    "    \n",
    "    metrics = compute_metrics(pred, tags)\n",
    "    test_acc.append(metrics[\"accuracy\"])\n",
    "    test_prec.append(metrics[\"precision\"])\n",
    "    test_rec.append(metrics[\"recall\"])\n",
    "    test_f1.append(metrics[\"f1\"])\n",
    "\n",
    "\n",
    "print(F'\\n\\tTest Loss: {np.mean(test_loss)}')\n",
    "print(F'\\n\\tTest acc: {np.mean(test_acc)}')\n",
    "print(F'\\n\\tTest prec: {np.mean(test_prec)}')\n",
    "print(F'\\n\\tTest rec: {np.mean(test_rec)}')\n",
    "print(F'\\n\\tTest f1: {np.mean(test_f1)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee0ddc",
   "metadata": {},
   "source": [
    "### Classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8be8db7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_true_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7b8767d87c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtag2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mid2tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_true_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_true_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_predict_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predict_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_true_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predict_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_true_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "tag2id = {label: idx for idx, label in enumerate([\"O\", \"B-C\", \"I-C\", \"B-E\", \"I-E\"])}\n",
    "tag2id[-100] = -100\n",
    "id2tag = {id:tag for tag,id in tag2id.items()}\n",
    "test_true_tag = [id2tag[ID] for ID in np.concatenate(test_true_labels)]#\n",
    "test_predict_tag = [id2tag[ID] for ID in np.concatenate(test_predict_labels)]\n",
    "print(classification_report(test_true_tag, test_predict_tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7093126e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/miniconda3/envs/clue/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.47      0.25      0.33       265\n",
      "           E       0.00      0.00      0.00       266\n",
      "\n",
      "   micro avg       0.47      0.12      0.20       531\n",
      "   macro avg       0.24      0.12      0.16       531\n",
      "weighted avg       0.24      0.12      0.16       531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report as classification_report_seqeval\n",
    "\n",
    "#The metrics we are seeing in this report are designed specifically for NLP tasks such as NER and POS tagging,\n",
    "#in which all words of an entity need to be predicted correctly to be counted as one correct prediction. \n",
    "#Therefore, the metrics in this classification report are much lower than in scikit-learn's classification report.\n",
    "test_true_tag = [[id2tag[ID] for ID in IDS] for IDS in test_true_labels]\n",
    "test_predict_tag = [[id2tag[ID] for ID in IDS] for IDS in test_predict_labels]\n",
    "print(classification_report_seqeval(test_true_tag, test_predict_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695f7fdf",
   "metadata": {},
   "source": [
    "### bio tags back to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc0f4d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Padded Sentence:\n",
      "['<s>', 'i', 'have', 'my', 'gluc@@', 'ose', 'test', 'next', 'month', 'and', 'i', \"'m\", ':sparkles:', 'terrified', ':sparkles:', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "true labels:\n",
      "tensor([-100,    0,    0,    0,    1, -100,    2,    0,    0,    0,    0,    0,\n",
      "           0,    3,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100], device='cuda:1')\n",
      "i \t\ttrue: 0   pred: 0\n",
      "have \t\ttrue: 0   pred: 0\n",
      "my \t\ttrue: 0   pred: 0\n",
      "gluc@@ \t\ttrue: 1   pred: 0\n",
      "test \t\ttrue: 2   pred: 0\n",
      "next \t\ttrue: 0   pred: 0\n",
      "month \t\ttrue: 0   pred: 0\n",
      "and \t\ttrue: 0   pred: 0\n",
      "i \t\ttrue: 0   pred: 0\n",
      "'m \t\ttrue: 0   pred: 0\n",
      ":sparkles: \t\ttrue: 0   pred: 0\n",
      "terrified \t\ttrue: 3   pred: 0\n",
      ":sparkles: \t\ttrue: 0   pred: 0\n"
     ]
    }
   ],
   "source": [
    "# take last batch of test set:\n",
    "t_input_ids, t_input_mask, t_token_type_ids, t_labels, t_bio_tags = batch \n",
    "\n",
    "for i in range(len(batch)):\n",
    "    tags_mask = t_bio_tags[i].to(\"cpu\").numpy() != -100 # only get token labels and not labels from subwords or special tokens\n",
    "    pred = np.argmax(logits[i], axis=1)[tags_mask]\n",
    "    true_tags = t_bio_tags[i][tags_mask].to(\"cpu\").numpy()    \n",
    "    \n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(t_input_ids[i])\n",
    "\n",
    "    print(\"\\n\\nPadded Sentence:\")\n",
    "    print(tokens)\n",
    "    print(\"true labels:\")\n",
    "    print(t_bio_tags[i])\n",
    "    for token, true_label, pred in zip(np.array(tokens)[tags_mask], true_tags, pred):\n",
    "        print(token, \"\\t\\ttrue:\", true_label, \"  pred:\", pred)\n",
    "\n",
    "    \n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed75fdc9",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e074406-b4a3-4123-9fc3-5b5510b418b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b92eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early stopping is doing this now \n",
    "\n",
    "# torch.save(model.state_dict(), \"./model-causal-span/causal_span_1_weighted-loss-moreData.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819275d",
   "metadata": {},
   "source": [
    "### Load model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dfc6ac-faa3-4ca8-a6c9-fa527663be98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4725e1bf-52bd-4bbc-bebd-d27cdadff675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cause-and-effect_model_1_finetuned-0-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-10-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-12-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-15-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-18-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-19-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--1-epochs-lr_0.001.pth\n",
      "cause-and-effect_model_1_finetuned--1-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-1-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-20-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-22-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-25-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-27-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--2-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-2-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-32-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-34-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-35-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-36-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-37-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--3-epochs-lr_0.001.pth\n",
      "cause-and-effect_model_1_finetuned--3-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-3-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-40-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-43-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--4-epochs-lr_0.001.pth\n",
      "cause-and-effect_model_1_finetuned-4-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--5-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-5-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--6-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--7-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-7-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--8-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned--9-epochs-lr_1e-05.pth\n",
      "cause-and-effect_model_1_finetuned-9-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-0-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-10-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-11-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-12-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-14-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-17-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-18-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned--1-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-20-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-21-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-23-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-25-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-2-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-30-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-32-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-33-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-39-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned--3-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-3-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned--4-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-4-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-5-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned--6-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned--7-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-8-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned--9-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_1_finetuned-9-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-0-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-10-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-17-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-18-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-19-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-23-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-28-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-2-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-30-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-32-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned--3-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-3-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned--4-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-4-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned--5-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned--6-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned--7-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-7-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned--8-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned--9-epochs-lr_1e-05.pth\n",
      "cause-or-effect_model_test_finetuned-9-epochs-lr_1e-05.pth\n"
     ]
    }
   ],
   "source": [
    "!ls model-causal-span/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0199ab-6492-4b90-ad3f-9e01bf11b924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c9d9354-6dc6-4d5e-9405-ea0dccef16da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../model-causal-span': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls ../model-causal-span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6830ead1-df2b-4568-8540-083e6d1d6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"../model-causal-span/cause-or-effect_model_test_finetuned-30-epochs-lr_1e-05.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99e8ccd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing BertModel: ['roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.7.output.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'lm_head.decoder.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.weight', 'lm_head.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../model-causal-span/cause-or-effect_model_test_finetuned-30-epochs-lr_1e-05.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3e17c63a1058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCausalNER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/clue/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/clue/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/clue/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../model-causal-span/cause-or-effect_model_test_finetuned-30-epochs-lr_1e-05.pth'"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CausalNER()\n",
    "model.load_state_dict(torch.load(modelName))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(TweetDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7730a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55e3258a-f7ab-4730-b757-078b5126f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#@@', 'diabetes', 'is', 'a', 'shitty', 'disease']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 85, 15015, 17, 11, 3263, 5110, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer1 = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "#tokenizer2 = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "#tokenizer3 = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "#tokenizer4 = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#bert = transformers.BertModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "seq = normalizeTweet(\"#diabetes is a shitty disease\")\n",
    "\n",
    "\n",
    "print(tokenizer1.tokenize(seq))\n",
    "#print(tokenizer2.tokenize(seq))\n",
    "#print(tokenizer3.tokenize(seq))\n",
    "#print(tokenizer4.tokenize(seq))\n",
    "\n",
    "inputs = tokenizer1(seq, padding=True, truncation=True, return_token_type_ids=True)\n",
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d3c027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '#@@', 'diabetes', 'is', 'a', 'shitty', 'disease', '</s>']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer1.convert_ids_to_tokens(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "306d8ffe-ac9c-46ee-8a5b-085abdc83d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USER', 'USER', 'I', 'knew', 'diabetes', 'and', 'fi@@', 'bro@@', 'my@@', 'al@@', 'gia', 'were', 'all', 'big', 'fake', 'conditions', 'just', 'like', 'cancer', '.', 'ðŸ™„']\n",
      "['USER', 'Ä US', 'ER', 'Ä I', 'Ä knew', 'Ä diabetes', 'Ä and', 'Ä fib', 'romy', 'algia', 'Ä were', 'Ä all', 'Ä big', 'Ä fake', 'Ä conditions', 'Ä just', 'Ä like', 'Ä cancer', 'Ä .', 'Ä Ã°Å', 'Ä»', 'Ä¦']\n",
      "['user', 'user', 'i', 'knew', 'diabetes', 'and', 'fi', '##bro', '##my', '##al', '##gia', 'were', 'all', 'big', 'fake', 'conditions', 'just', 'like', 'cancer', '.', '[UNK]']\n",
      "\n",
      "['â¬‡', 'ï¸', 'â¬‡', 'ï¸', 'â¬‡', 'ï¸', 'THIS', 'â¬‡', 'ï¸', 'â¬‡', 'ï¸', 'â¬‡', 'ï¸', 'My', 'wife', 'has', 'type', '-', '1', 'diabetes', '.', 'I@@', \"'m\", 'a', 'trans', 'woman', '.', 'Both', 'of', 'us', 'could', 'use', 'a', 'world', 'where', '\"', 'brave', 'and', 'strong', '\"', 'runs', 'a', 'distant', 'second', 'to', '\"', 'comfortable', 'and', 'included', '\"', '.', 'Make', 'a', 'world', 'where', 'people', 'can', 'just', 'be', ',', 'without', 'having', 'to', 'be', '\"', 'brave', 'and', 'strong', '\"', 'about', 'their', 'existence', '.']\n",
      "['Ã¢', 'Â¬', 'Ä©', 'Ä Ã¯', 'Â¸', 'Ä±', 'Ä Ã¢', 'Â¬', 'Ä©', 'Ä Ã¯', 'Â¸', 'Ä±', 'Ä Ã¢', 'Â¬', 'Ä©', 'Ä Ã¯', 'Â¸', 'Ä±', 'Ä THIS', 'Ä Ã¢', 'Â¬', 'Ä©', 'Ä Ã¯', 'Â¸', 'Ä±', 'Ä Ã¢', 'Â¬', 'Ä©', 'Ä Ã¯', 'Â¸', 'Ä±', 'Ä Ã¢', 'Â¬', 'Ä©', 'Ä Ã¯', 'Â¸', 'Ä±', 'Ä My', 'Ä wife', 'Ä has', 'Ä type', 'Ä -', 'Ä 1', 'Ä diabetes', 'Ä .', 'Ä I', \"'m\", 'Ä a', 'Ä trans', 'Ä woman', 'Ä .', 'Ä Both', 'Ä of', 'Ä us', 'Ä could', 'Ä use', 'Ä a', 'Ä world', 'Ä where', 'Ä \"', 'Ä brave', 'Ä and', 'Ä strong', 'Ä \"', 'Ä runs', 'Ä a', 'Ä distant', 'Ä second', 'Ä to', 'Ä \"', 'Ä comfortable', 'Ä and', 'Ä included', 'Ä \"', 'Ä .', 'Ä Make', 'Ä a', 'Ä world', 'Ä where', 'Ä people', 'Ä can', 'Ä just', 'Ä be', 'Ä ,', 'Ä without', 'Ä having', 'Ä to', 'Ä be', 'Ä \"', 'Ä brave', 'Ä and', 'Ä strong', 'Ä \"', 'Ä about', 'Ä their', 'Ä existence', 'Ä .']\n",
      "['[UNK]', '[UNK]', '[UNK]', 'this', '[UNK]', '[UNK]', '[UNK]', 'my', 'wife', 'has', 'type', '-', '1', 'diabetes', '.', 'i', \"'\", 'm', 'a', 'trans', 'woman', '.', 'both', 'of', 'us', 'could', 'use', 'a', 'world', 'where', '\"', 'brave', 'and', 'strong', '\"', 'runs', 'a', 'distant', 'second', 'to', '\"', 'comfortable', 'and', 'included', '\"', '.', 'make', 'a', 'world', 'where', 'people', 'can', 'just', 'be', ',', 'without', 'having', 'to', 'be', '\"', 'brave', 'and', 'strong', '\"', 'about', 'their', 'existence', '.']\n",
      "\n",
      "['USER', 'Cheers', '!', 'Have', 'one', 'for', 'this', 'diabetic', 'too', '!']\n",
      "['USER', 'Ä Che', 'ers', 'Ä !', 'Ä Have', 'Ä one', 'Ä for', 'Ä this', 'Ä diabetic', 'Ä too', 'Ä !']\n",
      "['user', 'cheers', '!', 'have', 'one', 'for', 'this', 'dia', '##bet', '##ic', 'too', '!']\n",
      "\n",
      "['USER', 'Additionally', 'the', 'medicines', 'are', 'being', 'charged', 'at', 'M@@', 'RP', 'and', 'some', 'of', 'them', 'are', 'costing', 'much', 'higher', 'now', 'for', 'instance', 'insulin', 'injections']\n",
      "['USER', 'Ä Additionally', 'Ä the', 'Ä medicines', 'Ä are', 'Ä being', 'Ä charged', 'Ä at', 'Ä MR', 'P', 'Ä and', 'Ä some', 'Ä of', 'Ä them', 'Ä are', 'Ä costing', 'Ä much', 'Ä higher', 'Ä now', 'Ä for', 'Ä instance', 'Ä insulin', 'Ä injections']\n",
      "['user', 'additionally', 'the', 'medicines', 'are', 'being', 'charged', 'at', 'mr', '##p', 'and', 'some', 'of', 'them', 'are', 'costing', 'much', 'higher', 'now', 'for', 'instance', 'insulin', 'injection', '##s']\n",
      "\n",
      "['USER', 'USER', 'We', 'have', 'those', 'days', 'Esp', '.', 'if', 'it', 'inter@@', 'rupts', 'his', 'fun', '.', 'I', 'hear', '\"', 'I', 'hate', 'being', 'a', 'diabetic', '\"', '.', 'T@@', '1s', 'fight', 'so', 'much', 'harder', '/', 'longer', 'than', 'people', 'can', 'see', '.']\n",
      "['USER', 'Ä US', 'ER', 'Ä We', 'Ä have', 'Ä those', 'Ä days', 'Ä Esp', 'Ä .', 'Ä if', 'Ä it', 'Ä interrupts', 'Ä his', 'Ä fun', 'Ä .', 'Ä I', 'Ä hear', 'Ä \"', 'Ä I', 'Ä hate', 'Ä being', 'Ä a', 'Ä diabetic', 'Ä \"', 'Ä .', 'Ä T', '1', 's', 'Ä fight', 'Ä so', 'Ä much', 'Ä harder', 'Ä /', 'Ä longer', 'Ä than', 'Ä people', 'Ä can', 'Ä see', 'Ä .']\n",
      "['user', 'user', 'we', 'have', 'those', 'days', 'es', '##p', '.', 'if', 'it', 'interrupt', '##s', 'his', 'fun', '.', 'i', 'hear', '\"', 'i', 'hate', 'being', 'a', 'dia', '##bet', '##ic', '\"', '.', 't', '##1', '##s', 'fight', 'so', 'much', 'harder', '/', 'longer', 'than', 'people', 'can', 'see', '.']\n",
      "\n",
      "['Why', 'all', 'of', 'a', 'sudden', 'are', 'people', 'hungry', 'and', 'vulnerable', 'in', 'the', 'uk', '?', 'Obesity', 'and', 'diabetes', 'on', 'the', 'rise', ',', 'it', 'does@@', \"n't\", 'add', 'up']\n",
      "['Why', 'Ä all', 'Ä of', 'Ä a', 'Ä sudden', 'Ä are', 'Ä people', 'Ä hungry', 'Ä and', 'Ä vulnerable', 'Ä in', 'Ä the', 'Ä u', 'k', 'Ä ?', 'Ä Obesity', 'Ä and', 'Ä diabetes', 'Ä on', 'Ä the', 'Ä rise', 'Ä ,', 'Ä it', 'Ä doesn', \"'t\", 'Ä add', 'Ä up']\n",
      "['why', 'all', 'of', 'a', 'sudden', 'are', 'people', 'hungry', 'and', 'vulnerable', 'in', 'the', 'uk', '?', 'obesity', 'and', 'diabetes', 'on', 'the', 'rise', ',', 'it', 'doesn', \"'\", 't', 'add', 'up']\n",
      "\n",
      "['i', 'got', 'lime', 'for', 'my', 'gluc@@', 'ose', 'test', ',', 'was@@', \"n't\", 'that', 'bad', 'but', 'that', 'shit', 'is', 'so', 'sweet', 'after', 'downing', 'a', 'whole', 'lil', 'bottle', 'i@@', \"'m\", 'nauseous', 'now', 'ðŸ˜­', 'ðŸ¤®']\n",
      "['i', 'Ä got', 'Ä lime', 'Ä for', 'Ä my', 'Ä glucose', 'Ä test', 'Ä ,', 'Ä wasn', \"'t\", 'Ä that', 'Ä bad', 'Ä but', 'Ä that', 'Ä shit', 'Ä is', 'Ä so', 'Ä sweet', 'Ä after', 'Ä down', 'ing', 'Ä a', 'Ä whole', 'Ä lil', 'Ä bottle', 'Ä i', \"'m\", 'Ä nause', 'ous', 'Ä now', 'Ä Ã°ÅÄº', 'Åƒ', 'Ä Ã°Å', 'Â¤', 'Â®']\n",
      "['i', 'got', 'lime', 'for', 'my', 'glucose', 'test', ',', 'wasn', \"'\", 't', 'that', 'bad', 'but', 'that', 'shit', 'is', 'so', 'sweet', 'after', 'downing', 'a', 'whole', 'lil', 'bottle', 'i', \"'\", 'm', 'na', '##use', '##ous', 'now', '[UNK]', '[UNK]']\n",
      "\n",
      "['This', 'stick@@', 'ur', 'of', 'Un@@', 'kel', 'Funny', 'iz', 'ware', 'i', 'am', 'shaved', 'too', 'git', 'my', 'insulin', '!', 'I', 'no', 'he', 'wood', 'like', 'that', '!', 'hee', 'hee', '!', 'USER', 'USER', 'USER', 'USER', 'USER', 'USER', 'USER', 'USER', 'USER', 'USER', 'USER', 'USER', 'HTTPURL']\n",
      "['This', 'Ä stick', 'ur', 'Ä of', 'Ä Un', 'kel', 'Ä Funny', 'Ä ', 'iz', 'Ä ware', 'Ä i', 'Ä am', 'Ä shaved', 'Ä too', 'Ä git', 'Ä my', 'Ä insulin', 'Ä !', 'Ä I', 'Ä no', 'Ä he', 'Ä wood', 'Ä like', 'Ä that', 'Ä !', 'Ä he', 'e', 'Ä he', 'e', 'Ä !', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä US', 'ER', 'Ä HTTP', 'URL']\n",
      "['this', 'stick', '##ur', 'of', 'un', '##kel', 'funny', 'i', '##z', 'ware', 'i', 'am', 'shaved', 'too', 'gi', '##t', 'my', 'insulin', '!', 'i', 'no', 'he', 'wood', 'like', 'that', '!', 'hee', 'hee', '!', 'user', 'user', 'user', 'user', 'user', 'user', 'user', 'user', 'user', 'user', 'user', 'user', 'http', '##ur', '##l']\n",
      "\n",
      "['For', 'the', 'second', 'time', 'in', 'my', 'life', 'I', 'gave', 'myself', 'insulin', 'for', 'a', 'beer', 'I', \"didn't\", 'end', 'up', 'drinking', '.', 'I', \"didn't\", 'pass', 'out', 'this', 'time', 'but', 'I', 'did', 'end', 'up', 'with', 'my', 'hand', 'covered', 'in', 'peanut', 'butter', 'yelling', 'â€œ', 'I@@', \"'m\", 'having', 'a', 'bad', 'time', '.', 'â€']\n",
      "['For', 'Ä the', 'Ä second', 'Ä time', 'Ä in', 'Ä my', 'Ä life', 'Ä I', 'Ä gave', 'Ä myself', 'Ä insulin', 'Ä for', 'Ä a', 'Ä beer', 'Ä I', 'Ä didn', \"'t\", 'Ä end', 'Ä up', 'Ä drinking', 'Ä .', 'Ä I', 'Ä didn', \"'t\", 'Ä pass', 'Ä out', 'Ä this', 'Ä time', 'Ä but', 'Ä I', 'Ä did', 'Ä end', 'Ä up', 'Ä with', 'Ä my', 'Ä hand', 'Ä covered', 'Ä in', 'Ä peanut', 'Ä butter', 'Ä yelling', 'Ä Ã¢Ä¢', 'Ä¾', 'Ä I', \"'m\", 'Ä having', 'Ä a', 'Ä bad', 'Ä time', 'Ä .', 'Ä Ã¢Ä¢', 'Ä¿']\n",
      "['for', 'the', 'second', 'time', 'in', 'my', 'life', 'i', 'gave', 'myself', 'insulin', 'for', 'a', 'beer', 'i', 'didn', \"'\", 't', 'end', 'up', 'drinking', '.', 'i', 'didn', \"'\", 't', 'pass', 'out', 'this', 'time', 'but', 'i', 'did', 'end', 'up', 'with', 'my', 'hand', 'covered', 'in', 'peanut', 'butter', 'yelling', 'â€œ', 'i', \"'\", 'm', 'having', 'a', 'bad', 'time', '.', 'â€']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in data[1:10].iterrows():\n",
    "    print(tokenizer1.tokenize(row[\"full_text\"]))\n",
    "    print(tokenizer2.tokenize(row[\"full_text\"]))\n",
    "    print(tokenizer4.tokenize(row[\"full_text\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8b11d-5fbe-4f8d-a441-0f68a19abf92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
