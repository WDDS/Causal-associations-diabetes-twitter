{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25788515",
   "metadata": {},
   "source": [
    "## A model build using TweetBERT to identify cause-effect pairs in sentences of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75586b5c",
   "metadata": {},
   "source": [
    "The cause-effect pair sentence prediction model will be trained on the dataset which got augmented in an active learning approach in 5 steps.\n",
    "\n",
    "Load already preprocessed file with sentence containing either cause or effect or both. Sentences labeled as Jokes, questions or having negations are removed.\n",
    "\n",
    "IO tagging is used instead of BIO tagging. The assumption is that the attention mechanism already encodes information about the postion (B-.). In consequence the training should be simplified with only 3 classes: I-C, I-E, O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689f9f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from seqeval.metrics import classification_report as classification_report_seqeval\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from tqdm import tqdm, trange\n",
    "from utils import normalizeTweet, split_into_sentences, bio_tagging, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from torchcrf import CRF\n",
    "%matplotlib inline\n",
    "\n",
    "########################### Check if cuda available ############################\n",
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "########################### DATA FILE ###################################\n",
    "dataPath = \"data/cause_effect_sentences_with_IO_tags.csv\"\n",
    "#dataPath = \"data/Causality_tweets_data.xlsx\"\n",
    "#dataPath = \"Causality_tweets_data.xlsx\"\n",
    "\n",
    "\n",
    "########################### MODEL PARAMETERS ############################\n",
    "lr = 1e-5 # earlier 1e-3    \n",
    "adam_eps = 1e-8\n",
    "epochs = 55\n",
    "num_warmup_steps = 0\n",
    "early_patience = 10 # earlier 5, how long to wait after last time validation loss improved\n",
    "\n",
    "train_batch_size = 8\n",
    "val_batch_size = 8\n",
    "test_batch_size = 8\n",
    "train_to_test_ratio = 0.9 # 10% test and 90% train\n",
    "val_to_train_ratio = 0.2\n",
    "type_ = \"cause-or-effect\"\n",
    "attempt_ = \"test\"\n",
    "\n",
    "bert_model = \"vinai/bertweet-base\" # \"bert-large-uncased\"; \"roberta-large\"\n",
    "\n",
    "n_labels = 3 # 0, I-C, I-E\n",
    "tag2id = {label: idx for idx, label in enumerate([\"O\", \"I-C\", \"I-E\"])}\n",
    "tag2id[-100] = -100\n",
    "id2tag = {id:tag for tag,id in tag2id.items()}\n",
    "\n",
    "useClassWeights = True # apply class weights in the model (before the CRF layer)\n",
    "\n",
    "# Options: https://pytorch-crf.readthedocs.io/en/stable/#torchcrf.CRF.forward\n",
    "# - \"sum\" : output will be summed over batches\n",
    "# - \"mean\" : output will be averaged over batches\n",
    "# - \"token_mean\" : output will be averaged over tokens\n",
    "# - None : no reduction\n",
    "reduction_crf = \"sum\" \n",
    "\n",
    "# if True, only sentences containing both cause and effect are considered.\n",
    "# if False, all sentences containing either cause or effect are considered\n",
    "requireCauseAndEffect = True \n",
    "\n",
    "# Each token has its associated IO tag (\"O\", \"I-C\", \"I-E\").\n",
    "# The Bertweet tokenizer splits words into sub-words\n",
    "# if True => assign IO tag of word to all sub-words\n",
    "# if False => assign IO tag of word to first sub-word and all other sub-words get -100 (loss function ignores this index)\n",
    "subwordTagEqualFirstwordTag = False # @Vivek : keep it on False\n",
    "\n",
    "metric_choice = \"weighted\" # micro, macro, samples or weighted \n",
    "# metrics_average = \"binary\" # this will give measure for class_1,i.e., causal class\n",
    "\n",
    "# saveModelName = \"./model-causal-span/cause-and-effect_model_1_finetuned-{}-epochs-lr_{}.pth\".format(epochs, lr) # it should be epoch so that the name shows at what epoch teh mdel ws saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c3521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Causal association</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER Additionally the medicines are being char...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medicines are being charged at MRP</td>\n",
       "      <td>costing much higher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, Additionally, the, medicines, are, bein...</td>\n",
       "      <td>[O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hear \" I hate being a diabetic \" .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diabetic</td>\n",
       "      <td>hate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[I, hear, \", I, hate, being, a, diabetic, \", .]</td>\n",
       "      <td>[O, O, O, O, I-E, O, O, I-C, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got lime for my glucose test , was n't that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glucose test</td>\n",
       "      <td>nauseous</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, got, lime, for, my, glucose, test, ,, was,...</td>\n",
       "      <td>[O, O, O, O, O, I-C, I-C, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sounds like Willow 's blood sugar level is rea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blood sugar level is real low</td>\n",
       "      <td>reduce her insulin shots</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sounds, like, Willow, 's, blood, sugar, level...</td>\n",
       "      <td>[O, O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER I 've always found it too sweet mustvsay ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaded diabetes</td>\n",
       "      <td>sauces are used sparingly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, I, 've, always, found, it, too, sweet, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, I-E, I-E,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Intent  \\\n",
       "0  USER Additionally the medicines are being char...    NaN   \n",
       "1               I hear \" I hate being a diabetic \" .    NaN   \n",
       "2  i got lime for my glucose test , was n't that ...    NaN   \n",
       "3  Sounds like Willow 's blood sugar level is rea...    NaN   \n",
       "4  USER I 've always found it too sweet mustvsay ...    NaN   \n",
       "\n",
       "                                Cause                     Effect  \\\n",
       "0  medicines are being charged at MRP        costing much higher   \n",
       "1                            diabetic                       hate   \n",
       "2                        glucose test                   nauseous   \n",
       "3       blood sugar level is real low   reduce her insulin shots   \n",
       "4                    dreaded diabetes  sauces are used sparingly   \n",
       "\n",
       "   Causal association                                          tokenized  \\\n",
       "0                 1.0  [USER, Additionally, the, medicines, are, bein...   \n",
       "1                 1.0    [I, hear, \", I, hate, being, a, diabetic, \", .]   \n",
       "2                 1.0  [i, got, lime, for, my, glucose, test, ,, was,...   \n",
       "3                 1.0  [Sounds, like, Willow, 's, blood, sugar, level...   \n",
       "4                 1.0  [USER, I, 've, always, found, it, too, sweet, ...   \n",
       "\n",
       "                                            bio_tags  \n",
       "0  [O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, O, ...  \n",
       "1                 [O, O, O, O, I-E, O, O, I-C, O, O]  \n",
       "2  [O, O, O, O, O, I-C, I-C, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, I-E, I-E,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### DATA TO LOAD ######\n",
    "\n",
    "data = pd.read_csv(dataPath, sep=\";\", converters={\"tokenized\":literal_eval, \"bio_tags\":literal_eval})\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bbaef",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec45cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2118, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Causal association</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER Additionally the medicines are being char...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medicines are being charged at MRP</td>\n",
       "      <td>costing much higher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, Additionally, the, medicines, are, bein...</td>\n",
       "      <td>[O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hear \" I hate being a diabetic \" .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diabetic</td>\n",
       "      <td>hate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[I, hear, \", I, hate, being, a, diabetic, \", .]</td>\n",
       "      <td>[O, O, O, O, I-E, O, O, I-C, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got lime for my glucose test , was n't that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glucose test</td>\n",
       "      <td>nauseous</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, got, lime, for, my, glucose, test, ,, was,...</td>\n",
       "      <td>[O, O, O, O, O, I-C, I-C, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sounds like Willow 's blood sugar level is rea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blood sugar level is real low</td>\n",
       "      <td>reduce her insulin shots</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sounds, like, Willow, 's, blood, sugar, level...</td>\n",
       "      <td>[O, O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER I 've always found it too sweet mustvsay ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaded diabetes</td>\n",
       "      <td>sauces are used sparingly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, I, 've, always, found, it, too, sweet, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, I-E, I-E,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Intent  \\\n",
       "0  USER Additionally the medicines are being char...    NaN   \n",
       "1               I hear \" I hate being a diabetic \" .    NaN   \n",
       "2  i got lime for my glucose test , was n't that ...    NaN   \n",
       "3  Sounds like Willow 's blood sugar level is rea...    NaN   \n",
       "4  USER I 've always found it too sweet mustvsay ...    NaN   \n",
       "\n",
       "                                Cause                     Effect  \\\n",
       "0  medicines are being charged at MRP        costing much higher   \n",
       "1                            diabetic                       hate   \n",
       "2                        glucose test                   nauseous   \n",
       "3       blood sugar level is real low   reduce her insulin shots   \n",
       "4                    dreaded diabetes  sauces are used sparingly   \n",
       "\n",
       "   Causal association                                          tokenized  \\\n",
       "0                 1.0  [USER, Additionally, the, medicines, are, bein...   \n",
       "1                 1.0    [I, hear, \", I, hate, being, a, diabetic, \", .]   \n",
       "2                 1.0  [i, got, lime, for, my, glucose, test, ,, was,...   \n",
       "3                 1.0  [Sounds, like, Willow, 's, blood, sugar, level...   \n",
       "4                 1.0  [USER, I, 've, always, found, it, too, sweet, ...   \n",
       "\n",
       "                                            bio_tags  \n",
       "0  [O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, O, ...  \n",
       "1                 [O, O, O, O, I-E, O, O, I-C, O, O]  \n",
       "2  [O, O, O, O, O, I-C, I-C, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, I-E, I-E,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Choose only sentences with both cause and effect or only sentences with either cause or effect (or both) #######\n",
    "\n",
    "\n",
    "if requireCauseAndEffect: # cause and effect in sentence\n",
    "    dataSentFiltered = data[(data[\"Cause\"].notnull()) & (data[\"Effect\"].notnull())]\n",
    "else: # cause or effect or both in sentence\n",
    "    dataSentFiltered = data[(data[\"Cause\"].notnull()) | (data[\"Effect\"].notnull())]\n",
    "\n",
    "print(dataSentFiltered.shape)\n",
    "dataSentFiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2739c3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([137., 494., 672., 402., 179., 115.,  79.,  30.,   9.,   1.]),\n",
       " array([ 3. , 10.2, 17.4, 24.6, 31.8, 39. , 46.2, 53.4, 60.6, 67.8, 75. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAARwUlEQVR4nO3dX4xc513G8e9Tp01pKdQma8vYLk4lk+IgkpSVSRVUlRiI26I6N5EcCWShSObCoEaqBDZIIJAsmZsKLgiS1X+WWmK5hRKrrdoalwiB2ribNKWxHWPThGSxay9BVfpHMtj8uJgTdbqe9c56d7Ljt9+PNDrnvPOemWcd59mzZ88cp6qQJLXlNcsdQJK09Cx3SWqQ5S5JDbLcJalBlrskNchyl6QGzVvuSW5L8nTf4+UkDydZleRokjPdcmXfPnuTnE1yOsl9o/0SJEmzZSHXuSdZAfwn8EvAbuC/q2p/kj3Ayqr6gySbgUeBLcBPA/8A/GxVXVny9JKkgW5a4PytwL9X1X8k2Q68qxs/CDwO/AGwHThUVZeA55KcpVf0X57rRW+55ZbauHHjAqNI0o+2J5988r+qamLQcwst9x30jsoB1lTVeYCqOp9kdTe+DvhK3z7T3dicNm7cyNTU1AKjSNKPtiT/MddzQ/9CNcnrgPcBn5xv6oCxq879JNmVZCrJ1MzMzLAxJElDWMjVMu8GnqqqC932hSRrAbrlxW58GtjQt9964NzsF6uqA1U1WVWTExMDf6qQJF2nhZT7g/zglAzAEWBnt74TeKxvfEeSm5PcCmwCji82qCRpeEOdc0/yBuDXgN/pG94PHE7yEPAC8ABAVZ1Ichg4CVwGdnuljCS9uoYq96r6PvBTs8Zeonf1zKD5+4B9i04nSboufkJVkhpkuUtSgyx3SWqQ5S5JDVroJ1Q1Bjbu+eyyvffz+9+7bO8taXgeuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDhir3JG9O8qkkzyY5leQdSVYlOZrkTLdc2Td/b5KzSU4nuW908SVJgwx75P6XwOer6m3AHcApYA9wrKo2Ace6bZJsBnYAtwPbgEeSrFjq4JKkuc1b7kl+Angn8GGAqvqfqvo2sB042E07CNzfrW8HDlXVpap6DjgLbFna2JKkaxnmyP2twAzw0SRfS/KhJG8E1lTVeYBuubqbvw54sW//6W5MkvQqGabcbwLeDvx1Vd0FfI/uFMwcMmCsrpqU7EoylWRqZmZmqLCSpOEMU+7TwHRVPdFtf4pe2V9IshagW17sm7+hb//1wLnZL1pVB6pqsqomJyYmrje/JGmAecu9qr4FvJjktm5oK3ASOALs7MZ2Ao9160eAHUluTnIrsAk4vqSpJUnXdNOQ834P+ESS1wHfBH6b3jeGw0keAl4AHgCoqhNJDtP7BnAZ2F1VV5Y8uSRpTkOVe1U9DUwOeGrrHPP3AfuuP5YkaTH8hKokNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWrQUOWe5Pkk30jydJKpbmxVkqNJznTLlX3z9yY5m+R0kvtGFV6SNNhCjtx/parurKrJbnsPcKyqNgHHum2SbAZ2ALcD24BHkqxYwsySpHks5rTMduBgt34QuL9v/FBVXaqq54CzwJZFvI8kaYGGLfcCvpjkySS7urE1VXUeoFuu7sbXAS/27TvdjUmSXiU3DTnvnqo6l2Q1cDTJs9eYmwFjddWk3jeJXQBvectbhowhSRrGUEfuVXWuW14EPk3vNMuFJGsBuuXFbvo0sKFv9/XAuQGveaCqJqtqcmJi4vq/AknSVeY9ck/yRuA1VfWdbv3XgT8DjgA7gf3d8rFulyPA3yT5IPDTwCbg+AiyL7uNez673BEkaaBhTsusAT6d5JX5f1NVn0/yVeBwkoeAF4AHAKrqRJLDwEngMrC7qq6MJL0kaaB5y72qvgncMWD8JWDrHPvsA/YtOp0k6br4CVVJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktSgocs9yYokX0vymW57VZKjSc50y5V9c/cmOZvkdJL7RhFckjS3hRy5vx841be9BzhWVZuAY902STYDO4DbgW3AI0lWLE1cSdIwhir3JOuB9wIf6hveDhzs1g8C9/eNH6qqS1X1HHAW2LIkaSVJQ7lpyHl/Afw+8Ka+sTVVdR6gqs4nWd2NrwO+0jdvuhtTAzbu+eyyvO/z+9+7LO8r3ajmPXJP8hvAxap6csjXzICxGvC6u5JMJZmamZkZ8qUlScMY5rTMPcD7kjwPHALuTfJx4EKStQDd8mI3fxrY0Lf/euDc7BetqgNVNVlVkxMTE4v4EiRJs81b7lW1t6rWV9VGer8o/VJV/SZwBNjZTdsJPNatHwF2JLk5ya3AJuD4kieXJM1p2HPug+wHDid5CHgBeACgqk4kOQycBC4Du6vqyqKTSpKGtqByr6rHgce79ZeArXPM2wfsW2Q2SdJ18hOqktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2at9yTvD7J8SRfT3IiyZ9246uSHE1ypluu7Ntnb5KzSU4nuW+UX4Ak6WrDHLlfAu6tqjuAO4FtSe4G9gDHqmoTcKzbJslmYAdwO7ANeCTJihFklyTNYd5yr57vdpuv7R4FbAcOduMHgfu79e3Aoaq6VFXPAWeBLUsZWpJ0bUOdc0+yIsnTwEXgaFU9AaypqvMA3XJ1N30d8GLf7tPdmCTpVTJUuVfVlaq6E1gPbEny89eYnkEvcdWkZFeSqSRTMzMzQ4WVJA1nQVfLVNW3gcfpnUu/kGQtQLe82E2bBjb07bYeODfgtQ5U1WRVTU5MTCw8uSRpTsNcLTOR5M3d+o8Bvwo8CxwBdnbTdgKPdetHgB1Jbk5yK7AJOL7EuSVJ13DTEHPWAge7K15eAxyuqs8k+TJwOMlDwAvAAwBVdSLJYeAkcBnYXVVXRhNfkjTIvOVeVf8K3DVg/CVg6xz77AP2LTqdJOm6+AlVSWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUoHnLPcmGJP+Y5FSSE0ne342vSnI0yZluubJvn71JziY5neS+UX4BkqSrDXPkfhn4QFX9HHA3sDvJZmAPcKyqNgHHum2653YAtwPbgEeSrBhFeEnSYPOWe1Wdr6qnuvXvAKeAdcB24GA37SBwf7e+HThUVZeq6jngLLBliXNLkq5hQefck2wE7gKeANZU1XnofQMAVnfT1gEv9u023Y1Jkl4lQ5d7kh8H/hZ4uKpevtbUAWM14PV2JZlKMjUzMzNsDEnSEIYq9ySvpVfsn6iqv+uGLyRZ2z2/FrjYjU8DG/p2Xw+cm/2aVXWgqiaranJiYuJ680uSBhjmapkAHwZOVdUH+546Auzs1ncCj/WN70hyc5JbgU3A8aWLLEmaz01DzLkH+C3gG0me7sb+ENgPHE7yEPAC8ABAVZ1Ichg4Se9Km91VdWWpg0uS5jZvuVfVPzP4PDrA1jn22QfsW0QuSdIi+AlVSWqQ5S5JDRrmnLu07Dbu+eyyvffz+9+7bO8tXS+P3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUoCZuHLacN5WSpHHkkbskNchyl6QGWe6S1CDLXZIaZLlLUoOauFpGGqXluhrLf95PizHvkXuSjyS5mOSZvrFVSY4mOdMtV/Y9tzfJ2SSnk9w3quCSpLkNc1rmY8C2WWN7gGNVtQk41m2TZDOwA7i92+eRJCuWLK0kaSjzlntV/RPw37OGtwMHu/WDwP1944eq6lJVPQecBbYsTVRJ0rCu9xeqa6rqPEC3XN2NrwNe7Js33Y1Jkl5FS321TAaM1cCJya4kU0mmZmZmljiGJP1ou95yv5BkLUC3vNiNTwMb+uatB84NeoGqOlBVk1U1OTExcZ0xJEmDXG+5HwF2dus7gcf6xnckuTnJrcAm4PjiIkqSFmre69yTPAq8C7glyTTwJ8B+4HCSh4AXgAcAqupEksPASeAysLuqrowouyRpDvOWe1U9OMdTW+eYvw/Yt5hQkqTF8fYDktQgbz8gjanl/EdovPXBjc8jd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhrk/dwlXWW57iXvfeSXjkfuktQgy12SGmS5S1KDLHdJatDIyj3JtiSnk5xNsmdU7yNJutpIrpZJsgL4K+DXgGngq0mOVNXJUbyfpDZ4lc7SGdWR+xbgbFV9s6r+BzgEbB/Re0mSZhnVde7rgBf7tqeBXxrRe0nSoizXTwwwup8aRlXuGTBWPzQh2QXs6ja/m+R0t34L8F8jyrWUzLn0bpSs5lxaN0pOGEHW/Pmidv+ZuZ4YVblPAxv6ttcD5/onVNUB4MDsHZNMVdXkiHItGXMuvRslqzmX1o2SE26srKM65/5VYFOSW5O8DtgBHBnRe0mSZhnJkXtVXU7yu8AXgBXAR6rqxCjeS5J0tZHdOKyqPgd87jp2vepUzZgy59K7UbKac2ndKDnhBsqaqpp/liTphuLtBySpQWNT7uN8u4IkH0lyMckzfWOrkhxNcqZbrlzOjF2mDUn+McmpJCeSvH8csyZ5fZLjSb7e5fzTccz5iiQrknwtyWe67XHN+XySbyR5OslUNzZ2WZO8Ocmnkjzb/V19x7jlTHJb9+f4yuPlJA+PW85rGYty77tdwbuBzcCDSTYvb6of8jFg26yxPcCxqtoEHOu2l9tl4ANV9XPA3cDu7s9x3LJeAu6tqjuAO4FtSe5m/HK+4v3Aqb7tcc0J8CtVdWff5XrjmPUvgc9X1duAO+j92Y5Vzqo63f053gn8IvB94NOMWc5rqqplfwDvAL7Qt70X2LvcuWZl3Ag807d9Gljbra8FTi93xgGZH6N3f5+xzQq8AXiK3ieYxy4nvc9oHAPuBT4zzv/tgeeBW2aNjVVW4CeA5+h+3zeuOWdl+3XgX8Y95+zHWBy5M/h2BeuWKcuw1lTVeYBuuXqZ8/yQJBuBu4AnGMOs3amOp4GLwNGqGsucwF8Avw/8X9/YOOaE3qfAv5jkye4T4DB+Wd8KzAAf7U51fSjJGxm/nP12AI926+Oc84eMS7nPe7sCDS/JjwN/CzxcVS8vd55BqupK9X7kXQ9sSfLzyxzpKkl+A7hYVU8ud5Yh3VNVb6d3enN3kncud6ABbgLeDvx1Vd0FfI8xPrXRfQjzfcAnlzvLQo1Luc97u4IxdCHJWoBueXGZ8wCQ5LX0iv0TVfV33fBYZgWoqm8Dj9P7nca45bwHeF+S5+nd2fTeJB9n/HICUFXnuuVFeueHtzB+WaeB6e4nNYBP0Sv7ccv5incDT1XVhW57XHNeZVzK/Ua8XcERYGe3vpPe+e1llSTAh4FTVfXBvqfGKmuSiSRv7tZ/DPhV4FnGLGdV7a2q9VW1kd7fyS9V1W8yZjkBkrwxyZteWad3nvgZxixrVX0LeDHJbd3QVuAkY5azz4P84JQMjG/Oqy33Sf++X1q8B/g34N+BP1ruPLOyPQqcB/6X3pHHQ8BP0ftF25luuWoMcv4yvdNZ/wo83T3eM25ZgV8AvtblfAb44258rHLOyvwufvAL1bHLSe9c9te7x4lX/h8a06x3AlPdf/+/B1aOac43AC8BP9k3NnY553r4CVVJatC4nJaRJC0hy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAb9P5VLgT0sOKbXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## Distribution of sentences length ########################\n",
    "\n",
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in dataSentFiltered[\"sentence\"]]\n",
    "plt.hist(seq_len)\n",
    "#pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a7b2d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f806e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (72, 7)\n",
      "Validate: (18, 7)\n",
      "Test: (10, 7)\n"
     ]
    }
   ],
   "source": [
    "trainingDataSample = dataSentFiltered#.sample(n=100)   # Only for testing\n",
    "train = trainingDataSample.sample(frac=train_to_test_ratio, random_state=0)\n",
    "test = trainingDataSample.drop(train.index)\n",
    "validate = train.sample(frac=val_to_train_ratio, random_state=0)\n",
    "train = train.drop(validate.index)\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Validate:\", validate.shape)\n",
    "print(\"Test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26cdc4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "18\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "######### BERTWEET TOKENIZER + PYTORCH DATASET/DATALOADER STRUCTURE ##################\n",
    "\n",
    "class TweetDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, labels, bio_tags, tokenizer):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bio_tags = bio_tags\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.text, padding=True, truncation=True, return_token_type_ids=True)\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]     \n",
    "        bio_tags_extended = self.extend_tags(self.text[idx], self.bio_tags[idx], ids[idx])\n",
    "\n",
    "        assert len(ids[idx]) == len(bio_tags_extended), \"token ids (N: {}) and IO tags (N: {}) lengths do not match!\\nids[idx]: {}\\nbio_tags: {}\".format(len(ids[idx]), len(bio_tags_extended), ids[idx], bio_tags_extended)\n",
    "        return {\n",
    "                \"input_ids\" : torch.tensor(ids[idx], dtype=torch.long)\n",
    "              , \"attention_mask\" : torch.tensor(mask[idx], dtype=torch.long)\n",
    "              , \"token_type_ids\" : torch.tensor(token_type_ids[idx], dtype=torch.long)\n",
    "              , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "              , \"bio_tags\" : torch.tensor(list(map(lambda bioTags: tag2id[bioTags], bio_tags_extended))\n",
    ", dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    def extend_tags(self, tokens_old, tags_old, ids_tokenized_padded):\n",
    "        \"\"\" \n",
    "            Each token has a IO tag label. \n",
    "            However BERT's tokenization splits tokens into subwords. How to label those subwords?\n",
    "            \n",
    "            Option 1:\n",
    "            ---------\n",
    "            \n",
    "            add the same label to each subword than the first subword\n",
    "            Ex. \n",
    "            #lowbloodsugar => '#low@@', 'blood@@', 'sugar@@'\n",
    "               \"I-C\"       =>   \"I-C\" ,   \"I-C\"  ,   \"I-C\"\n",
    "            \n",
    "            Option 2:      \n",
    "            ---------\n",
    "            \n",
    "            From : https://huggingface.co/transformers/custom_datasets.html#token-classification-with-w-nut-emerging-entities\n",
    "            A common obstacle with using pre-trained models for token-level classification: many of the tokens in\n",
    "            the W-NUT corpus are not in DistilBert’s vocabulary. Bert and many models like it use a method called \n",
    "            WordPiece Tokenization, meaning that single words are split into multiple tokens such that each token\n",
    "            is likely to be in the vocabulary. For example, DistilBert’s tokenizer would split the Twitter \n",
    "            handle @huggingface into the tokens ['@', 'hugging', '##face']. This is a problem for us because we \n",
    "            have exactly one tag per token. If the tokenizer splits a token into multiple sub-tokens, then we will\n",
    "            end up with a mismatch between our tokens and our labels.\n",
    "\n",
    "            One way to handle this is to only train on the tag labels for the first subtoken of a split token. \n",
    "            We can do this in 🤗 Transformers by setting the labels we wish to ignore to -100. \n",
    "            In the example above, if the label for @HuggingFace is 3 (indexing B-corporation), we would set \n",
    "            the labels of ['@', 'hugging', '##face'] to [3, -100, -100].\n",
    "        \"\"\"\n",
    "        tags = [-100] # add for start token <CLS>\n",
    "        for token_old, tag in zip(tokens_old.split(\" \"), tags_old):\n",
    "            #print(F\"\\ntoken_old: {token_old};    tag: {tag}\")\n",
    "            for i, sub_token in enumerate(self.tokenizer.tokenize(token_old)):\n",
    "                if (i == 0): # first sub token of a word keeps the original bio tag\n",
    "                    firstTag = tag\n",
    "                    tags.append(tag)\n",
    "                    #print(F\"\\tsubToken: {sub_token};    tag: {tag}\")\n",
    "                else: \n",
    "                    if subwordTagEqualFirstwordTag: # the other sub tokens get the first bio tag than the first sub token\n",
    "                        tags.append(firstTag)\n",
    "                    #    print(F\"\\tsubToken: {sub_token};    tag: {firstTag}\")\n",
    "                    else: # to other sub tokens get the tag -100 (ignored in loss function)\n",
    "                        tags.append(-100)\n",
    "                    #    print(F\"\\tsubToken: {sub_token};    tag: {-100}\")\n",
    "\n",
    "        tags.append(-100) # 0 for end of sentence token\n",
    "    \n",
    "        # append -100 for all padded elements\n",
    "        padded_elements = ids_tokenized_padded.count(1) # id 1 is <PAD> ; Alternative: where attention_mask == 0 add -100\n",
    "        tags.extend([-100]*padded_elements)\n",
    "        #print(\"\\tpadded_elements:\", ids_tokenized_padded.count(1))\n",
    "        return tags\n",
    "        \n",
    "        \n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model, padding = \"max_length\", truncation = True, max_length = 60 )\n",
    "\n",
    "\n",
    "train_dataset = TweetDataSet(train[\"sentence\"].values.tolist()\n",
    "                           , train[\"Causal association\"].values.tolist()\n",
    "                           , train[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "val_dataset = TweetDataSet(validate[\"sentence\"].values.tolist()\n",
    "                           , validate[\"Causal association\"].values.tolist()\n",
    "                           , validate[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "test_dataset = TweetDataSet(test[\"sentence\"].values.tolist()\n",
    "                           , test[\"Causal association\"].values.tolist()\n",
    "                           , test[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "# put data to batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d072dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-a7b5e9115285>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_bio_tags: [0 0 0 ... 0 0 0]\n",
      "train_bio_tags_count_info: 0    0.802673\n",
      "1    0.104392\n",
      "2    0.092934\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.415279\n",
       "1    3.193089\n",
       "2    3.586758\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ class weights #####################\n",
    "\n",
    "# Since -100 will anyway be ignored by loss func, drop it\n",
    "train_bio_tags = np.hstack([t[\"bio_tags\"][t[\"bio_tags\"]!=-100].numpy() for t in train_dataset])\n",
    "print(\"train_bio_tags:\", train_bio_tags)\n",
    "\n",
    "train_bio_tags_count_info = (pd.Series(train_bio_tags).value_counts(normalize=True))\n",
    "print(\"train_bio_tags_count_info:\", train_bio_tags_count_info)\n",
    "\n",
    "# for class-imbalanced dataset, the class weight for a ith class\n",
    "# to be specified for balancing in the loss function is given by:\n",
    "# weight[i] = num_samples / (num_classes * num_samples[i])\n",
    "# since train_bio_tags_count_info obtained above has fraction of \n",
    "# samples for ith class, hence the corresponding weight calculation is:\n",
    "class_weight = (1/train_bio_tags_count_info)/len(train_bio_tags_count_info)\n",
    "class_weight = class_weight[sorted(class_weight.index)]\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d48a7",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afbc15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, labels):\n",
    "    \"\"\"\n",
    "        Dataset is unbalanced -> measure weighted metrics\n",
    "        Calculate metrics for each label, and find their average wieghted by support (Number of true instances for each label)\n",
    "        This alters 'macro' to account for label imbalance;\n",
    "        it can result in an F-Score taht is not between precision and recall\n",
    "    \"\"\"\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average= metric_choice) # TODO: check weightin\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c6df4",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c83b3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalNER(torch.nn.Module):\n",
    "    \"\"\" Model Bert\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CausalNER, self).__init__()\n",
    "        self.bert = transformers.BertModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear1 = torch.nn.Linear(768, 256)\n",
    "        self.linear2 = torch.nn.Linear(256, n_labels)\n",
    "        self.softmax = torch.nn.Softmax(-1)\n",
    "        self.crf = CRF(num_tags=n_labels, batch_first=True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, tags=None, mask_tags_without_CLS=None):\n",
    "#        _, output_1 = self.bert(input_ids, attention_mask = attention_mask, token_type_ids=token_type_ids, return_dict=False) # if output 1 is our cls token\n",
    "        output_seq, _ = self.bert(input_ids, attention_mask = attention_mask, token_type_ids=token_type_ids, return_dict=False) # if output 1 is our cls token\n",
    "        output_2 = self.dropout(output_seq)\n",
    "        output_3 = self.linear1(output_2)\n",
    "        output_4 = self.dropout(output_3)\n",
    "        output_5 = self.linear2(output_4)\n",
    "        #print(\"\\toutput_5:\", output_5.shape)\n",
    "        \n",
    "        # Add class weights on logits before the CRF layer. It is experimental, based on: https://github.com/kmkurn/pytorch-crf/issues/47\n",
    "        if useClassWeights:\n",
    "            output_5 = torch.stack((output_5[:, :, 0] * class_weight[0]\n",
    "                                    , output_5[:, :, 1] * class_weight[1]\n",
    "                                    , output_5[:, :, 2] * class_weight[2] ), dim=2)\n",
    "\n",
    "        if tags is not None:\n",
    "            # to avoid this error from the pytorch-crf package: ValueError: mask of the first timestep must all be on\n",
    "            # delete [CLS] token of every phrase and first token of mask.\n",
    "            tags_without_CLS = torch.cat([tags[i][1:] for i in range(len(tags))]).view(tags.shape[0],-1)\n",
    "            logits_without_CLS = torch.cat([output_5[i][1:] for i in range(len(output_5))]).view(tags.shape[0],-1,n_labels)\n",
    "            \n",
    "            tags_without_CLS[tags_without_CLS==-100] = 0 # replace all -100 by 0. This is a requirement for crf. But by using the mask, those values are ignored anyways\n",
    "            \n",
    "            loss = self.crf(emissions=logits_without_CLS, tags=tags_without_CLS, mask=mask_tags_without_CLS)\n",
    "            sequence_of_tags = self.crf.decode(emissions=logits_without_CLS, mask=mask_tags_without_CLS)\n",
    "            \n",
    "            return loss, sequence_of_tags\n",
    "        else:\n",
    "            sequence_of_tags = self.crf.decode(output_5)\n",
    "            return sequence_of_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feeaf062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing BertModel: ['roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['embeddings.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CausalNER()\n",
    "model.to(device)\n",
    "\n",
    "# fine-tune only the task-specific parameters \n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "#     param[:-1].requires_grad = False\n",
    "#     param[-1].requires_grad = True\n",
    "\n",
    "num_training_steps = np.ceil(len(train_dataset)/train_batch_size)*epochs\n",
    "optim = AdamW(model.parameters(), lr=lr, eps=adam_eps)\n",
    "# scheduler with a linearly decreasing learning rate from the initial lr set in the optimizer to 0;\n",
    "# after a warmup period during which it increases linearly from to the initial lr set in the optimizer\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps) \n",
    "\n",
    "\n",
    "## adding weight to the loss function \n",
    "#loss_fn = CrossEntropyLoss(\n",
    "#    weight=torch.tensor(class_weight.to_list()).to(device),\n",
    "#    ignore_index=-100 # ignore subwords/tokens with label -100 \n",
    "#)\n",
    "\n",
    "#loss_fn = CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6d5ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/55 [00:00<?, ?it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A<ipython-input-12-a7b5e9115285>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 1/9 [00:00<00:05,  1.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 3.1688e-02,  1.1323e+00, -1.2428e+00],\n",
      "         [-9.2115e-02,  2.0119e-01, -1.8430e+00],\n",
      "         [ 2.4658e-01, -6.3110e-01,  6.0676e-01],\n",
      "         ...,\n",
      "         [-2.7256e-01, -9.0704e-01, -1.7028e+00],\n",
      "         [-2.8203e-02,  6.6730e-01, -1.1917e+00],\n",
      "         [ 9.8463e-02, -8.7828e-01, -1.2588e+00]],\n",
      "\n",
      "        [[-2.8947e-01, -1.0662e+00, -2.2454e+00],\n",
      "         [ 1.5229e-01, -1.7752e+00, -1.5391e+00],\n",
      "         [-5.4367e-03, -1.4074e+00, -2.1924e+00],\n",
      "         ...,\n",
      "         [ 3.7107e-01, -1.0555e+00, -2.2964e-03],\n",
      "         [-1.2744e-01, -1.4888e+00, -1.5369e+00],\n",
      "         [-4.4083e-02, -1.5029e+00, -1.3485e+00]],\n",
      "\n",
      "        [[-2.2584e-01,  1.2221e+00, -1.2360e+00],\n",
      "         [ 2.7887e-01, -2.7550e+00, -2.1472e+00],\n",
      "         [ 9.3733e-02,  2.1720e+00, -1.5523e+00],\n",
      "         ...,\n",
      "         [-1.8945e-01, -5.6375e-01, -3.0436e+00],\n",
      "         [ 1.6819e-01, -8.9354e-01,  1.1197e-01],\n",
      "         [ 1.4772e-01, -3.0119e-01,  8.3386e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.3825e-01,  4.7025e-02, -1.4212e+00],\n",
      "         [-2.5626e-02, -2.4239e-01,  1.3314e+00],\n",
      "         [-3.4918e-02, -1.4481e+00,  1.4943e+00],\n",
      "         ...,\n",
      "         [ 2.1191e-02, -7.2323e-01, -4.5483e-01],\n",
      "         [ 1.5919e-01, -6.3703e-01,  5.9332e-01],\n",
      "         [ 2.6080e-01, -2.5949e+00,  6.2126e-01]],\n",
      "\n",
      "        [[-9.1194e-02,  1.1751e+00, -3.0208e+00],\n",
      "         [-5.1237e-02, -7.5943e-01, -2.0299e+00],\n",
      "         [ 1.5370e-01,  4.8134e-01,  3.4506e-01],\n",
      "         ...,\n",
      "         [ 2.8641e-01, -2.2318e+00,  1.8938e+00],\n",
      "         [-2.6492e-01,  7.7779e-01, -6.5346e-01],\n",
      "         [-2.0533e-01, -2.0667e+00,  1.0204e+00]],\n",
      "\n",
      "        [[-2.3527e-01,  1.4277e-01, -8.6065e-01],\n",
      "         [-3.4072e-02,  6.6798e-01,  1.5453e+00],\n",
      "         [ 9.6750e-02, -6.0937e-01, -6.0017e-01],\n",
      "         ...,\n",
      "         [-1.6524e-01, -1.4100e+00,  3.6631e-02],\n",
      "         [-2.7520e-01,  1.2213e+00, -1.5643e+00],\n",
      "         [-2.2744e-01,  8.5066e-01,  5.4378e-01]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-250.2411, grad_fn=<SumBackward0>)\n",
      "loss: tensor(250.2411, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (214,)\n",
      "type(pred): <class 'list'> \t pred: 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 2/9 [00:01<00:04,  1.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-1.5659e-01, -8.3264e-01, -1.4897e+00],\n",
      "         [ 9.4517e-02,  1.4556e+00, -2.5718e+00],\n",
      "         [ 4.1358e-01, -1.1324e+00,  3.2143e-01],\n",
      "         ...,\n",
      "         [-9.5965e-02, -2.0463e+00,  2.2768e+00],\n",
      "         [ 4.9940e-04, -7.3650e-01,  7.0503e-01],\n",
      "         [-1.9877e-01, -3.2915e+00, -1.6557e+00]],\n",
      "\n",
      "        [[-2.7292e-01,  7.1966e-01, -1.3775e+00],\n",
      "         [-1.4219e-01, -1.4855e+00, -1.8994e+00],\n",
      "         [-1.9337e-01, -1.4460e+00, -1.6227e+00],\n",
      "         ...,\n",
      "         [ 2.1438e-01, -1.0373e+00,  1.9979e+00],\n",
      "         [-9.1732e-02,  1.2342e+00,  4.3663e-01],\n",
      "         [ 4.3413e-02, -8.7657e-01,  2.3486e+00]],\n",
      "\n",
      "        [[-1.5766e-01,  7.4259e-01, -3.6344e+00],\n",
      "         [-1.5118e-01, -1.5837e+00,  1.2047e+00],\n",
      "         [ 1.9540e-01, -5.7568e-01, -1.4947e+00],\n",
      "         ...,\n",
      "         [-3.6083e-01, -8.0543e-01, -3.2209e-01],\n",
      "         [-2.6438e-01, -1.8469e+00,  2.3069e+00],\n",
      "         [ 4.8551e-02, -2.4643e+00,  1.8674e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6454e-01,  3.0230e-01, -1.8732e+00],\n",
      "         [ 1.4847e-03,  1.3433e+00, -1.0877e+00],\n",
      "         [ 9.1138e-03, -1.2153e-01, -1.5880e-01],\n",
      "         ...,\n",
      "         [ 4.6606e-02, -3.0559e+00,  2.5129e-01],\n",
      "         [-6.1657e-02, -3.1660e-01,  9.6884e-01],\n",
      "         [-8.9894e-02, -1.7154e+00,  1.2023e-01]],\n",
      "\n",
      "        [[-2.6548e-01,  1.6112e-01, -3.7708e+00],\n",
      "         [ 7.2371e-02,  1.9835e+00, -1.1897e+00],\n",
      "         [ 1.3255e-01, -5.5372e-01,  1.7197e+00],\n",
      "         ...,\n",
      "         [ 2.4176e-01,  4.6274e-01,  2.5873e-01],\n",
      "         [ 3.3711e-02,  4.4730e-01,  1.1361e-02],\n",
      "         [-2.0042e-01, -3.3968e-01,  2.0590e+00]],\n",
      "\n",
      "        [[-3.5934e-01, -1.8211e+00, -4.8310e-02],\n",
      "         [ 1.9257e-01,  3.6789e-01, -8.7205e-01],\n",
      "         [ 3.3580e-01,  6.3523e-02, -1.3193e+00],\n",
      "         ...,\n",
      "         [-1.6198e-01, -1.5221e+00,  1.0263e+00],\n",
      "         [ 2.5542e-01, -1.8097e+00, -3.1423e-02],\n",
      "         [-1.6595e-01,  5.0153e-01, -8.1516e-01]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-219.5137, grad_fn=<SumBackward0>)\n",
      "loss: tensor(219.5137, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (185,)\n",
      "type(pred): <class 'list'> \t pred: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 3/9 [00:02<00:04,  1.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 2.3177e-01, -1.5627e+00, -1.9007e+00],\n",
      "         [-3.8122e-02,  3.3159e-01, -3.7635e-01],\n",
      "         [-1.0711e-01,  1.8681e+00, -2.1561e+00],\n",
      "         ...,\n",
      "         [ 1.1428e-01, -2.7211e+00,  3.8584e-01],\n",
      "         [ 2.6234e-02,  1.3459e+00, -9.8879e-01],\n",
      "         [ 2.5410e-03,  6.9595e-01,  2.3998e-01]],\n",
      "\n",
      "        [[-8.3244e-02,  2.6950e-02, -1.8695e+00],\n",
      "         [-1.1916e-01, -5.9731e-01, -4.2394e-01],\n",
      "         [-4.7130e-02, -3.9399e-01, -2.0570e+00],\n",
      "         ...,\n",
      "         [-2.3525e-01, -1.7073e+00,  5.2792e-01],\n",
      "         [-1.1944e-02,  1.2459e+00, -3.7864e+00],\n",
      "         [ 9.8840e-02, -2.9936e-02,  2.6172e-01]],\n",
      "\n",
      "        [[-4.9339e-03,  3.8179e-01, -2.0196e+00],\n",
      "         [-5.0515e-02, -5.4086e-01, -1.3208e+00],\n",
      "         [ 1.0959e-02,  5.0807e-01, -1.9956e+00],\n",
      "         ...,\n",
      "         [ 1.4729e-01, -3.0589e+00, -7.2558e-01],\n",
      "         [ 2.3552e-02, -9.3664e-01,  1.2051e+00],\n",
      "         [ 2.5567e-03, -1.5921e+00, -2.4942e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7278e-01,  1.3504e+00, -2.1232e+00],\n",
      "         [ 1.0732e-03, -2.1064e+00, -6.1607e-02],\n",
      "         [ 1.4729e-01, -5.2596e-02,  6.9573e-01],\n",
      "         ...,\n",
      "         [ 1.8035e-01, -1.3142e+00, -4.6888e-01],\n",
      "         [ 4.9261e-01, -2.5589e+00, -2.0989e+00],\n",
      "         [-1.1147e-01, -1.2621e+00,  9.5783e-01]],\n",
      "\n",
      "        [[-2.4658e-01, -1.7429e+00,  3.3041e+00],\n",
      "         [ 2.6937e-02, -1.7335e+00, -1.5220e+00],\n",
      "         [-8.5659e-02, -3.1111e-02, -1.9026e+00],\n",
      "         ...,\n",
      "         [ 6.6038e-02, -1.7276e+00,  1.1768e+00],\n",
      "         [-7.5974e-02,  1.2460e+00, -1.1361e-01],\n",
      "         [-2.5280e-01, -1.5184e+00,  2.5439e+00]],\n",
      "\n",
      "        [[-6.4747e-02,  1.0119e+00, -7.8078e-01],\n",
      "         [-9.0922e-02,  5.1875e-01,  1.1689e+00],\n",
      "         [ 2.9088e-01, -1.2744e+00,  1.6116e+00],\n",
      "         ...,\n",
      "         [ 1.8810e-01, -3.2963e+00,  1.3559e+00],\n",
      "         [ 5.1606e-01,  1.1230e+00, -1.8670e+00],\n",
      "         [-8.7532e-02, -2.5724e-01,  1.7524e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-209.6558, grad_fn=<SumBackward0>)\n",
      "loss: tensor(209.6558, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (189,)\n",
      "type(pred): <class 'list'> \t pred: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 4/9 [00:02<00:03,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-2.9489e-02, -9.2304e-01, -2.2518e+00],\n",
      "         [ 1.2461e-01, -5.9648e-01, -1.9624e+00],\n",
      "         [-1.9970e-01, -1.3918e-01, -1.7362e+00],\n",
      "         ...,\n",
      "         [-8.8661e-02, -9.5419e-01,  1.5568e+00],\n",
      "         [-1.1375e-01,  1.6186e-01, -2.5925e+00],\n",
      "         [-5.3972e-02, -1.0139e+00, -1.4005e+00]],\n",
      "\n",
      "        [[-5.4652e-02,  1.6708e+00, -1.6361e+00],\n",
      "         [ 1.0618e-01,  9.1220e-01, -1.9565e+00],\n",
      "         [ 1.2838e-01, -1.7642e-01, -1.3367e+00],\n",
      "         ...,\n",
      "         [-1.2301e-01, -2.4347e+00,  1.2786e+00],\n",
      "         [ 1.7760e-03,  1.1753e+00, -9.4898e-01],\n",
      "         [-1.5898e-01, -8.5475e-01, -2.1002e+00]],\n",
      "\n",
      "        [[-6.6534e-02,  1.8460e-01, -2.1405e+00],\n",
      "         [ 2.0051e-01, -1.6388e-01, -3.2084e+00],\n",
      "         [-4.0383e-02, -2.6791e+00,  3.0865e-01],\n",
      "         ...,\n",
      "         [-3.6449e-01, -2.7235e+00,  1.2663e+00],\n",
      "         [-9.9849e-02, -1.2694e+00, -1.1339e+00],\n",
      "         [ 1.0140e-01,  1.1524e-01,  2.4329e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.0429e-02,  1.1168e+00, -1.8604e+00],\n",
      "         [ 1.0874e-01, -4.0305e+00, -2.5691e+00],\n",
      "         [ 3.5865e-01,  1.4482e+00, -7.2933e-01],\n",
      "         ...,\n",
      "         [-6.5191e-03, -4.3756e-01,  3.8626e-01],\n",
      "         [ 6.0527e-03,  1.0631e+00,  1.9944e+00],\n",
      "         [-8.8243e-03, -3.3287e-01, -1.5724e+00]],\n",
      "\n",
      "        [[ 3.2463e-02, -8.4644e-01, -2.4363e+00],\n",
      "         [-1.9615e-01, -1.8466e-01, -2.2325e+00],\n",
      "         [ 2.4054e-01, -5.7014e-01, -3.9994e-01],\n",
      "         ...,\n",
      "         [-1.3692e-01, -2.1032e+00, -3.1633e-01],\n",
      "         [ 2.8231e-01, -1.2713e+00,  8.2462e-01],\n",
      "         [-2.0402e-01, -3.7776e+00, -2.1160e-01]],\n",
      "\n",
      "        [[-4.3430e-02, -2.3294e-01, -2.5228e+00],\n",
      "         [-1.9901e-02, -5.6109e-01,  4.6923e-01],\n",
      "         [-6.4605e-02, -1.3097e+00,  1.2252e-01],\n",
      "         ...,\n",
      "         [-8.9301e-02, -2.4040e+00, -8.1809e-01],\n",
      "         [ 8.7539e-03, -5.4861e-01,  2.1145e-02],\n",
      "         [-1.8392e-01, -7.4022e-01,  1.0553e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-170.6311, grad_fn=<SumBackward0>)\n",
      "loss: tensor(170.6311, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (145,)\n",
      "type(pred): <class 'list'> \t pred: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 5/9 [00:03<00:02,  1.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-1.8230e-04,  1.5339e-01, -2.6521e+00],\n",
      "         [-3.8170e-04, -1.7048e+00, -5.5682e-01],\n",
      "         [ 2.4457e-01, -3.9877e+00, -1.7093e+00],\n",
      "         ...,\n",
      "         [-1.0725e-01, -1.8577e+00,  1.1845e+00],\n",
      "         [-1.0240e-01, -1.5178e+00,  1.3154e+00],\n",
      "         [-3.4446e-01, -1.4928e+00, -1.2490e-01]],\n",
      "\n",
      "        [[ 7.2935e-02, -6.6152e-01, -5.9370e-01],\n",
      "         [ 1.3198e-02, -2.7343e-02, -3.5457e-01],\n",
      "         [ 1.1275e-01,  5.9060e-01, -9.3777e-01],\n",
      "         ...,\n",
      "         [-1.4918e-01, -2.2495e+00, -1.3311e+00],\n",
      "         [ 1.8747e-02, -1.1811e+00,  9.9304e-01],\n",
      "         [-1.4327e-01, -2.0833e+00, -1.3147e+00]],\n",
      "\n",
      "        [[-9.7404e-02,  5.0761e-02, -1.0401e+00],\n",
      "         [ 6.5127e-03, -8.0430e-01, -1.3585e+00],\n",
      "         [ 9.2427e-02, -1.1337e-01,  2.1303e-01],\n",
      "         ...,\n",
      "         [-5.4490e-02, -1.5443e+00,  6.7442e-01],\n",
      "         [ 1.6074e-01, -1.1216e+00, -1.5514e+00],\n",
      "         [-3.0058e-01, -1.9021e+00, -9.2725e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.9723e-02, -1.7004e-01, -5.4623e+00],\n",
      "         [ 9.0678e-02, -3.6468e-01,  6.5594e-01],\n",
      "         [ 1.3151e-01, -1.6635e+00, -2.1782e+00],\n",
      "         ...,\n",
      "         [ 3.5382e-01, -1.0936e-02,  3.8882e-01],\n",
      "         [ 5.8905e-02, -2.5839e-01, -9.0618e-01],\n",
      "         [-1.2866e-01, -7.2597e-01, -7.6105e-01]],\n",
      "\n",
      "        [[ 3.1132e-01,  1.0663e+00, -1.8045e-01],\n",
      "         [ 3.7360e-02, -2.1924e+00, -1.0071e+00],\n",
      "         [-1.1204e-01, -3.7702e-01,  1.5537e+00],\n",
      "         ...,\n",
      "         [-2.0453e-01, -1.5602e+00,  5.1066e-01],\n",
      "         [ 4.6034e-02,  4.3089e-01,  4.1627e-01],\n",
      "         [-4.5718e-02,  9.7108e-01, -2.1015e+00]],\n",
      "\n",
      "        [[-2.2427e-01, -3.5648e-02, -3.5808e+00],\n",
      "         [ 4.3144e-02,  1.1570e+00, -5.0082e-01],\n",
      "         [ 4.0308e-02, -4.4238e-01, -1.1671e+00],\n",
      "         ...,\n",
      "         [-5.5405e-02, -1.3626e+00, -1.3013e+00],\n",
      "         [ 2.3943e-02, -1.6413e+00, -6.2416e-01],\n",
      "         [-2.5665e-01, -2.5079e+00, -3.7775e-01]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-170.8393, grad_fn=<SumBackward0>)\n",
      "loss: tensor(170.8393, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (140,)\n",
      "type(pred): <class 'list'> \t pred: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 6/9 [00:03<00:01,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.0921, -1.0202, -0.9742],\n",
      "         [-0.1317,  0.3678, -1.1130],\n",
      "         [ 0.0702, -2.3998, -2.1868],\n",
      "         ...,\n",
      "         [-0.0217, -0.3071,  0.2012],\n",
      "         [-0.2137, -0.8210, -0.1894],\n",
      "         [ 0.2128,  0.0371,  0.8520]],\n",
      "\n",
      "        [[ 0.0559,  0.4186, -0.1078],\n",
      "         [-0.1199,  0.6473, -0.6441],\n",
      "         [-0.2089,  0.8640,  0.1759],\n",
      "         ...,\n",
      "         [ 0.0711, -3.4383, -0.6331],\n",
      "         [-0.0120,  1.2040,  0.1901],\n",
      "         [ 0.1297, -2.8550,  2.7507]],\n",
      "\n",
      "        [[-0.3912, -2.1923, -0.4548],\n",
      "         [ 0.0061, -0.5332,  2.7440],\n",
      "         [-0.0539, -1.9076, -2.6684],\n",
      "         ...,\n",
      "         [-0.0710,  0.0170,  1.8617],\n",
      "         [-0.1679, -0.8010, -0.6439],\n",
      "         [ 0.0823,  0.0877, -0.8053]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0150,  1.4905, -1.7436],\n",
      "         [ 0.2336, -0.3289,  0.7652],\n",
      "         [-0.1072,  0.9710, -2.3145],\n",
      "         ...,\n",
      "         [-0.0416,  0.6985,  0.2951],\n",
      "         [-0.2965, -2.2319,  0.0916],\n",
      "         [-0.0841,  1.0082, -2.0693]],\n",
      "\n",
      "        [[ 0.1178,  0.4781, -2.2137],\n",
      "         [ 0.0317, -1.8424, -0.9438],\n",
      "         [ 0.0543, -2.5981, -0.3902],\n",
      "         ...,\n",
      "         [-0.1157, -1.2888,  0.7589],\n",
      "         [-0.1109, -1.4366, -0.6169],\n",
      "         [ 0.0635, -0.5092, -2.0495]],\n",
      "\n",
      "        [[-0.1431,  0.1412, -2.8375],\n",
      "         [-0.0815, -1.3935, -1.0462],\n",
      "         [ 0.2894,  0.2086,  1.9097],\n",
      "         ...,\n",
      "         [ 0.0297, -2.2071,  1.1648],\n",
      "         [ 0.2694,  1.0050, -0.9889],\n",
      "         [ 0.0753, -1.1710, -1.8914]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-203.8499, grad_fn=<SumBackward0>)\n",
      "loss: tensor(203.8499, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (178,)\n",
      "type(pred): <class 'list'> \t pred: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 7/9 [00:04<00:01,  1.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-2.4195e-01, -9.6475e-01,  1.1806e+00],\n",
      "         [-1.4692e-01, -8.6783e-02, -1.5882e+00],\n",
      "         [ 1.8072e-01,  1.0580e-01,  1.5735e+00],\n",
      "         ...,\n",
      "         [ 1.9748e-01, -2.4769e+00, -6.0015e-01],\n",
      "         [-3.9520e-02,  4.8684e-01,  1.6533e+00],\n",
      "         [-9.4815e-02, -1.1614e+00, -2.1497e+00]],\n",
      "\n",
      "        [[ 2.6242e-01, -6.0767e-01, -1.8347e+00],\n",
      "         [ 1.6960e-01,  3.0886e-01, -3.2381e-01],\n",
      "         [-1.0445e-01, -1.8661e-01, -2.6190e+00],\n",
      "         ...,\n",
      "         [ 1.9260e-01, -2.0190e+00,  4.5864e-01],\n",
      "         [-5.9340e-02, -1.2880e+00, -2.1294e+00],\n",
      "         [-3.5399e-03, -1.7825e+00, -2.8489e+00]],\n",
      "\n",
      "        [[-1.1070e-02, -2.2511e+00, -2.3229e+00],\n",
      "         [ 8.2175e-02, -1.8149e+00, -2.0611e+00],\n",
      "         [ 1.0866e-01, -4.5588e-01, -8.3085e-01],\n",
      "         ...,\n",
      "         [ 1.0074e-01, -2.6767e+00,  1.0554e+00],\n",
      "         [-1.8087e-01, -4.7329e-02,  6.3185e-02],\n",
      "         [-4.4125e-01, -5.0966e-01, -4.9372e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.5730e-03, -2.8188e-01, -2.5577e+00],\n",
      "         [ 2.6370e-03, -1.8305e+00, -1.1008e+00],\n",
      "         [ 1.4237e-01,  1.8776e-02, -1.3857e+00],\n",
      "         ...,\n",
      "         [-8.8276e-02, -1.5644e+00,  3.7421e-01],\n",
      "         [ 9.4224e-02,  1.3412e+00, -1.2314e+00],\n",
      "         [-2.4001e-01, -1.4330e+00, -1.6590e+00]],\n",
      "\n",
      "        [[-1.8646e-01,  1.4117e+00, -3.2376e+00],\n",
      "         [ 2.3747e-01, -1.7777e+00, -2.5184e+00],\n",
      "         [ 1.0962e-01, -9.2922e-01,  5.5950e-01],\n",
      "         ...,\n",
      "         [-5.5568e-02, -8.5136e-02,  6.0927e-01],\n",
      "         [ 3.5597e-02, -7.8393e-01, -1.6227e+00],\n",
      "         [-9.9994e-02, -1.9354e+00, -3.5865e-01]],\n",
      "\n",
      "        [[-1.1298e-01,  8.2691e-01, -1.9111e+00],\n",
      "         [ 4.4131e-02, -2.6956e+00, -7.8046e-01],\n",
      "         [ 3.2009e-01,  2.3555e+00, -1.4361e+00],\n",
      "         ...,\n",
      "         [-8.8645e-02,  1.1639e-01, -1.1999e+00],\n",
      "         [ 2.3930e-02, -2.9474e+00, -1.2499e-01],\n",
      "         [ 9.5662e-02, -5.7250e-02, -1.5790e-01]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-196.6244, grad_fn=<SumBackward0>)\n",
      "loss: tensor(196.6244, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (186,)\n",
      "type(pred): <class 'list'> \t pred: 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 8/9 [00:05<00:00,  1.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.1603, -0.9000, -2.7521],\n",
      "         [-0.1210, -0.5594, -1.8801],\n",
      "         [ 0.2918, -0.8608, -2.4318],\n",
      "         ...,\n",
      "         [-0.2268,  0.2180,  3.8067],\n",
      "         [ 0.3154, -1.6499, -1.3634],\n",
      "         [ 0.0852,  0.1492,  1.6858]],\n",
      "\n",
      "        [[-0.1978,  1.5022, -2.9118],\n",
      "         [-0.1905, -2.6112, -2.2710],\n",
      "         [-0.0708, -0.5629, -0.3005],\n",
      "         ...,\n",
      "         [-0.1068, -0.3127, -0.1032],\n",
      "         [ 0.0586,  0.1267, -1.2113],\n",
      "         [ 0.1497, -1.1471, -0.9444]],\n",
      "\n",
      "        [[-0.0766, -0.2237, -2.3981],\n",
      "         [ 0.0537, -1.9635, -0.5263],\n",
      "         [ 0.2149, -2.1442, -0.9375],\n",
      "         ...,\n",
      "         [ 0.2796, -0.7420,  2.5404],\n",
      "         [-0.1302, -2.4607, -0.9579],\n",
      "         [-0.1819, -2.2352, -1.8790]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1121, -0.2881, -1.5680],\n",
      "         [ 0.3402, -1.6424,  1.3853],\n",
      "         [ 0.0883, -0.9487,  0.9417],\n",
      "         ...,\n",
      "         [ 0.1603, -1.6442, -0.2541],\n",
      "         [ 0.1332,  0.5219, -0.7566],\n",
      "         [ 0.1763, -1.0529,  0.7965]],\n",
      "\n",
      "        [[-0.1324, -0.2290, -3.5016],\n",
      "         [-0.3059, -0.3108, -0.1268],\n",
      "         [ 0.0167, -0.4070, -0.2511],\n",
      "         ...,\n",
      "         [-0.2135, -2.3806, -0.4411],\n",
      "         [-0.0270,  0.2505,  0.5622],\n",
      "         [ 0.0511,  0.1586, -1.7765]],\n",
      "\n",
      "        [[-0.1396, -1.7635, -4.8001],\n",
      "         [-0.1409, -1.5332,  0.2461],\n",
      "         [ 0.1449, -0.2849, -2.1267],\n",
      "         ...,\n",
      "         [-0.0700, -1.2530,  0.7131],\n",
      "         [ 0.0356, -0.4630,  0.2024],\n",
      "         [-0.0492, -2.0146, -3.1873]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-195.4108, grad_fn=<SumBackward0>)\n",
      "loss: tensor(195.4108, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (172,)\n",
      "type(pred): <class 'list'> \t pred: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.49it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-3.4367e-01, -7.2795e-01, -2.2530e+00],\n",
      "         [ 3.6332e-02, -2.3267e+00, -1.4296e+00],\n",
      "         [ 2.0852e-01,  6.2073e-01, -3.7288e-01],\n",
      "         ...,\n",
      "         [-1.9462e-01, -3.3172e-01,  6.5490e-01],\n",
      "         [ 2.7683e-01,  7.6436e-01,  9.3776e-01],\n",
      "         [-1.3885e-01, -7.4581e-01, -2.4996e+00]],\n",
      "\n",
      "        [[-2.4181e-02,  2.6752e+00, -1.6768e+00],\n",
      "         [-2.9543e-01,  1.3033e-01, -2.6125e+00],\n",
      "         [ 1.2868e-02, -9.7043e-01, -1.6354e+00],\n",
      "         ...,\n",
      "         [ 1.3055e-01, -1.8210e+00, -6.2356e-01],\n",
      "         [-4.0339e-02,  7.5131e-02, -5.6935e-01],\n",
      "         [ 3.4765e-02, -4.7727e-01, -2.7210e+00]],\n",
      "\n",
      "        [[ 2.1811e-02, -1.1640e-01, -4.4829e+00],\n",
      "         [ 2.1569e-01, -1.8322e+00,  1.3124e+00],\n",
      "         [ 2.6129e-01, -1.9452e+00, -1.4751e+00],\n",
      "         ...,\n",
      "         [-1.9404e-02, -1.9656e+00, -2.1924e+00],\n",
      "         [ 1.5209e-01, -9.0515e-01, -1.5737e+00],\n",
      "         [ 1.4714e-02, -9.3388e-01, -8.2544e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.8836e-01,  3.9913e-01, -2.7020e+00],\n",
      "         [-3.1978e-01, -2.6395e+00, -1.6602e+00],\n",
      "         [ 2.4417e-01,  1.1083e-02, -3.9895e+00],\n",
      "         ...,\n",
      "         [-2.1382e-01,  4.3649e-01, -6.1833e-03],\n",
      "         [-1.3782e-01, -2.4162e-01, -1.8382e+00],\n",
      "         [ 5.5883e-02, -9.0877e-01,  9.2477e-01]],\n",
      "\n",
      "        [[-5.4573e-02,  1.4912e+00, -3.3020e+00],\n",
      "         [ 3.1612e-01,  5.2702e-01, -8.9443e-01],\n",
      "         [ 1.4437e-01,  5.0625e-01, -3.1643e+00],\n",
      "         ...,\n",
      "         [ 1.8374e-01, -5.1588e-01, -1.4334e+00],\n",
      "         [-6.9153e-02, -3.1637e+00,  4.4038e-02],\n",
      "         [-1.5202e-03,  1.0470e-01,  4.2034e-01]],\n",
      "\n",
      "        [[-2.0559e-01, -5.8399e-02, -3.8792e+00],\n",
      "         [ 6.6681e-02, -6.0254e-01, -3.1252e+00],\n",
      "         [-3.6771e-03,  9.3316e-01, -1.1542e+00],\n",
      "         ...,\n",
      "         [-3.6434e-01, -2.8931e+00, -1.8894e+00],\n",
      "         [-9.7391e-02, -6.8130e-01, -2.6161e+00],\n",
      "         [ 1.8428e-01, -1.1315e+00, -5.6342e-01]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-159.0221, grad_fn=<SumBackward0>)\n",
      "loss: tensor(159.0221, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (162,)\n",
      "type(pred): <class 'list'> \t pred: 162\n",
      "\n",
      "\tTraining Loss: 197.3097907172309\n",
      "\n",
      "\tTraining acc: 0.42639865648507147\n",
      "\n",
      "\tTraining prec: 0.6328035936679167\n",
      "\n",
      "\tTraining rec: 0.42639865648507147\n",
      "\n",
      "\tTraining f1: 0.49420044176098454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[-0.0357, -0.5240, -2.6592],\n",
      "         [-0.0460, -0.9456, -0.7712],\n",
      "         [ 0.0858, -0.8549, -2.0832],\n",
      "         ...,\n",
      "         [-0.0171, -0.0640, -2.0459],\n",
      "         [ 0.0706, -1.2696, -2.3720],\n",
      "         [ 0.1472, -1.6287, -1.4654]],\n",
      "\n",
      "        [[-0.0515, -0.4812, -2.1623],\n",
      "         [-0.0296, -1.1627, -0.9841],\n",
      "         [ 0.0390, -1.1512, -0.8067],\n",
      "         ...,\n",
      "         [-0.0314, -0.1395, -1.4503],\n",
      "         [ 0.0586, -1.2518, -2.0148],\n",
      "         [ 0.1355, -1.5639, -1.0414]],\n",
      "\n",
      "        [[-0.0793, -0.2926, -2.5871],\n",
      "         [-0.0635, -0.6447, -1.2276],\n",
      "         [ 0.0157, -0.0210, -1.0980],\n",
      "         ...,\n",
      "         [-0.0547,  0.0926, -2.0013],\n",
      "         [ 0.0132, -0.9177, -2.5643],\n",
      "         [ 0.1035, -1.4011, -1.6814]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0568, -0.4403, -1.9658],\n",
      "         [-0.0382, -1.2228, -0.7364],\n",
      "         [ 0.0169, -1.0072, -0.6070],\n",
      "         ...,\n",
      "         [-0.0420, -0.1067, -1.3861],\n",
      "         [ 0.0413, -1.1305, -1.8795],\n",
      "         [ 0.1048, -1.5781, -0.9414]],\n",
      "\n",
      "        [[-0.0806, -0.5201, -2.3306],\n",
      "         [-0.0171, -0.8734, -1.6242],\n",
      "         [ 0.0676, -1.2154, -1.6644],\n",
      "         ...,\n",
      "         [-0.0575, -0.0993, -1.6798],\n",
      "         [ 0.0117, -1.2297, -2.1474],\n",
      "         [ 0.0893, -1.5264, -1.2446]],\n",
      "\n",
      "        [[-0.0803, -0.4948, -2.3161],\n",
      "         [-0.0526, -1.1565, -1.1754],\n",
      "         [ 0.0090, -0.9171, -1.0530],\n",
      "         ...,\n",
      "         [-0.0502, -0.0615, -1.7406],\n",
      "         [ 0.0277, -1.2015, -2.1358],\n",
      "         [ 0.0943, -1.5112, -1.2087]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[-0.0825, -0.2885, -2.1126],\n",
      "         [-0.0597, -1.3132, -0.9991],\n",
      "         [ 0.0196, -0.5953, -2.3618],\n",
      "         ...,\n",
      "         [-0.0701,  0.0256, -1.5738],\n",
      "         [ 0.0204, -1.0410, -2.0519],\n",
      "         [ 0.0917, -1.3479, -1.1934]],\n",
      "\n",
      "        [[-0.0593, -0.6370, -2.2415],\n",
      "         [-0.0354, -1.2735, -1.0645],\n",
      "         [ 0.0362, -1.0109, -0.9140],\n",
      "         ...,\n",
      "         [-0.0297, -0.1035, -1.6712],\n",
      "         [ 0.0482, -1.2602, -2.0781],\n",
      "         [ 0.1234, -1.5748, -1.2108]],\n",
      "\n",
      "        [[-0.0491, -0.3955, -2.3514],\n",
      "         [ 0.0557, -0.8915, -1.2771],\n",
      "         [-0.0058, -0.6240, -1.5541],\n",
      "         ...,\n",
      "         [-0.0172,  0.0520, -1.6634],\n",
      "         [ 0.0545, -1.1365, -2.1205],\n",
      "         [ 0.1298, -1.5216, -1.1061]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0902, -0.3929, -2.2526],\n",
      "         [ 0.0075, -1.6491, -1.8501],\n",
      "         [ 0.0240, -1.7011, -1.9952],\n",
      "         ...,\n",
      "         [-0.0738,  0.0238, -1.8524],\n",
      "         [-0.0027, -1.1197, -2.2587],\n",
      "         [ 0.0711, -1.5231, -1.2852]],\n",
      "\n",
      "        [[-0.0749, -0.4565, -2.2298],\n",
      "         [-0.0717, -0.7466, -0.5684],\n",
      "         [ 0.0839,  0.7094, -1.9977],\n",
      "         ...,\n",
      "         [-0.0546, -0.0218, -1.6478],\n",
      "         [ 0.0258, -1.1292, -2.1264],\n",
      "         [ 0.0981, -1.4280, -1.2117]],\n",
      "\n",
      "        [[-0.0799, -0.6762, -2.0581],\n",
      "         [-0.0589, -1.3008, -0.7451],\n",
      "         [ 0.0024, -1.2029, -0.5831],\n",
      "         ...,\n",
      "         [-0.0643, -0.2833, -1.3470],\n",
      "         [ 0.0219, -1.3726, -1.8335],\n",
      "         [ 0.0940, -1.7367, -0.8246]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([2, 52, 3])\n",
      "tensor([[[-7.1888e-02, -7.1540e-01, -2.2732e+00],\n",
      "         [ 1.8174e-01, -1.1189e+00, -1.3727e+00],\n",
      "         [ 1.2167e-01, -1.2622e+00, -2.0568e+00],\n",
      "         [ 3.9053e-02, -1.9606e+00, -7.2530e-01],\n",
      "         [-1.7627e-02, -1.8541e+00, -1.3036e+00],\n",
      "         [-6.7319e-02, -2.5202e+00, -2.6446e+00],\n",
      "         [ 1.2939e-02, -1.7756e+00, -1.2018e+00],\n",
      "         [-5.1207e-02, -1.4651e+00, -2.5603e+00],\n",
      "         [-3.7260e-02, -1.6765e+00, -3.1978e+00],\n",
      "         [ 7.3126e-02, -2.7486e+00, -2.5244e+00],\n",
      "         [ 1.1048e-01, -1.6648e+00, -3.7288e-01],\n",
      "         [-5.0036e-03, -1.7785e+00, -1.4286e+00],\n",
      "         [ 7.0309e-03, -1.3929e+00, -1.8457e+00],\n",
      "         [ 3.8526e-02, -1.9742e+00, -2.4681e+00],\n",
      "         [-4.0750e-02, -8.2370e-01, -3.2457e-01],\n",
      "         [ 8.3919e-02, -1.6012e+00, -7.6461e-01],\n",
      "         [ 1.7383e-01, -1.6850e+00, -2.2974e+00],\n",
      "         [-1.9895e-02, -7.5924e-01, -2.9229e+00],\n",
      "         [ 5.2209e-02, -9.6295e-01, -4.0319e-01],\n",
      "         [-1.1545e-01, -1.7964e+00, -1.1181e+00],\n",
      "         [ 8.9544e-02, -1.7372e+00, -1.6658e+00],\n",
      "         [ 1.5136e-02, -1.8114e+00, -1.1984e+00],\n",
      "         [-7.4382e-02, -8.7569e-01, -9.3217e-02],\n",
      "         [-6.0397e-02, -8.4537e-01, -1.5984e+00],\n",
      "         [-9.0863e-02, -2.0104e+00, -1.1861e+00],\n",
      "         [-1.5419e-01, -1.4955e+00, -7.5439e-01],\n",
      "         [-4.6792e-02, -1.2477e+00, -1.8069e+00],\n",
      "         [ 2.9401e-02, -1.8839e-01, -2.6146e+00],\n",
      "         [-2.0361e-03, -9.5095e-01, -7.5813e-01],\n",
      "         [-5.4335e-03, -1.0686e+00, -1.1547e+00],\n",
      "         [ 6.1815e-02, -1.1499e+00, -2.7781e+00],\n",
      "         [ 9.0687e-03, -2.1211e-01, -1.7413e+00],\n",
      "         [-1.6505e-02, -4.6268e-01, -1.8313e+00],\n",
      "         [ 4.6979e-02, -1.1688e+00, -1.8272e+00],\n",
      "         [ 1.3729e-02, -6.7202e-01, -2.9079e-01],\n",
      "         [ 8.6488e-02, -1.4183e+00, -1.8868e+00],\n",
      "         [-5.2860e-02, -7.4990e-01, -1.4623e+00],\n",
      "         [ 5.3756e-02, -1.7448e+00, -1.1893e+00],\n",
      "         [ 2.8620e-02, -1.6174e+00, -1.8066e+00],\n",
      "         [-4.3793e-03, -4.8742e-01, -1.0724e+00],\n",
      "         [ 7.4171e-02, -2.1001e+00, -1.5699e+00],\n",
      "         [ 1.1106e-01, -1.6885e+00, -5.1901e-01],\n",
      "         [ 2.3372e-01, -1.3546e+00, -3.8533e-01],\n",
      "         [-2.9152e-02, -1.7629e+00, -3.4190e-01],\n",
      "         [ 1.7111e-01, -1.6543e+00, -3.0897e-01],\n",
      "         [ 2.2802e-02, -2.2567e+00, -6.8645e-01],\n",
      "         [-5.9741e-02, -1.5420e+00,  2.8020e-02],\n",
      "         [-2.6326e-03, -1.3077e+00, -1.0015e+00],\n",
      "         [ 2.3647e-03, -1.7554e+00, -3.9576e-01],\n",
      "         [-3.7170e-02, -3.4983e-01, -1.5636e+00],\n",
      "         [ 5.5260e-02, -1.3013e+00, -2.0650e+00],\n",
      "         [ 1.1400e-01, -1.8189e+00, -1.0786e+00]],\n",
      "\n",
      "        [[-8.9767e-02, -6.1414e-01, -2.0996e+00],\n",
      "         [-2.3975e-02, -5.5866e-01, -8.2900e-01],\n",
      "         [ 1.7820e-01, -8.6176e-01, -1.0109e+00],\n",
      "         [ 3.2544e-02, -1.2907e+00, -1.6174e+00],\n",
      "         [ 6.2729e-02, -6.6830e-01, -1.4447e+00],\n",
      "         [-7.1120e-02, -1.5470e+00, -1.1262e+00],\n",
      "         [-4.8106e-02, -5.7616e-01, -1.3945e+00],\n",
      "         [-1.3233e-02, -7.7866e-01, -2.1191e+00],\n",
      "         [-4.6994e-03, -2.1997e+00, -3.9977e+00],\n",
      "         [ 1.4313e-03, -2.4516e+00, -8.8925e-01],\n",
      "         [ 1.5009e-01, -1.0041e+00, -1.6074e+00],\n",
      "         [-8.2098e-02, -8.2480e-01, -4.4672e-01],\n",
      "         [ 5.8243e-02, -1.3301e+00,  1.8998e-01],\n",
      "         [ 8.2091e-02, -9.1027e-01, -1.7924e+00],\n",
      "         [ 2.3771e-02, -5.1755e-01, -1.5513e-01],\n",
      "         [ 5.3655e-02, -1.7683e-01, -1.6707e+00],\n",
      "         [ 1.4962e-01, -2.0175e+00, -1.1103e-01],\n",
      "         [-5.7922e-02, -1.5354e+00, -2.0800e+00],\n",
      "         [ 6.3821e-02, -3.5791e-01, -1.0991e+00],\n",
      "         [-1.1152e-01, -1.4253e+00, -4.7878e-01],\n",
      "         [ 6.0816e-02, -4.9787e-01, -9.2733e-01],\n",
      "         [-6.5083e-02, -1.9052e+00, -5.5752e-01],\n",
      "         [ 4.5086e-02, -5.4357e-01, -4.1309e-01],\n",
      "         [-2.3556e-02, -7.3295e-01, -1.2724e+00],\n",
      "         [ 1.1405e-02, -1.5757e+00, -7.2051e-01],\n",
      "         [-1.1140e-01, -1.2130e+00, -2.4528e+00],\n",
      "         [-5.8685e-02, -1.4120e+00, -1.3850e+00],\n",
      "         [ 3.6943e-03, -2.6809e-01, -1.6083e+00],\n",
      "         [-8.7127e-03, -6.3571e-01, -7.3225e-01],\n",
      "         [-9.6667e-02, -3.1760e-01, -1.1376e+00],\n",
      "         [-1.2256e-01, -1.0419e+00, -2.0748e+00],\n",
      "         [-3.2592e-02, -5.9739e-01, -1.9240e+00],\n",
      "         [-2.8671e-02, -6.5900e-01, -3.0910e-01],\n",
      "         [ 6.3652e-02, -9.2887e-01, -1.6757e+00],\n",
      "         [-2.6501e-03, -8.0283e-01,  9.7061e-02],\n",
      "         [-2.6737e-02, -1.1945e+00, -1.0923e+00],\n",
      "         [ 3.7976e-02, -7.0554e-01, -4.3994e-01],\n",
      "         [ 4.0770e-02, -1.5481e+00, -1.1614e+00],\n",
      "         [ 3.2652e-03, -1.4751e+00, -1.7093e+00],\n",
      "         [-3.2728e-02, -2.3844e-01, -8.4782e-01],\n",
      "         [ 5.5448e-02, -1.8123e+00, -1.3655e+00],\n",
      "         [ 8.5421e-02, -1.4626e+00, -5.9292e-01],\n",
      "         [ 2.0176e-01, -1.1874e+00, -1.5651e-01],\n",
      "         [-4.3098e-02, -1.6746e+00, -2.4080e-01],\n",
      "         [ 1.7393e-01, -1.5989e+00, -1.4447e-01],\n",
      "         [ 2.7401e-03, -1.9928e+00, -6.0577e-01],\n",
      "         [-7.5635e-02, -1.2659e+00,  4.2992e-02],\n",
      "         [-2.8699e-02, -1.0630e+00, -9.5723e-01],\n",
      "         [-1.2867e-02, -1.5146e+00, -2.6379e-01],\n",
      "         [-4.0664e-02, -6.1224e-02, -1.4629e+00],\n",
      "         [ 1.8627e-02, -1.1608e+00, -1.9353e+00],\n",
      "         [ 1.0578e-01, -1.5942e+00, -9.4805e-01]]])\n",
      "\n",
      "\tValidation Loss: 106.33373641967773\n",
      "\n",
      "\tValidation acc: 0.7866137967585937\n",
      "\n",
      "\tValidation prec: 0.7047049832709312\n",
      "\n",
      "\tValidation rec: 0.7866137967585937\n",
      "\n",
      "\tValidation f1: 0.7416551138052054\n",
      "Validation loss decreased (inf --> 106.333736).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   2%|▏         | 1/55 [00:08<07:20,  8.17s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 2 ======================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 1/9 [00:00<00:07,  1.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 8.4146e-02, -1.1236e+00, -4.6082e+00],\n",
      "         [ 2.2214e-01, -1.0488e-01, -2.8118e+00],\n",
      "         [-1.9893e-01, -1.2342e+00, -1.3614e+00],\n",
      "         ...,\n",
      "         [ 1.0926e-01, -1.3828e+00, -3.2274e-01],\n",
      "         [-6.5724e-03,  4.2385e-02,  2.2221e-01],\n",
      "         [-3.4821e-01, -6.8840e-01, -1.1216e+00]],\n",
      "\n",
      "        [[-2.1612e-01,  5.3609e-01, -2.6043e+00],\n",
      "         [-2.7964e-01, -3.5163e-02, -1.6349e+00],\n",
      "         [-1.8337e-01,  3.3622e-01, -1.2698e+00],\n",
      "         ...,\n",
      "         [-2.0012e-02, -6.1452e-01, -1.1823e+00],\n",
      "         [-1.8692e-01, -1.6777e-01, -1.6572e+00],\n",
      "         [ 8.1837e-02, -1.5592e-01, -7.9031e-01]],\n",
      "\n",
      "        [[-8.3673e-03,  5.8532e-01, -2.6972e+00],\n",
      "         [-3.1361e-01, -2.6137e-01, -2.0893e+00],\n",
      "         [-1.6057e-02, -2.0851e+00, -3.0942e-02],\n",
      "         ...,\n",
      "         [-1.2095e-01, -2.1190e-01, -2.1847e+00],\n",
      "         [-1.3648e-02,  5.0390e-01, -9.6361e-01],\n",
      "         [-3.3128e-02, -2.4428e+00, -2.7919e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.0272e-02,  1.5253e+00, -1.2563e+00],\n",
      "         [ 4.4929e-03, -6.8791e-01, -6.5993e-01],\n",
      "         [ 1.6587e-01, -2.0549e-01, -4.2438e-01],\n",
      "         ...,\n",
      "         [-1.1734e-01, -1.7185e+00,  1.7987e-01],\n",
      "         [ 3.4698e-01,  8.1739e-01,  1.0465e+00],\n",
      "         [ 5.6361e-02, -1.0675e+00, -1.4457e+00]],\n",
      "\n",
      "        [[ 2.3119e-02,  2.1431e-01, -4.1648e+00],\n",
      "         [-5.8387e-02, -5.8104e-01, -5.3577e+00],\n",
      "         [ 1.1317e-01, -8.3581e-01, -1.3316e+00],\n",
      "         ...,\n",
      "         [ 3.9127e-01,  4.8269e-02,  9.5088e-01],\n",
      "         [ 1.0419e-01, -1.0266e+00,  1.0991e+00],\n",
      "         [-1.4697e-01,  5.1787e-02,  3.6482e-01]],\n",
      "\n",
      "        [[-2.0354e-01, -2.7909e+00, -2.5615e+00],\n",
      "         [ 4.8041e-02, -2.3999e+00, -7.1285e-01],\n",
      "         [ 1.9920e-01,  3.9507e-01,  6.0660e-01],\n",
      "         ...,\n",
      "         [-3.4668e-01, -1.2631e+00,  4.1819e-01],\n",
      "         [-1.1495e-01,  8.4423e-02, -5.5626e-01],\n",
      "         [-1.5696e-01, -1.2749e+00, -8.9925e-01]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-240.9053, grad_fn=<SumBackward0>)\n",
      "loss: tensor(240.9053, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (238,)\n",
      "type(pred): <class 'list'> \t pred: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 2/9 [00:01<00:06,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 0.0731,  0.5620, -2.8750],\n",
      "         [-0.2833, -3.6708, -1.2645],\n",
      "         [-0.1271,  0.0608, -4.0366],\n",
      "         ...,\n",
      "         [-0.2240, -1.6679, -0.4293],\n",
      "         [-0.0206, -1.6366, -2.3112],\n",
      "         [ 0.0434, -0.1519, -1.8269]],\n",
      "\n",
      "        [[-0.1294, -2.9328, -1.3262],\n",
      "         [ 0.1031, -1.5462, -3.7311],\n",
      "         [ 0.5576, -3.6159, -0.8538],\n",
      "         ...,\n",
      "         [ 0.2094, -3.0833, -0.0443],\n",
      "         [ 0.2407, -0.4942, -1.1575],\n",
      "         [-0.2459, -0.6640, -1.1740]],\n",
      "\n",
      "        [[-0.1482, -0.0201, -3.8553],\n",
      "         [-0.1684, -1.0374, -2.5913],\n",
      "         [-0.1272, -2.5686, -1.5484],\n",
      "         ...,\n",
      "         [-0.1238, -2.0590, -1.4741],\n",
      "         [ 0.1671, -2.2989,  0.6521],\n",
      "         [-0.3857, -2.1026, -0.6733]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1091,  0.3201, -1.3071],\n",
      "         [ 0.1713, -0.3404,  0.1537],\n",
      "         [ 0.2921, -0.9967, -2.0329],\n",
      "         ...,\n",
      "         [-0.0947, -1.3583, -0.1861],\n",
      "         [ 0.2910, -1.0251, -0.7507],\n",
      "         [-0.1458, -1.5166, -0.0170]],\n",
      "\n",
      "        [[ 0.1413, -1.3157, -2.0855],\n",
      "         [ 0.1526, -1.5164, -1.7326],\n",
      "         [-0.1253,  0.2047, -3.0142],\n",
      "         ...,\n",
      "         [ 0.0291, -1.7915,  0.4813],\n",
      "         [ 0.0561,  0.3503, -0.4806],\n",
      "         [-0.0988, -1.8341,  0.4803]],\n",
      "\n",
      "        [[-0.0923,  0.1084, -1.6934],\n",
      "         [ 0.2985, -1.0211,  0.3318],\n",
      "         [ 0.0247, -0.8869,  1.7459],\n",
      "         ...,\n",
      "         [ 0.1106, -1.2817, -0.3008],\n",
      "         [-0.0936, -0.5562,  0.5186],\n",
      "         [ 0.2170, -1.3151, -1.3327]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-178.3273, grad_fn=<SumBackward0>)\n",
      "loss: tensor(178.3273, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (191,)\n",
      "type(pred): <class 'list'> \t pred: 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 3/9 [00:02<00:05,  1.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.0239, -0.7054, -1.1600],\n",
      "         [-0.0271, -3.1186, -1.9941],\n",
      "         [ 0.1665, -0.8224, -2.2487],\n",
      "         ...,\n",
      "         [-0.3798, -2.0472, -1.5563],\n",
      "         [ 0.1453, -1.7107, -2.2390],\n",
      "         [-0.2614, -3.0185, -1.0299]],\n",
      "\n",
      "        [[ 0.2729, -0.7099, -1.3193],\n",
      "         [ 0.0860, -2.2626,  1.4416],\n",
      "         [ 0.0302,  1.1344, -1.5408],\n",
      "         ...,\n",
      "         [ 0.0334, -0.3497, -1.9517],\n",
      "         [ 0.2609,  0.3559,  0.5054],\n",
      "         [-0.1645, -1.8263, -1.9379]],\n",
      "\n",
      "        [[ 0.0310, -1.1780,  0.6690],\n",
      "         [ 0.0248, -0.1684, -0.6955],\n",
      "         [ 0.0555, -0.1878, -1.5799],\n",
      "         ...,\n",
      "         [ 0.0501, -1.4896, -1.1457],\n",
      "         [ 0.0138, -0.1483, -0.7787],\n",
      "         [ 0.0078, -3.0914, -0.5875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2036, -0.2857, -1.6409],\n",
      "         [-0.2368, -2.6514, -1.4364],\n",
      "         [ 0.0527, -0.4026, -0.5956],\n",
      "         ...,\n",
      "         [-0.0061, -3.7550,  0.7670],\n",
      "         [ 0.0583,  0.4314, -3.7400],\n",
      "         [-0.1888, -2.2236, -1.8099]],\n",
      "\n",
      "        [[ 0.0495, -1.2911, -2.0125],\n",
      "         [-0.2170, -1.0202, -0.3648],\n",
      "         [-0.0954,  0.3384, -1.8825],\n",
      "         ...,\n",
      "         [-0.0109, -2.2900, -0.2778],\n",
      "         [ 0.3525, -1.7514, -1.0130],\n",
      "         [-0.4338,  0.6128, -1.0322]],\n",
      "\n",
      "        [[-0.1619, -0.7262, -1.9369],\n",
      "         [-0.0263, -1.3079, -1.8772],\n",
      "         [-0.1357, -2.3118, -0.6395],\n",
      "         ...,\n",
      "         [-0.0525,  0.2335, -0.0538],\n",
      "         [ 0.5002, -0.5108, -0.6992],\n",
      "         [-0.1967, -0.2979, -2.0698]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-156.6944, grad_fn=<SumBackward0>)\n",
      "loss: tensor(156.6944, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (177,)\n",
      "type(pred): <class 'list'> \t pred: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 4/9 [00:03<00:03,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-2.1395e-01, -1.2654e+00, -2.9512e+00],\n",
      "         [-1.2474e-01, -1.4250e+00,  3.9412e-01],\n",
      "         [ 1.0652e-01,  5.9631e-01,  1.0681e-01],\n",
      "         ...,\n",
      "         [ 1.3140e-01, -2.0207e+00,  2.1254e-01],\n",
      "         [-7.4447e-02, -1.3546e+00,  1.2326e-01],\n",
      "         [ 9.2660e-02, -1.9167e+00, -1.6384e-01]],\n",
      "\n",
      "        [[-9.0745e-02, -5.2307e-01, -4.2376e+00],\n",
      "         [ 7.5123e-02, -5.8916e-01,  9.3240e-01],\n",
      "         [ 3.0023e-01, -1.2288e+00, -3.1955e+00],\n",
      "         ...,\n",
      "         [ 2.9994e-01, -1.0385e+00,  5.3260e-01],\n",
      "         [-5.9878e-02, -2.3071e+00,  1.5384e-01],\n",
      "         [-1.9509e-02,  3.0416e-01,  1.7595e+00]],\n",
      "\n",
      "        [[-1.4472e-02, -4.9659e-01, -1.4122e+00],\n",
      "         [-1.9713e-01, -8.7021e-01,  8.7701e-01],\n",
      "         [ 4.3682e-03,  1.2338e-01, -1.3936e-01],\n",
      "         ...,\n",
      "         [-1.5250e-02, -1.2333e-01, -1.7615e-01],\n",
      "         [-8.7941e-02, -3.7282e+00, -1.6011e+00],\n",
      "         [-4.0059e-02, -3.5408e+00, -1.0576e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.4657e-02, -3.5311e-01, -7.9495e-02],\n",
      "         [ 2.0084e-01,  6.3209e-01, -1.9457e+00],\n",
      "         [ 1.1533e-01,  1.6136e+00, -3.0941e+00],\n",
      "         ...,\n",
      "         [-6.9583e-04, -3.6114e-01, -2.2550e+00],\n",
      "         [ 1.7368e-02,  5.6234e-01, -5.9412e-01],\n",
      "         [-1.5343e-01, -2.3173e+00, -2.6901e+00]],\n",
      "\n",
      "        [[ 2.1418e-01, -5.8119e-01, -2.2509e+00],\n",
      "         [-1.0561e-01, -3.7419e+00, -3.1884e+00],\n",
      "         [ 9.0933e-02, -1.7705e+00, -5.6739e-01],\n",
      "         ...,\n",
      "         [ 1.1091e-01, -3.8318e+00, -1.9607e+00],\n",
      "         [ 1.8279e-02, -1.5762e+00,  7.5636e-01],\n",
      "         [-1.6710e-01, -1.6789e-01, -6.3977e-01]],\n",
      "\n",
      "        [[-1.4046e-01, -2.5345e+00, -3.0125e+00],\n",
      "         [ 4.7612e-02, -1.7126e+00, -1.3119e+00],\n",
      "         [ 2.2708e-01, -1.8304e+00, -2.6717e+00],\n",
      "         ...,\n",
      "         [ 1.1259e-01, -3.8948e-01, -1.5175e+00],\n",
      "         [ 5.7431e-02, -6.7409e-01, -2.0099e+00],\n",
      "         [ 7.1231e-02, -2.3744e+00, -1.9464e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-158.6081, grad_fn=<SumBackward0>)\n",
      "loss: tensor(158.6081, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (140,)\n",
      "type(pred): <class 'list'> \t pred: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 5/9 [00:04<00:03,  1.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 1.0769e-01, -3.2877e-01, -9.5801e-01],\n",
      "         [ 2.9835e-02, -8.7831e-01,  6.0361e-02],\n",
      "         [ 5.7214e-01, -2.7017e+00, -1.2003e+00],\n",
      "         ...,\n",
      "         [-9.7029e-02, -5.6505e-01, -2.1297e+00],\n",
      "         [-2.7666e-01,  7.3329e-02, -1.9529e+00],\n",
      "         [-3.4620e-01, -8.1513e-01, -1.6978e+00]],\n",
      "\n",
      "        [[-7.7134e-02,  1.3476e+00, -4.3409e+00],\n",
      "         [ 2.2153e-01, -1.5946e-01, -3.1365e+00],\n",
      "         [ 1.0519e-01, -6.2474e-01, -3.6076e+00],\n",
      "         ...,\n",
      "         [ 3.2920e-01, -2.8114e+00, -4.5737e-01],\n",
      "         [ 2.4387e-04, -1.3778e-01, -3.1828e+00],\n",
      "         [ 1.2396e-01, -2.1792e+00,  6.3679e-02]],\n",
      "\n",
      "        [[ 4.7442e-02,  3.2968e-01, -3.0404e+00],\n",
      "         [ 6.9215e-02,  9.9216e-02, -9.2476e-01],\n",
      "         [ 3.6833e-01, -8.0426e-01, -1.4534e+00],\n",
      "         ...,\n",
      "         [-2.6072e-02, -1.1434e+00, -2.3574e+00],\n",
      "         [-5.6462e-02, -1.3356e-01, -1.8104e+00],\n",
      "         [-1.1919e-01, -1.3621e+00, -3.5470e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2436e-02, -3.0551e+00, -3.2068e+00],\n",
      "         [-4.6662e-02, -4.0417e-02, -3.0793e+00],\n",
      "         [ 3.7789e-02, -3.0090e+00, -4.3493e+00],\n",
      "         ...,\n",
      "         [ 1.8835e-01, -2.0360e+00, -1.4317e+00],\n",
      "         [ 6.5625e-03, -1.7836e-01, -1.7645e+00],\n",
      "         [-2.7190e-02, -1.6857e+00,  6.0312e-01]],\n",
      "\n",
      "        [[-3.2868e-02, -1.6408e+00, -2.1616e+00],\n",
      "         [-1.8031e-01, -6.9946e-02, -3.0388e+00],\n",
      "         [ 1.9243e-01, -6.1359e-01, -8.5125e-01],\n",
      "         ...,\n",
      "         [-2.0882e-02, -2.2742e+00, -2.9572e-01],\n",
      "         [-2.4219e-01, -2.2617e+00, -3.4842e+00],\n",
      "         [ 1.9731e-01, -4.3992e-01, -3.4949e+00]],\n",
      "\n",
      "        [[-1.3205e-02,  5.9131e-01, -4.3045e+00],\n",
      "         [ 1.5316e-02,  2.7321e-01, -3.1624e+00],\n",
      "         [-1.8757e-01, -1.3801e+00, -3.0502e+00],\n",
      "         ...,\n",
      "         [-1.6364e-01, -1.4422e+00, -6.7826e-01],\n",
      "         [-1.5589e-01, -4.9597e-02,  1.1320e+00],\n",
      "         [ 1.6803e-01,  9.5672e-01, -1.4959e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-171.1125, grad_fn=<SumBackward0>)\n",
      "loss: tensor(171.1125, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (198,)\n",
      "type(pred): <class 'list'> \t pred: 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 6/9 [00:04<00:02,  1.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.4894, -0.6302, -2.9690],\n",
      "         [-0.0698, -1.6233, -4.5945],\n",
      "         [-0.1206, -2.1480, -0.9002],\n",
      "         ...,\n",
      "         [-0.0254, -1.4537, -2.3948],\n",
      "         [-0.0227,  1.1042, -2.6441],\n",
      "         [-0.1249, -0.6998, -3.2517]],\n",
      "\n",
      "        [[-0.1075,  0.8007, -2.2282],\n",
      "         [ 0.2063, -2.4605, -0.6563],\n",
      "         [ 0.0721,  1.1973, -2.3164],\n",
      "         ...,\n",
      "         [-0.2194, -2.8098,  0.1670],\n",
      "         [ 0.3122, -2.8697, -2.1251],\n",
      "         [-0.2696, -2.7410, -1.5830]],\n",
      "\n",
      "        [[-0.0239, -1.2681, -2.4816],\n",
      "         [ 0.2603, -0.8425, -0.7649],\n",
      "         [-0.0408, -2.8759, -1.4605],\n",
      "         ...,\n",
      "         [-0.0323, -3.2352,  0.2455],\n",
      "         [ 0.2745, -2.5528,  0.7446],\n",
      "         [-0.0681, -3.3686, -0.8872]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0608, -1.5779, -2.8469],\n",
      "         [-0.1012,  0.9909, -1.7503],\n",
      "         [ 0.0062, -1.4272, -3.0552],\n",
      "         ...,\n",
      "         [ 0.0464, -0.5422, -2.3303],\n",
      "         [-0.0767, -2.3638, -2.4590],\n",
      "         [ 0.0278, -2.8121, -1.5623]],\n",
      "\n",
      "        [[ 0.0614, -0.6120, -3.2874],\n",
      "         [ 0.1073, -2.0114, -3.6773],\n",
      "         [-0.1178, -3.5139, -3.1958],\n",
      "         ...,\n",
      "         [ 0.1211, -3.1473,  1.0301],\n",
      "         [-0.0574,  0.5131, -1.7611],\n",
      "         [ 0.1267, -2.4773, -1.7291]],\n",
      "\n",
      "        [[ 0.0502, -0.6547, -1.8521],\n",
      "         [-0.0164, -1.7098, -4.0148],\n",
      "         [ 0.0685, -0.3982,  1.5180],\n",
      "         ...,\n",
      "         [ 0.2001, -2.8554, -1.2486],\n",
      "         [-0.1762, -1.2374, -1.6324],\n",
      "         [-0.2138, -1.1382, -0.1703]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-154.2692, grad_fn=<SumBackward0>)\n",
      "loss: tensor(154.2692, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (150,)\n",
      "type(pred): <class 'list'> \t pred: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 7/9 [00:05<00:01,  1.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 8.0998e-02, -2.0677e+00, -3.2287e+00],\n",
      "         [ 2.5068e-01,  5.1278e-01, -2.0386e+00],\n",
      "         [-8.8069e-04, -1.3082e+00, -2.3680e+00],\n",
      "         ...,\n",
      "         [-3.9018e-02, -1.7269e+00, -1.0437e-01],\n",
      "         [ 1.8863e-01, -1.6401e+00, -1.6004e+00],\n",
      "         [-3.1290e-01, -1.6247e-01, -2.4867e-01]],\n",
      "\n",
      "        [[-1.2210e-01, -1.2566e+00, -1.9369e+00],\n",
      "         [ 4.0809e-02,  5.2837e-01, -2.0112e+00],\n",
      "         [-2.1475e-01, -1.3696e+00, -1.6273e+00],\n",
      "         ...,\n",
      "         [ 3.5252e-01, -1.5476e+00, -9.3170e-01],\n",
      "         [-8.5076e-02, -5.8935e-01, -2.6991e+00],\n",
      "         [ 1.8196e-01, -2.4143e+00,  1.0398e+00]],\n",
      "\n",
      "        [[-6.8423e-02, -1.0568e+00, -3.9463e+00],\n",
      "         [-2.9769e-01,  3.0150e-01, -2.2420e+00],\n",
      "         [-1.1310e-02, -6.1445e-01, -9.4852e-01],\n",
      "         ...,\n",
      "         [-2.9749e-02, -3.6635e+00, -7.0688e-01],\n",
      "         [-1.2575e-01, -2.2105e+00, -4.2541e+00],\n",
      "         [-1.0999e-01, -1.1208e+00, -1.6785e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.9145e-01,  8.4738e-01, -5.3819e+00],\n",
      "         [-1.0221e-01, -3.3856e+00, -2.8141e+00],\n",
      "         [ 9.6792e-02,  5.7098e-01, -2.1836e+00],\n",
      "         ...,\n",
      "         [-4.0958e-02,  2.0264e-02, -3.6402e-01],\n",
      "         [-1.6843e-01, -1.0052e+00, -1.6221e+00],\n",
      "         [ 2.2561e-01, -3.1436e+00, -1.9630e+00]],\n",
      "\n",
      "        [[-6.3609e-02, -5.4820e-01, -2.3811e+00],\n",
      "         [-1.0953e-03,  1.6068e+00, -5.0536e+00],\n",
      "         [ 2.8643e-01, -6.2354e-01, -2.2211e+00],\n",
      "         ...,\n",
      "         [-1.2998e-03, -1.1152e+00, -8.6266e-01],\n",
      "         [ 2.2162e-01,  8.1246e-01, -1.0737e+00],\n",
      "         [ 1.6377e-01, -2.5070e+00, -2.6308e+00]],\n",
      "\n",
      "        [[ 3.5560e-01, -1.0555e+00, -2.0223e+00],\n",
      "         [ 2.4711e-01, -1.4123e+00,  8.6684e-01],\n",
      "         [ 7.3864e-02, -2.4303e+00, -2.9506e+00],\n",
      "         ...,\n",
      "         [ 1.4687e-01, -2.4107e+00, -3.2510e+00],\n",
      "         [-1.5609e-01, -1.5552e+00, -4.3814e+00],\n",
      "         [-7.8259e-02, -1.9638e+00, -1.4242e-01]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-142.7669, grad_fn=<SumBackward0>)\n",
      "loss: tensor(142.7669, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (179,)\n",
      "type(pred): <class 'list'> \t pred: 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 8/9 [00:06<00:00,  1.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-1.5216e-01, -5.1127e-01, -4.2295e+00],\n",
      "         [ 6.6072e-02, -9.9867e-01, -3.1285e+00],\n",
      "         [ 1.7339e-01, -3.1486e+00,  1.6552e+00],\n",
      "         ...,\n",
      "         [-3.7879e-02, -4.2914e+00,  5.2105e-01],\n",
      "         [-6.8275e-02, -1.7404e-01, -1.7030e+00],\n",
      "         [ 1.8798e-01, -3.2591e+00, -8.3591e-01]],\n",
      "\n",
      "        [[ 1.5751e-03, -1.7755e+00, -3.6937e+00],\n",
      "         [-2.6370e-01, -3.3119e-01, -2.4233e+00],\n",
      "         [ 1.5073e-01, -2.8739e+00, -2.2610e+00],\n",
      "         ...,\n",
      "         [ 8.7369e-03, -2.4979e+00,  2.4181e-01],\n",
      "         [-8.9583e-02,  1.3455e-01, -7.1275e-01],\n",
      "         [ 2.4217e-01,  7.7677e-02, -2.3145e+00]],\n",
      "\n",
      "        [[ 1.1460e-01,  1.9286e+00, -3.1032e+00],\n",
      "         [ 2.3688e-01, -7.0384e-01, -1.0354e+00],\n",
      "         [ 2.0774e-01, -1.9591e+00,  2.3123e-01],\n",
      "         ...,\n",
      "         [ 2.0417e-01, -1.8382e+00, -2.3643e+00],\n",
      "         [-2.5576e-02, -2.3343e+00, -5.1960e-03],\n",
      "         [-3.0664e-02,  1.1266e-01, -2.3597e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.9912e-02, -1.2682e+00, -3.2376e+00],\n",
      "         [ 4.8436e-02, -1.4499e-01, -2.6528e+00],\n",
      "         [-1.1557e-01, -1.5860e+00,  1.3878e+00],\n",
      "         ...,\n",
      "         [ 1.4924e-02, -1.9826e+00, -3.1381e+00],\n",
      "         [ 2.0126e-01, -2.6271e+00, -7.6853e-01],\n",
      "         [-2.7303e-01, -2.5934e+00, -1.2181e-01]],\n",
      "\n",
      "        [[ 7.0035e-02, -2.7712e+00, -1.1030e+00],\n",
      "         [ 5.0945e-02, -8.8749e-01, -5.1724e-01],\n",
      "         [ 3.2341e-01,  3.0096e-01, -7.0721e-01],\n",
      "         ...,\n",
      "         [-7.8125e-02, -1.7045e+00,  8.1682e-01],\n",
      "         [-4.0864e-02, -1.6283e+00,  1.1354e+00],\n",
      "         [ 8.0544e-02, -2.0130e+00, -3.8387e+00]],\n",
      "\n",
      "        [[ 1.5371e-02, -3.5723e+00, -4.7365e+00],\n",
      "         [-2.1710e-01, -1.1602e+00, -2.2244e+00],\n",
      "         [-3.7158e-02, -2.5297e+00,  1.7429e+00],\n",
      "         ...,\n",
      "         [-3.4453e-02, -2.0970e+00, -1.3372e+00],\n",
      "         [-1.1505e-02, -1.2380e+00,  1.3152e+00],\n",
      "         [-1.8511e-02, -6.9338e-01, -1.2959e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-158.9565, grad_fn=<SumBackward0>)\n",
      "loss: tensor(158.9565, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (181,)\n",
      "type(pred): <class 'list'> \t pred: 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.32it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 1.7112e-02,  6.0721e-01, -4.6297e+00],\n",
      "         [ 6.1840e-02,  1.5666e+00, -2.2685e+00],\n",
      "         [-6.4603e-02, -1.5133e+00, -2.5709e+00],\n",
      "         ...,\n",
      "         [-1.6584e-01, -2.4744e+00, -3.4602e+00],\n",
      "         [ 1.7988e-01, -5.7310e-01, -2.2234e+00],\n",
      "         [ 1.5975e-01, -1.8984e+00,  4.1152e-01]],\n",
      "\n",
      "        [[-7.3099e-02, -8.8064e-01, -7.8522e-01],\n",
      "         [-9.8711e-02, -2.2081e+00, -1.7229e+00],\n",
      "         [ 6.9777e-02, -1.1992e+00, -2.8897e+00],\n",
      "         ...,\n",
      "         [ 3.2215e-02, -4.4280e-01, -2.9805e+00],\n",
      "         [ 2.9183e-02, -1.6673e+00, -2.1838e+00],\n",
      "         [ 1.7413e-01, -1.6590e+00, -1.3305e+00]],\n",
      "\n",
      "        [[ 3.8463e-03, -6.3386e-01, -1.9785e+00],\n",
      "         [-2.4028e-02, -1.0285e+00, -2.5106e+00],\n",
      "         [ 1.2284e-03, -1.0697e+00, -6.9296e-01],\n",
      "         ...,\n",
      "         [-6.6772e-02, -2.1927e+00, -2.0464e+00],\n",
      "         [-5.8513e-02, -7.8331e-02, -4.0779e+00],\n",
      "         [-4.9839e-02, -1.3135e+00, -2.2192e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.3648e-02,  5.9351e-01, -3.3803e+00],\n",
      "         [ 1.6092e-01, -8.9392e-01, -1.9656e+00],\n",
      "         [ 2.7940e-01, -1.4130e+00, -1.8907e+00],\n",
      "         ...,\n",
      "         [ 2.6475e-01, -1.7806e+00, -2.6039e+00],\n",
      "         [ 9.1112e-02, -1.3598e+00, -5.6109e-01],\n",
      "         [-2.6513e-01, -1.3386e+00,  1.5690e-01]],\n",
      "\n",
      "        [[-2.0350e-01,  9.7959e-01,  1.0405e+00],\n",
      "         [-8.3969e-02, -1.1442e+00, -1.8876e+00],\n",
      "         [-2.4779e-02, -1.5437e+00, -2.4372e+00],\n",
      "         ...,\n",
      "         [-3.3094e-01, -1.2470e+00, -1.9532e+00],\n",
      "         [-1.5142e-01, -1.0191e+00,  5.0794e-01],\n",
      "         [-7.4150e-02, -1.7348e+00, -1.5802e+00]],\n",
      "\n",
      "        [[ 1.8349e-01, -9.3283e-01, -4.1421e+00],\n",
      "         [-1.6602e-01, -1.8559e+00,  1.3074e-01],\n",
      "         [ 4.0576e-01, -3.2434e-01, -8.4006e-01],\n",
      "         ...,\n",
      "         [ 2.3712e-01, -2.7484e+00, -2.3343e+00],\n",
      "         [ 6.1522e-03, -7.5244e-01, -2.9305e+00],\n",
      "         [ 6.8800e-02, -2.5186e+00, -6.6640e-01]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-116.0250, grad_fn=<SumBackward0>)\n",
      "loss: tensor(116.0250, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (117,)\n",
      "type(pred): <class 'list'> \t pred: 117\n",
      "\n",
      "\tTraining Loss: 164.1850111219618\n",
      "\n",
      "\tTraining acc: 0.5982518945839905\n",
      "\n",
      "\tTraining prec: 0.6540715703282842\n",
      "\n",
      "\tTraining rec: 0.5982518945839905\n",
      "\n",
      "\tTraining f1: 0.6214802108637711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[-6.2263e-02, -1.2315e+00, -2.7814e+00],\n",
      "         [-4.0777e-02, -1.8503e+00, -1.4791e+00],\n",
      "         [ 1.9901e-02, -1.7481e+00, -1.2957e+00],\n",
      "         ...,\n",
      "         [-4.4827e-02, -8.8183e-01, -2.1441e+00],\n",
      "         [ 4.0117e-02, -1.9403e+00, -2.5762e+00],\n",
      "         [ 1.1330e-01, -2.3315e+00, -1.6156e+00]],\n",
      "\n",
      "        [[ 2.6093e-03, -1.1552e+00, -2.5878e+00],\n",
      "         [ 9.9947e-03, -1.9503e+00, -1.3184e+00],\n",
      "         [ 7.2976e-02, -1.7536e+00, -1.2680e+00],\n",
      "         ...,\n",
      "         [ 8.6719e-03, -7.7767e-01, -2.0164e+00],\n",
      "         [ 8.4066e-02, -1.8688e+00, -2.4325e+00],\n",
      "         [ 1.7121e-01, -2.2669e+00, -1.5450e+00]],\n",
      "\n",
      "        [[-4.1703e-02, -1.1920e+00, -2.9614e+00],\n",
      "         [-1.7608e-02, -1.8142e+00, -1.7848e+00],\n",
      "         [ 5.3370e-02, -1.5479e+00, -1.6109e+00],\n",
      "         ...,\n",
      "         [-1.0379e-02, -6.9702e-01, -2.4573e+00],\n",
      "         [ 6.6288e-02, -1.8231e+00, -2.8121e+00],\n",
      "         [ 1.4238e-01, -2.1615e+00, -1.9860e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.4103e-02, -1.0322e+00, -2.8753e+00],\n",
      "         [-1.1790e-02, -1.7060e+00, -1.7052e+00],\n",
      "         [ 5.6272e-02, -1.6905e+00, -1.5062e+00],\n",
      "         ...,\n",
      "         [-1.2218e-02, -7.3250e-01, -2.2345e+00],\n",
      "         [ 7.6517e-02, -1.8118e+00, -2.7427e+00],\n",
      "         [ 1.5472e-01, -2.1551e+00, -1.8226e+00]],\n",
      "\n",
      "        [[-5.4248e-02, -1.2707e+00, -2.9938e+00],\n",
      "         [ 1.9983e-01, -1.6748e+00, -2.1066e+00],\n",
      "         [ 1.3981e-01, -1.8231e+00, -2.7877e+00],\n",
      "         ...,\n",
      "         [-1.7672e-02, -9.4936e-01, -2.3605e+00],\n",
      "         [ 7.3443e-02, -1.8688e+00, -2.8030e+00],\n",
      "         [ 1.3330e-01, -2.4125e+00, -1.8647e+00]],\n",
      "\n",
      "        [[-6.5341e-02, -8.3368e-01, -2.8116e+00],\n",
      "         [-4.1608e-02, -1.8611e+00, -1.7392e+00],\n",
      "         [ 3.7595e-02, -1.1653e+00, -3.0814e+00],\n",
      "         ...,\n",
      "         [-5.0972e-02, -5.6779e-01, -2.3539e+00],\n",
      "         [ 3.8242e-02, -1.6017e+00, -2.7742e+00],\n",
      "         [ 1.1086e-01, -1.9430e+00, -1.9742e+00]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[-6.3533e-02, -1.0603e+00, -3.0278e+00],\n",
      "         [ 6.8906e-04, -1.4208e+00, -2.3465e+00],\n",
      "         [ 8.4709e-02, -1.7439e+00, -2.3606e+00],\n",
      "         ...,\n",
      "         [-3.8502e-02, -6.8608e-01, -2.4556e+00],\n",
      "         [ 2.9388e-02, -1.7836e+00, -2.8663e+00],\n",
      "         [ 1.0816e-01, -2.1114e+00, -2.0146e+00]],\n",
      "\n",
      "        [[-6.2766e-02, -1.0470e+00, -3.0315e+00],\n",
      "         [-3.4613e-02, -1.7037e+00, -1.9027e+00],\n",
      "         [ 2.6434e-02, -1.4602e+00, -1.7574e+00],\n",
      "         ...,\n",
      "         [-3.0855e-02, -6.5810e-01, -2.5303e+00],\n",
      "         [ 4.5698e-02, -1.7627e+00, -2.8665e+00],\n",
      "         [ 1.1346e-01, -2.1034e+00, -1.9912e+00]],\n",
      "\n",
      "        [[-6.1921e-02, -8.4100e-01, -3.2939e+00],\n",
      "         [-4.5514e-02, -1.2003e+00, -1.9571e+00],\n",
      "         [ 3.2647e-02, -5.5079e-01, -1.7843e+00],\n",
      "         ...,\n",
      "         [-3.5303e-02, -5.0626e-01, -2.7906e+00],\n",
      "         [ 3.1214e-02, -1.4815e+00, -3.2918e+00],\n",
      "         [ 1.2275e-01, -1.9953e+00, -2.4622e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.9516e-02, -9.8801e-01, -2.6755e+00],\n",
      "         [-2.0462e-02, -1.7641e+00, -1.4578e+00],\n",
      "         [ 3.4075e-02, -1.5421e+00, -1.3019e+00],\n",
      "         ...,\n",
      "         [-2.2883e-02, -6.9552e-01, -2.1667e+00],\n",
      "         [ 5.9127e-02, -1.6882e+00, -2.6056e+00],\n",
      "         [ 1.2381e-01, -2.1651e+00, -1.7183e+00]],\n",
      "\n",
      "        [[-1.8479e-02, -1.0690e+00, -3.3626e+00],\n",
      "         [-2.7757e-02, -1.5114e+00, -1.5110e+00],\n",
      "         [ 1.0364e-01, -1.4044e+00, -2.8131e+00],\n",
      "         ...,\n",
      "         [ 2.1567e-03, -6.5902e-01, -2.8286e+00],\n",
      "         [ 8.8242e-02, -1.8207e+00, -3.0858e+00],\n",
      "         [ 1.6619e-01, -2.2167e+00, -2.2397e+00]],\n",
      "\n",
      "        [[-7.1981e-02, -1.1724e+00, -2.8233e+00],\n",
      "         [-5.2533e-03, -1.1296e+00, -1.5855e+00],\n",
      "         [ 1.9582e-01, -1.4040e+00, -1.7300e+00],\n",
      "         ...,\n",
      "         [-2.1031e-02, -6.6336e-01, -2.2603e+00],\n",
      "         [ 3.6869e-02, -1.7283e+00, -2.6715e+00],\n",
      "         [ 1.2509e-01, -2.1872e+00, -1.7316e+00]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([2, 52, 3])\n",
      "tensor([[[-3.5027e-02, -1.1202e+00, -2.8077e+00],\n",
      "         [ 4.5891e-02, -1.6422e+00, -2.9593e+00],\n",
      "         [ 5.2771e-02, -4.6560e-01, -2.0254e+00],\n",
      "         [ 1.3466e-01, -1.8558e+00, -2.0709e+00],\n",
      "         [-1.0942e-02, -2.1981e+00, -2.8026e+00],\n",
      "         [ 1.1673e-01, -2.4290e+00, -2.7109e+00],\n",
      "         [ 1.5412e-01, -1.1544e+00, -1.5344e+00],\n",
      "         [-6.5000e-02, -1.2208e+00, -2.5639e+00],\n",
      "         [ 4.6703e-02, -1.3391e+00, -3.4636e+00],\n",
      "         [ 1.0570e-01, -2.2428e+00, -1.9099e+00],\n",
      "         [ 9.7516e-02, -1.3575e+00, -1.2745e+00],\n",
      "         [ 5.1189e-02, -1.4069e+00, -2.0068e+00],\n",
      "         [-6.0731e-03, -2.0756e+00, -1.5141e+00],\n",
      "         [ 3.7944e-02, -1.3770e+00, -2.3912e+00],\n",
      "         [-1.0487e-03, -1.8555e+00, -2.7323e+00],\n",
      "         [ 2.9275e-02, -1.0455e+00, -3.0829e+00],\n",
      "         [ 1.6621e-01, -2.1531e+00, -9.8759e-01],\n",
      "         [ 6.5252e-02, -1.9311e+00, -2.5492e+00],\n",
      "         [ 1.4678e-01, -1.0646e+00, -1.9580e+00],\n",
      "         [ 4.9132e-02, -1.5749e+00, -1.0297e+00],\n",
      "         [ 3.7901e-03, -1.5107e+00, -1.0080e+00],\n",
      "         [ 7.1727e-02, -1.4963e+00, -2.3689e+00],\n",
      "         [ 8.1363e-02, -1.7914e+00, -1.0607e+00],\n",
      "         [-1.6562e-01, -8.9329e-01, -3.0724e+00],\n",
      "         [-4.2131e-03, -2.3111e+00, -1.4507e+00],\n",
      "         [-3.6371e-02, -1.9478e+00, -2.8213e+00],\n",
      "         [-1.6908e-02, -2.0096e+00, -2.2048e+00],\n",
      "         [ 5.9451e-02, -8.0519e-01, -2.3775e+00],\n",
      "         [ 4.2403e-02, -1.2765e+00, -1.6417e+00],\n",
      "         [-5.1090e-02, -8.8913e-01, -1.9747e+00],\n",
      "         [-7.1035e-02, -1.6948e+00, -2.7130e+00],\n",
      "         [ 1.0009e-02, -1.2157e+00, -2.6810e+00],\n",
      "         [ 2.6859e-02, -1.2142e+00, -1.0950e+00],\n",
      "         [ 1.0878e-01, -1.5123e+00, -2.6152e+00],\n",
      "         [ 4.5971e-02, -1.3446e+00, -7.3657e-01],\n",
      "         [ 2.0678e-02, -1.8260e+00, -2.0925e+00],\n",
      "         [ 8.9333e-02, -1.2772e+00, -1.2771e+00],\n",
      "         [ 8.3386e-02, -2.2116e+00, -1.9918e+00],\n",
      "         [ 5.5285e-02, -2.0910e+00, -2.5451e+00],\n",
      "         [ 1.9579e-02, -8.9130e-01, -1.6765e+00],\n",
      "         [ 1.0250e-01, -2.4256e+00, -2.1790e+00],\n",
      "         [ 1.4538e-01, -2.0852e+00, -1.3695e+00],\n",
      "         [ 2.6484e-01, -1.8551e+00, -9.8270e-01],\n",
      "         [ 1.1248e-02, -2.2764e+00, -1.0153e+00],\n",
      "         [ 2.1075e-01, -2.0602e+00, -8.1866e-01],\n",
      "         [ 5.0151e-02, -2.6133e+00, -1.3813e+00],\n",
      "         [-3.7683e-02, -1.9471e+00, -7.8595e-01],\n",
      "         [ 1.1878e-02, -1.6969e+00, -1.6527e+00],\n",
      "         [ 3.6840e-02, -2.1126e+00, -1.1546e+00],\n",
      "         [-4.8381e-04, -6.4929e-01, -2.3496e+00],\n",
      "         [ 7.0918e-02, -1.7678e+00, -2.7800e+00],\n",
      "         [ 1.4318e-01, -2.1899e+00, -1.8942e+00]],\n",
      "\n",
      "        [[-4.7168e-02, -8.2379e-01, -3.1790e+00],\n",
      "         [ 6.5784e-02, -1.2579e+00, -2.1605e+00],\n",
      "         [ 5.0677e-02, -1.1864e+00, -1.6535e+00],\n",
      "         [ 8.7248e-02, -1.6713e+00, -1.8990e+00],\n",
      "         [ 1.5074e-01, -2.0570e+00, -2.9763e+00],\n",
      "         [ 1.0900e-01, -2.1383e+00, -2.9935e+00],\n",
      "         [ 6.4199e-02, -5.8304e-01, -3.1855e+00],\n",
      "         [-8.4844e-02, -3.1098e-01, -3.5726e+00],\n",
      "         [ 8.1358e-02, -1.7034e+00, -3.1422e+00],\n",
      "         [-2.7079e-02, -2.4085e+00, -2.0098e+00],\n",
      "         [ 2.4047e-02, -6.4629e-01, -1.3021e+00],\n",
      "         [ 4.2040e-02, -1.3609e+00, -2.4025e+00],\n",
      "         [ 1.4118e-01, -1.9099e+00, -1.5261e+00],\n",
      "         [-1.6406e-02, -1.1972e+00, -1.6577e+00],\n",
      "         [-3.7953e-02, -1.8506e+00, -9.9454e-01],\n",
      "         [ 7.8586e-02, -7.9876e-01, -2.0672e+00],\n",
      "         [ 1.4341e-01, -1.7812e+00, -2.5668e+00],\n",
      "         [-5.1960e-02, -1.0010e+00, -1.9676e+00],\n",
      "         [ 1.9492e-01, -1.3407e+00, -2.1145e+00],\n",
      "         [ 1.1176e-02, -2.2594e+00, -1.8477e+00],\n",
      "         [ 1.5309e-01, -1.7016e+00, -1.9407e+00],\n",
      "         [-1.3841e-02, -1.5186e+00, -1.9251e+00],\n",
      "         [ 3.7107e-02, -7.8266e-01, -2.1907e+00],\n",
      "         [-1.0383e-02, -1.3775e-01, -2.6536e+00],\n",
      "         [ 1.4457e-01, -1.8117e+00, -1.8485e+00],\n",
      "         [-5.9497e-02, -1.1633e+00, -2.0325e+00],\n",
      "         [ 1.5806e-01, -1.1041e+00, -3.1098e+00],\n",
      "         [ 1.2364e-01, -9.0586e-01, -2.6678e+00],\n",
      "         [ 9.8383e-03, -6.3605e-01, -1.9920e+00],\n",
      "         [-1.4652e-02,  6.0929e-02, -2.9152e+00],\n",
      "         [-3.1842e-02, -1.8835e+00, -2.9404e+00],\n",
      "         [ 3.9600e-02, -7.2640e-01, -2.7570e+00],\n",
      "         [ 1.4946e-01, -2.9236e-02, -1.8636e+00],\n",
      "         [ 1.8123e-01, -1.4429e+00, -2.6057e+00],\n",
      "         [ 3.4478e-02, -1.4583e+00, -2.0284e+00],\n",
      "         [-2.7061e-03, -1.6943e+00, -2.5387e+00],\n",
      "         [ 1.2445e-01, -1.4701e+00, -1.6545e+00],\n",
      "         [ 1.4538e-01, -6.9661e-01, -2.3450e+00],\n",
      "         [ 1.8638e-01, -1.8279e+00, -2.8589e+00],\n",
      "         [ 1.5467e-01,  2.5533e-01, -2.3590e+00],\n",
      "         [ 1.0685e-01, -2.2249e+00, -2.2708e+00],\n",
      "         [ 4.1266e-02, -1.9430e+00, -8.5858e-01],\n",
      "         [ 5.1692e-02, -9.8071e-01, -1.0512e+00],\n",
      "         [ 8.9306e-02, -2.1143e+00, -1.3304e+00],\n",
      "         [ 1.0755e-01, -1.3422e+00, -2.1285e+00],\n",
      "         [ 4.5899e-02, -2.3077e+00, -1.6812e+00],\n",
      "         [-4.8928e-02, -1.6308e+00, -9.6849e-01],\n",
      "         [ 1.1963e-02, -1.3737e+00, -2.0300e+00],\n",
      "         [ 2.1730e-02, -1.8293e+00, -1.3163e+00],\n",
      "         [-4.7782e-03, -3.3765e-01, -2.6132e+00],\n",
      "         [ 6.7372e-02, -1.5455e+00, -3.0055e+00],\n",
      "         [ 1.4138e-01, -1.9008e+00, -2.1204e+00]]])\n",
      "\n",
      "\tValidation Loss: 90.05007235209148\n",
      "\n",
      "\tValidation acc: 0.8582952338566111\n",
      "\n",
      "\tValidation prec: 0.7470275369597598\n",
      "\n",
      "\tValidation rec: 0.8582952338566111\n",
      "\n",
      "\tValidation f1: 0.7981733896991496\n",
      "Validation loss decreased (106.333736 --> 90.050072).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   4%|▎         | 2/55 [00:18<08:34,  9.71s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 3 ======================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 1/9 [00:00<00:05,  1.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.2672, -0.7511, -2.2893],\n",
      "         [ 0.1012, -0.8654,  0.9951],\n",
      "         [-0.1705,  0.3355, -2.5444],\n",
      "         ...,\n",
      "         [-0.2498, -2.9842, -2.2932],\n",
      "         [ 0.1919, -1.9512, -2.3657],\n",
      "         [ 0.2287, -2.9253, -0.9022]],\n",
      "\n",
      "        [[-0.0187,  0.4977, -1.7813],\n",
      "         [-0.0103,  0.4488, -0.6555],\n",
      "         [-0.2622, -1.5449, -0.2431],\n",
      "         ...,\n",
      "         [ 0.1173, -1.4548, -0.4359],\n",
      "         [-0.0288, -1.8983, -1.3986],\n",
      "         [ 0.0527, -2.5926, -1.5941]],\n",
      "\n",
      "        [[ 0.1625, -1.0258, -3.6487],\n",
      "         [-0.0442, -2.7278, -4.1551],\n",
      "         [ 0.1187, -2.0094, -5.2653],\n",
      "         ...,\n",
      "         [-0.1250, -2.3736, -1.4763],\n",
      "         [ 0.0973,  0.1141, -0.8238],\n",
      "         [ 0.2284, -1.9243, -2.4348]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1227, -0.8530, -3.0494],\n",
      "         [-0.0145, -1.8651, -1.4661],\n",
      "         [ 0.0615,  0.7960, -5.2482],\n",
      "         ...,\n",
      "         [ 0.2031, -0.7673, -1.2797],\n",
      "         [ 0.0253, -0.0757, -2.5128],\n",
      "         [-0.3962, -2.0347, -1.8420]],\n",
      "\n",
      "        [[-0.1853, -1.2306, -2.3380],\n",
      "         [ 0.0449, -1.2033, -1.4751],\n",
      "         [-0.1787, -1.4484, -0.2438],\n",
      "         ...,\n",
      "         [-0.0464, -1.0146, -2.1967],\n",
      "         [ 0.1116, -0.3528, -1.5133],\n",
      "         [ 0.1919, -1.7805, -1.0070]],\n",
      "\n",
      "        [[-0.4700, -1.4211,  0.0077],\n",
      "         [ 0.0747, -2.0657, -2.4021],\n",
      "         [ 0.3056, -2.1308, -1.6086],\n",
      "         ...,\n",
      "         [ 0.1841, -3.4510, -1.1356],\n",
      "         [ 0.1537,  0.4155, -1.1600],\n",
      "         [-0.1103, -2.4230, -1.6998]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-162.9467, grad_fn=<SumBackward0>)\n",
      "loss: tensor(162.9467, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (192,)\n",
      "type(pred): <class 'list'> \t pred: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 2/9 [00:01<00:04,  1.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 0.1097, -0.2744, -3.6549],\n",
      "         [-0.0367, -2.5568, -2.2146],\n",
      "         [ 0.0559, -1.3271, -3.2630],\n",
      "         ...,\n",
      "         [ 0.1477, -1.9023, -0.9957],\n",
      "         [ 0.0697,  1.3037, -2.1439],\n",
      "         [-0.2005, -0.8812, -0.5627]],\n",
      "\n",
      "        [[-0.0298,  0.2573, -2.1220],\n",
      "         [-0.1226, -1.4865, -2.5803],\n",
      "         [ 0.2327, -0.9744, -2.6218],\n",
      "         ...,\n",
      "         [-0.2134, -2.6967, -3.3412],\n",
      "         [-0.0082, -0.4556, -2.3202],\n",
      "         [-0.0277, -1.9350, -3.3612]],\n",
      "\n",
      "        [[-0.2374, -0.4061, -3.4392],\n",
      "         [-0.0561, -2.2397, -3.2877],\n",
      "         [-0.0274, -0.3762, -2.3798],\n",
      "         ...,\n",
      "         [-0.0940, -2.1728, -4.1405],\n",
      "         [ 0.2242, -0.4247, -1.3221],\n",
      "         [-0.0530, -1.3115, -1.7587]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0724, -3.4201,  0.5324],\n",
      "         [ 0.0612, -0.8207, -0.9487],\n",
      "         [ 0.3307, -0.9407, -0.8853],\n",
      "         ...,\n",
      "         [ 0.2044, -2.8052, -2.5979],\n",
      "         [-0.0904, -2.6928, -0.5354],\n",
      "         [ 0.0155, -2.7346, -2.5072]],\n",
      "\n",
      "        [[ 0.2271, -1.4726,  1.1374],\n",
      "         [-0.0415, -1.5435,  1.0831],\n",
      "         [ 0.0295, -1.8105, -1.0406],\n",
      "         ...,\n",
      "         [ 0.3795, -2.1024,  0.4662],\n",
      "         [ 0.1020, -0.5851, -5.1456],\n",
      "         [ 0.1151, -2.5592, -3.4208]],\n",
      "\n",
      "        [[-0.2234, -0.2705, -2.6674],\n",
      "         [-0.0622, -0.9410, -3.1077],\n",
      "         [ 0.2446, -1.5599, -2.6680],\n",
      "         ...,\n",
      "         [-0.4227, -3.2999, -1.4448],\n",
      "         [-0.1435, -0.9860, -0.1629],\n",
      "         [-0.3837, -4.2319, -1.1555]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-155.7519, grad_fn=<SumBackward0>)\n",
      "loss: tensor(155.7519, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (207,)\n",
      "type(pred): <class 'list'> \t pred: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 3/9 [00:01<00:03,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 0.0363, -0.6344, -1.1081],\n",
      "         [ 0.0963, -0.5769,  0.2973],\n",
      "         [ 0.2342, -1.2759, -3.2882],\n",
      "         ...,\n",
      "         [ 0.1711, -0.5577, -1.9481],\n",
      "         [ 0.0845,  0.1933, -1.9209],\n",
      "         [-0.1265, -2.8703, -3.4287]],\n",
      "\n",
      "        [[-0.0380, -1.5423, -3.0777],\n",
      "         [-0.2253, -3.5653, -2.2702],\n",
      "         [-0.2217, -2.7174, -5.5229],\n",
      "         ...,\n",
      "         [-0.1391, -3.5354, -4.0103],\n",
      "         [-0.1611, -2.8117, -1.8951],\n",
      "         [-0.3237, -1.5616,  0.0926]],\n",
      "\n",
      "        [[ 0.2212, -1.0926, -5.0571],\n",
      "         [ 0.1050, -1.3460, -0.9032],\n",
      "         [ 0.1197, -1.1629, -3.0158],\n",
      "         ...,\n",
      "         [ 0.2480, -3.5250, -1.4996],\n",
      "         [-0.2391, -2.4239, -1.5609],\n",
      "         [-0.2085, -4.2320, -0.4088]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4083,  0.3198, -0.9648],\n",
      "         [ 0.0491, -1.9566, -4.1486],\n",
      "         [-0.1151, -0.8410,  1.6723],\n",
      "         ...,\n",
      "         [-0.1142, -2.1041, -1.5784],\n",
      "         [ 0.0972, -0.4245, -1.5326],\n",
      "         [ 0.0280, -2.3106, -1.2657]],\n",
      "\n",
      "        [[-0.0153, -0.9533, -1.8092],\n",
      "         [ 0.1786, -1.8920, -1.9446],\n",
      "         [ 0.1052, -1.2218, -3.0081],\n",
      "         ...,\n",
      "         [-0.0243, -1.2018, -1.7663],\n",
      "         [-0.0474, -2.8986, -0.0708],\n",
      "         [ 0.0657, -1.7025, -0.5262]],\n",
      "\n",
      "        [[ 0.0679, -1.3473, -3.3876],\n",
      "         [-0.0365, -1.6769, -2.0532],\n",
      "         [ 0.0625, -2.0198, -1.7986],\n",
      "         ...,\n",
      "         [-0.1150, -2.6271, -2.0815],\n",
      "         [ 0.2603, -1.0785, -1.9373],\n",
      "         [-0.0501, -1.5596, -2.2933]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-142.3919, grad_fn=<SumBackward0>)\n",
      "loss: tensor(142.3919, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (165,)\n",
      "type(pred): <class 'list'> \t pred: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 4/9 [00:02<00:03,  1.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 1.7913e-01, -7.7830e-01, -3.5878e+00],\n",
      "         [-1.4254e-01, -3.2094e+00, -2.1203e+00],\n",
      "         [ 3.9733e-02, -3.1050e+00, -9.6755e-01],\n",
      "         ...,\n",
      "         [ 1.1791e-05, -2.7734e+00, -2.0063e+00],\n",
      "         [ 1.1975e-03, -2.4877e+00, -2.4806e+00],\n",
      "         [-3.0612e-02, -3.6949e+00, -2.1874e+00]],\n",
      "\n",
      "        [[-3.9810e-02, -4.0819e-01, -1.1571e+00],\n",
      "         [-2.5026e-01, -9.8116e-01, -1.4080e+00],\n",
      "         [ 1.9372e-01, -1.6157e+00,  1.0198e+00],\n",
      "         ...,\n",
      "         [ 3.3123e-01, -2.4322e+00, -9.1095e-01],\n",
      "         [ 1.0123e-01, -2.0187e+00, -2.3356e+00],\n",
      "         [ 2.7666e-01, -4.7505e+00,  5.8462e-01]],\n",
      "\n",
      "        [[ 1.7585e-01, -3.4540e+00, -3.3010e+00],\n",
      "         [-2.8407e-01, -1.2178e+00, -2.7796e+00],\n",
      "         [-2.0050e-01, -2.0610e+00, -2.6113e+00],\n",
      "         ...,\n",
      "         [-1.5992e-01, -3.0262e+00,  1.0304e-02],\n",
      "         [ 6.0234e-02, -2.1494e+00, -8.0620e-02],\n",
      "         [ 8.3555e-02, -1.2677e+00, -4.1529e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.9520e-02, -2.6288e+00, -3.0914e+00],\n",
      "         [ 1.0497e-01, -2.2594e+00, -1.3569e+00],\n",
      "         [ 2.8464e-01, -1.2586e+00, -1.8014e+00],\n",
      "         ...,\n",
      "         [ 2.5318e-01, -2.1832e+00, -1.5575e+00],\n",
      "         [-1.1893e-01, -1.8712e+00, -2.7716e+00],\n",
      "         [-2.1313e-01, -1.3830e+00, -2.6063e-01]],\n",
      "\n",
      "        [[-1.4978e-01, -1.3071e+00, -4.0209e+00],\n",
      "         [-1.7488e-01, -7.4578e-01, -3.7480e+00],\n",
      "         [ 1.2499e-01, -1.8605e+00, -2.7841e+00],\n",
      "         ...,\n",
      "         [ 7.4589e-02, -2.2204e+00, -4.8506e-01],\n",
      "         [ 1.4508e-01, -7.4469e-01, -4.6572e+00],\n",
      "         [-4.3804e-02, -1.3789e+00, -2.9052e+00]],\n",
      "\n",
      "        [[ 1.8975e-01, -1.3393e+00, -4.0476e+00],\n",
      "         [-4.3968e-02, -3.0963e+00, -1.5444e+00],\n",
      "         [ 4.3514e-02,  5.8177e-02, -2.7447e+00],\n",
      "         ...,\n",
      "         [ 1.4050e-01, -1.6462e+00, -1.8871e+00],\n",
      "         [ 2.1358e-01, -3.1355e-01,  1.0037e+00],\n",
      "         [-2.3172e-01, -3.6167e+00, -1.5257e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-173.1278, grad_fn=<SumBackward0>)\n",
      "loss: tensor(173.1278, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (173,)\n",
      "type(pred): <class 'list'> \t pred: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 5/9 [00:03<00:02,  1.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 1.2637e-01,  7.5100e-02, -3.5543e+00],\n",
      "         [ 8.1133e-02, -9.2802e-01, -2.5257e+00],\n",
      "         [ 2.8640e-01,  3.3110e-01, -3.4956e+00],\n",
      "         ...,\n",
      "         [-7.9461e-02, -2.5175e-01, -2.0105e+00],\n",
      "         [ 1.6179e-01, -3.5134e+00, -1.8942e+00],\n",
      "         [-1.7073e-01, -1.5710e+00, -2.2820e+00]],\n",
      "\n",
      "        [[ 2.2429e-01,  1.5791e+00, -4.5307e+00],\n",
      "         [-5.7673e-02, -1.0359e+00, -2.7426e+00],\n",
      "         [ 2.0670e-05, -1.8666e+00, -4.5205e+00],\n",
      "         ...,\n",
      "         [-2.9087e-02, -4.1763e+00,  7.6844e-01],\n",
      "         [-2.9872e-02, -2.1706e+00, -4.1083e+00],\n",
      "         [ 1.4096e-01, -1.5903e+00, -8.9595e-01]],\n",
      "\n",
      "        [[-1.5427e-01, -1.5741e+00, -5.2810e+00],\n",
      "         [-7.3273e-03, -2.3651e-01, -1.4554e-01],\n",
      "         [ 3.6152e-01, -1.7392e+00, -3.3924e+00],\n",
      "         ...,\n",
      "         [-1.1067e-02, -1.6333e+00, -2.0002e+00],\n",
      "         [ 1.7627e-01, -2.2008e+00, -1.4413e+00],\n",
      "         [-1.8287e-01, -1.0979e+00, -1.9787e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.8820e-03,  3.3916e-01, -3.2594e+00],\n",
      "         [-1.0547e-01, -1.8237e+00, -5.1167e-01],\n",
      "         [ 1.6110e-01, -1.0761e+00, -1.3566e+00],\n",
      "         ...,\n",
      "         [-2.4389e-01, -3.0628e+00, -2.1105e+00],\n",
      "         [ 2.4564e-01, -2.2589e+00, -1.5779e+00],\n",
      "         [-1.8542e-01, -2.2124e+00,  8.4747e-01]],\n",
      "\n",
      "        [[ 1.0308e-01,  2.2675e-01, -5.4602e+00],\n",
      "         [-7.7393e-02, -2.3463e+00, -2.0313e+00],\n",
      "         [ 6.5154e-02, -1.9416e+00, -2.3239e+00],\n",
      "         ...,\n",
      "         [ 4.9348e-02, -6.8777e+00, -2.1386e+00],\n",
      "         [ 2.8970e-01, -2.4776e+00, -1.6930e-01],\n",
      "         [-1.2137e-01, -1.0763e+00, -7.5867e-01]],\n",
      "\n",
      "        [[-3.2260e-01, -3.9603e-01, -2.5257e+00],\n",
      "         [ 3.1846e-01,  3.7033e-01, -1.3148e+00],\n",
      "         [ 4.8215e-02, -1.4906e+00, -1.2679e+00],\n",
      "         ...,\n",
      "         [-2.0942e-01, -3.0143e+00, -2.0942e+00],\n",
      "         [ 2.1684e-01, -2.0219e-01, -2.1687e+00],\n",
      "         [-1.1825e-01, -1.9975e+00, -3.3219e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-146.3098, grad_fn=<SumBackward0>)\n",
      "loss: tensor(146.3098, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (142,)\n",
      "type(pred): <class 'list'> \t pred: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 6/9 [00:03<00:01,  1.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 0.2439, -1.3964, -4.1297],\n",
      "         [ 0.2305, -0.7967, -1.4706],\n",
      "         [ 0.3947, -2.1078, -1.5477],\n",
      "         ...,\n",
      "         [ 0.1590, -2.2898, -2.7746],\n",
      "         [-0.2093, -0.4714, -1.5825],\n",
      "         [ 0.0250, -3.1019, -3.6001]],\n",
      "\n",
      "        [[-0.1672,  0.7270, -0.5659],\n",
      "         [-0.1199, -1.6049, -2.1916],\n",
      "         [ 0.0872, -4.3762, -0.3632],\n",
      "         ...,\n",
      "         [-0.0152, -3.0412, -1.0195],\n",
      "         [ 0.3511, -1.6249, -1.1599],\n",
      "         [ 0.2596, -1.0980, -2.3572]],\n",
      "\n",
      "        [[-0.1517, -1.6785,  0.3688],\n",
      "         [-0.0074, -2.8440, -3.2914],\n",
      "         [ 0.3137, -0.5796, -0.9974],\n",
      "         ...,\n",
      "         [-0.0443, -1.2336,  0.1040],\n",
      "         [-0.0450, -2.3735, -0.0158],\n",
      "         [-0.0064, -1.2437, -1.6357]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0215, -0.9097,  0.4672],\n",
      "         [-0.0108, -1.5297, -2.0662],\n",
      "         [ 0.1381, -0.9247, -4.0124],\n",
      "         ...,\n",
      "         [ 0.3155, -3.3768, -1.3333],\n",
      "         [ 0.0957, -2.0108, -0.9092],\n",
      "         [ 0.1012, -1.8453, -0.8529]],\n",
      "\n",
      "        [[ 0.0498, -0.7460, -3.6435],\n",
      "         [-0.0899, -1.0072, -4.8798],\n",
      "         [-0.0942, -1.6548, -4.0319],\n",
      "         ...,\n",
      "         [ 0.0543, -2.3562, -3.6655],\n",
      "         [-0.0682, -1.0138, -2.3107],\n",
      "         [-0.1150, -1.7174, -1.3372]],\n",
      "\n",
      "        [[ 0.0651, -0.4982, -1.1322],\n",
      "         [-0.2211, -1.1151, -1.3804],\n",
      "         [ 0.0463, -1.2834, -1.2959],\n",
      "         ...,\n",
      "         [ 0.0586, -2.8233, -1.1248],\n",
      "         [ 0.0957, -1.7012, -0.7047],\n",
      "         [-0.1241, -4.5643, -1.5358]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-116.2268, grad_fn=<SumBackward0>)\n",
      "loss: tensor(116.2268, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (160,)\n",
      "type(pred): <class 'list'> \t pred: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 7/9 [00:04<00:01,  1.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 2.8000e-02, -2.0674e+00,  5.3890e-01],\n",
      "         [-1.3006e-03, -1.3714e+00, -2.3795e+00],\n",
      "         [-3.3613e-01, -3.1329e+00, -1.9293e+00],\n",
      "         ...,\n",
      "         [-1.1688e-02, -2.0634e+00, -1.6989e+00],\n",
      "         [ 1.8060e-01, -2.2259e+00, -4.0684e-01],\n",
      "         [-7.7597e-02, -2.3709e+00, -2.1220e+00]],\n",
      "\n",
      "        [[ 1.4932e-01, -3.3068e-01, -5.1822e+00],\n",
      "         [ 2.2435e-01, -2.8961e+00, -1.6229e+00],\n",
      "         [ 2.8343e-01, -2.0296e+00, -2.0567e+00],\n",
      "         ...,\n",
      "         [-8.7203e-02, -2.9186e+00, -8.6804e-01],\n",
      "         [-9.9922e-02,  9.7257e-02, -1.6315e+00],\n",
      "         [ 1.4425e-01, -5.3507e-01, -3.0005e+00]],\n",
      "\n",
      "        [[ 2.2782e-02, -3.3118e+00, -3.7586e+00],\n",
      "         [ 3.0023e-01, -2.9693e+00, -2.0341e+00],\n",
      "         [ 9.6894e-02,  9.9223e-02, -2.7336e+00],\n",
      "         ...,\n",
      "         [-1.8197e-03, -2.0155e+00, -2.2985e+00],\n",
      "         [-1.1499e-01, -2.2626e+00, -6.0344e+00],\n",
      "         [-3.9490e-01, -5.8940e+00, -5.2725e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.2133e-02,  5.1731e-01, -4.9855e+00],\n",
      "         [ 1.4362e-01, -1.1776e+00, -1.1273e+00],\n",
      "         [-4.6280e-03, -2.9112e+00, -2.9513e-01],\n",
      "         ...,\n",
      "         [ 2.8333e-02, -1.7202e+00, -2.1144e+00],\n",
      "         [-4.5336e-02, -1.7861e+00, -1.4774e+00],\n",
      "         [ 5.3424e-02, -3.3807e+00, -1.7743e+00]],\n",
      "\n",
      "        [[-1.2630e-01, -6.6365e-01, -2.3069e+00],\n",
      "         [-4.2235e-02, -3.0922e+00, -3.5590e-01],\n",
      "         [ 4.3410e-01, -2.3965e+00, -1.7353e+00],\n",
      "         ...,\n",
      "         [-2.2930e-01, -3.1307e+00, -2.2036e+00],\n",
      "         [ 3.8163e-01,  1.3524e+00, -1.2323e+00],\n",
      "         [ 8.0639e-02, -2.3403e+00, -3.4870e+00]],\n",
      "\n",
      "        [[-3.5559e-02, -1.6518e+00, -1.5224e+00],\n",
      "         [-9.8202e-02, -2.2736e+00, -1.3580e+00],\n",
      "         [ 3.5780e-01, -7.1909e-01, -1.4009e+00],\n",
      "         ...,\n",
      "         [-8.3168e-02, -3.2356e+00, -1.2143e+00],\n",
      "         [ 1.6367e-01, -2.3134e+00, -3.2735e+00],\n",
      "         [-6.3149e-02, -1.3882e+00, -1.7385e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-158.4418, grad_fn=<SumBackward0>)\n",
      "loss: tensor(158.4418, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (191,)\n",
      "type(pred): <class 'list'> \t pred: 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 8/9 [00:05<00:00,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-1.6818e-01, -2.6645e+00, -2.3307e+00],\n",
      "         [ 7.4364e-02, -6.6028e-01, -2.6657e+00],\n",
      "         [-6.3801e-02, -2.6267e+00, -4.4285e+00],\n",
      "         ...,\n",
      "         [ 1.1654e-01, -1.5179e+00,  2.0747e-01],\n",
      "         [ 4.2759e-02, -3.4986e+00, -4.9092e-01],\n",
      "         [ 5.8817e-02, -4.1153e+00, -1.6904e+00]],\n",
      "\n",
      "        [[ 6.8843e-02, -1.0194e+00, -5.6875e+00],\n",
      "         [ 1.1802e-01, -1.3878e-01, -6.1582e+00],\n",
      "         [ 3.5908e-01, -1.9364e+00,  1.8117e+00],\n",
      "         ...,\n",
      "         [ 2.9378e-01, -1.3957e+00, -1.4545e+00],\n",
      "         [ 3.5731e-01, -1.4826e+00, -3.3254e+00],\n",
      "         [ 1.3061e-02, -4.5078e+00, -3.7781e+00]],\n",
      "\n",
      "        [[ 5.8690e-02, -2.7891e+00, -4.2566e+00],\n",
      "         [-3.1788e-03, -7.9242e-01,  2.9632e-01],\n",
      "         [-2.2176e-01, -4.3635e+00, -9.1616e-01],\n",
      "         ...,\n",
      "         [ 6.6083e-02, -2.2161e+00, -8.0079e-01],\n",
      "         [ 1.1499e-01, -2.0722e+00, -1.2774e+00],\n",
      "         [-2.1325e-01, -2.0479e+00, -3.0313e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0488e-01,  1.5035e-01,  1.3448e-01],\n",
      "         [ 2.6759e-01, -1.4618e+00, -3.2291e+00],\n",
      "         [-4.0999e-02, -2.8070e+00, -1.3120e+00],\n",
      "         ...,\n",
      "         [ 2.6312e-01, -3.8366e+00, -7.6619e-01],\n",
      "         [ 3.1326e-01, -5.9749e-01, -3.1133e+00],\n",
      "         [-8.7595e-02, -2.4914e+00, -2.7056e+00]],\n",
      "\n",
      "        [[-2.4940e-01, -7.4314e-01, -5.5956e+00],\n",
      "         [ 3.1886e-02,  9.5658e-01, -2.2525e+00],\n",
      "         [ 3.2994e-01, -2.9766e+00, -2.4828e+00],\n",
      "         ...,\n",
      "         [-1.2695e-01, -4.6798e+00, -1.8609e+00],\n",
      "         [ 2.8139e-01, -2.0433e+00, -4.2017e+00],\n",
      "         [ 2.9240e-01, -4.0709e-01, -1.9525e+00]],\n",
      "\n",
      "        [[-2.3429e-01, -6.5721e-01, -3.4339e+00],\n",
      "         [ 1.7149e-01, -3.3517e-01, -7.5566e-01],\n",
      "         [ 5.5979e-02, -8.9140e-02, -3.8731e+00],\n",
      "         ...,\n",
      "         [ 2.6223e-01, -1.2319e+00, -2.4054e+00],\n",
      "         [ 8.0803e-02, -2.0682e+00, -4.2884e+00],\n",
      "         [-6.9838e-02, -1.8600e-01, -1.2662e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-127.1783, grad_fn=<SumBackward0>)\n",
      "loss: tensor(127.1783, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (157,)\n",
      "type(pred): <class 'list'> \t pred: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9/9 [00:05<00:00,  1.58it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 1.7856e-01, -2.5291e+00, -1.8739e+00],\n",
      "         [-7.1584e-03, -2.5349e+00, -1.5881e+00],\n",
      "         [-5.4771e-02, -2.5674e+00,  3.5906e-01],\n",
      "         ...,\n",
      "         [ 2.2610e-01, -2.4736e+00,  4.0993e-01],\n",
      "         [-4.0117e-02, -2.1341e+00, -3.7055e+00],\n",
      "         [ 2.8490e-02, -2.1101e+00, -8.3298e-01]],\n",
      "\n",
      "        [[-1.4905e-01, -1.7310e+00, -2.6688e+00],\n",
      "         [ 1.3222e-01, -2.2009e+00,  1.4689e-01],\n",
      "         [ 2.9701e-01, -2.2510e+00, -1.5697e+00],\n",
      "         ...,\n",
      "         [ 1.7333e-01, -3.1326e+00, -9.2950e-01],\n",
      "         [ 1.2438e-01, -2.0563e+00, -1.4731e-01],\n",
      "         [-9.3525e-02, -1.8935e+00, -1.9706e+00]],\n",
      "\n",
      "        [[-2.6832e-01, -8.8866e-01, -1.5072e+00],\n",
      "         [ 7.4210e-02, -1.3922e+00, -2.2928e+00],\n",
      "         [ 4.7050e-01, -1.5056e+00, -2.0729e+00],\n",
      "         ...,\n",
      "         [ 1.6570e-04, -3.7223e+00, -8.8171e-01],\n",
      "         [-3.4194e-02, -1.0568e+00, -3.7944e-01],\n",
      "         [ 1.0082e-01, -3.6382e+00, -2.3436e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0114e-01, -1.9267e+00, -4.2700e+00],\n",
      "         [ 1.6443e-02, -1.1709e+00, -2.3920e+00],\n",
      "         [ 1.5834e-01, -3.4068e+00, -2.1550e+00],\n",
      "         ...,\n",
      "         [-5.0074e-02, -1.3614e+00, -2.0186e+00],\n",
      "         [ 2.4797e-01, -5.9247e-01, -2.1295e+00],\n",
      "         [ 1.5582e-01, -6.6550e-03, -4.5494e+00]],\n",
      "\n",
      "        [[-1.4534e-01, -7.9251e-01, -1.8790e+00],\n",
      "         [-3.7983e-01, -2.1558e+00, -1.6002e+00],\n",
      "         [ 6.9235e-02, -1.5146e+00, -4.2016e+00],\n",
      "         ...,\n",
      "         [-1.7529e-03, -1.9846e+00, -1.1991e+00],\n",
      "         [-3.4863e-02, -3.5235e+00, -7.3341e-01],\n",
      "         [ 3.0264e-04, -1.6098e+00, -2.6622e+00]],\n",
      "\n",
      "        [[ 5.0242e-02, -9.9039e-01, -2.2991e+00],\n",
      "         [-1.1221e-01, -3.0075e+00, -3.0654e+00],\n",
      "         [ 2.4372e-01, -2.6186e+00, -2.9864e+00],\n",
      "         ...,\n",
      "         [-2.1371e-03, -2.7874e+00, -1.7449e+00],\n",
      "         [ 7.3509e-03, -4.0180e+00, -2.0272e+00],\n",
      "         [ 1.3058e-01, -1.9182e+00, -3.8203e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-127.3868, grad_fn=<SumBackward0>)\n",
      "loss: tensor(127.3868, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (184,)\n",
      "type(pred): <class 'list'> \t pred: 184\n",
      "\n",
      "\tTraining Loss: 145.52909342447916\n",
      "\n",
      "\tTraining acc: 0.697023128998015\n",
      "\n",
      "\tTraining prec: 0.6727492019904355\n",
      "\n",
      "\tTraining rec: 0.697023128998015\n",
      "\n",
      "\tTraining f1: 0.6808354007140559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[-2.5575e-02, -1.5546e+00, -3.1447e+00],\n",
      "         [-5.8848e-03, -2.3292e+00, -1.9578e+00],\n",
      "         [ 4.8050e-02, -2.0945e+00, -1.7857e+00],\n",
      "         ...,\n",
      "         [-7.4596e-03, -1.3123e+00, -2.6847e+00],\n",
      "         [ 7.3498e-02, -2.2671e+00, -3.0798e+00],\n",
      "         [ 1.3920e-01, -2.7740e+00, -2.2364e+00]],\n",
      "\n",
      "        [[-4.8734e-02, -1.6183e+00, -3.5003e+00],\n",
      "         [-1.9935e-02, -2.2750e+00, -2.4034e+00],\n",
      "         [ 4.0570e-02, -2.0211e+00, -2.2440e+00],\n",
      "         ...,\n",
      "         [-1.5280e-02, -1.2826e+00, -3.0508e+00],\n",
      "         [ 6.0160e-02, -2.3447e+00, -3.3412e+00],\n",
      "         [ 1.2898e-01, -2.7181e+00, -2.5099e+00]],\n",
      "\n",
      "        [[-4.7430e-03, -1.6322e+00, -3.8185e+00],\n",
      "         [-1.2905e-02, -2.1031e+00, -2.0067e+00],\n",
      "         [ 1.1805e-01, -1.9701e+00, -3.3012e+00],\n",
      "         ...,\n",
      "         [ 1.7554e-02, -1.2811e+00, -3.3368e+00],\n",
      "         [ 1.0233e-01, -2.3922e+00, -3.5438e+00],\n",
      "         [ 1.8147e-01, -2.8264e+00, -2.7459e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.7670e-02, -1.7496e+00, -3.3002e+00],\n",
      "         [ 1.0037e-02, -1.7243e+00, -2.0969e+00],\n",
      "         [ 2.1010e-01, -1.9619e+00, -2.2245e+00],\n",
      "         ...,\n",
      "         [-5.1917e-03, -1.2942e+00, -2.7857e+00],\n",
      "         [ 5.1569e-02, -2.3176e+00, -3.1499e+00],\n",
      "         [ 1.4072e-01, -2.8026e+00, -2.2513e+00]],\n",
      "\n",
      "        [[-5.8586e-02, -1.5189e+00, -3.4369e+00],\n",
      "         [ 4.0757e-02, -2.7973e+00, -3.1013e+00],\n",
      "         [ 5.5753e-02, -2.8005e+00, -3.1968e+00],\n",
      "         ...,\n",
      "         [-3.8677e-02, -1.2031e+00, -3.1613e+00],\n",
      "         [ 2.9881e-02, -2.2669e+00, -3.4590e+00],\n",
      "         [ 1.0590e-01, -2.7333e+00, -2.5837e+00]],\n",
      "\n",
      "        [[-4.0062e-02, -1.8452e+00, -3.4700e+00],\n",
      "         [ 2.1452e-01, -2.2642e+00, -2.5928e+00],\n",
      "         [ 1.5450e-01, -2.4041e+00, -3.2837e+00],\n",
      "         ...,\n",
      "         [-1.9382e-03, -1.5779e+00, -2.8882e+00],\n",
      "         [ 8.8090e-02, -2.4574e+00, -3.2854e+00],\n",
      "         [ 1.4891e-01, -3.0290e+00, -2.3883e+00]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[-6.9322e-02, -1.5485e+00, -3.4391e+00],\n",
      "         [ 8.2312e-03, -2.4644e+00, -1.8294e+00],\n",
      "         [ 6.2558e-02, -1.2682e+00, -2.0943e+00],\n",
      "         ...,\n",
      "         [-9.7758e-02, -9.3452e-01, -2.6049e+00],\n",
      "         [ 6.9020e-02, -2.4739e+00, -3.3857e+00],\n",
      "         [-9.3573e-04, -2.3335e+00, -3.2928e+00]],\n",
      "\n",
      "        [[-1.7457e-02, -1.5180e+00, -3.5439e+00],\n",
      "         [ 8.9682e-02, -2.0623e+00, -2.5655e+00],\n",
      "         [ 2.5028e-02, -1.6896e+00, -2.7223e+00],\n",
      "         ...,\n",
      "         [ 1.7734e-02, -1.1691e+00, -2.9798e+00],\n",
      "         [ 8.7083e-02, -2.2809e+00, -3.3341e+00],\n",
      "         [ 1.6446e-01, -2.7213e+00, -2.4113e+00]],\n",
      "\n",
      "        [[-4.8050e-02, -1.8066e+00, -3.2581e+00],\n",
      "         [-2.5967e-02, -2.4244e+00, -1.9859e+00],\n",
      "         [ 3.4182e-02, -2.3118e+00, -1.7899e+00],\n",
      "         ...,\n",
      "         [-2.9114e-02, -1.5095e+00, -2.6712e+00],\n",
      "         [ 5.4802e-02, -2.5298e+00, -3.0611e+00],\n",
      "         [ 1.2897e-01, -2.9502e+00, -2.1414e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0076e-02, -1.6034e+00, -3.3432e+00],\n",
      "         [ 2.7988e-03, -2.2745e+00, -2.2015e+00],\n",
      "         [ 7.0325e-02, -2.2484e+00, -1.9899e+00],\n",
      "         ...,\n",
      "         [ 3.2785e-03, -1.3542e+00, -2.7514e+00],\n",
      "         [ 9.0934e-02, -2.3937e+00, -3.2152e+00],\n",
      "         [ 1.7021e-01, -2.7699e+00, -2.3399e+00]],\n",
      "\n",
      "        [[-3.3003e-02, -1.3991e+00, -3.6488e+00],\n",
      "         [ 8.1183e-02, -1.8607e+00, -2.6792e+00],\n",
      "         [ 6.5599e-02, -1.7823e+00, -2.1569e+00],\n",
      "         ...,\n",
      "         [ 1.0897e-02, -9.6515e-01, -3.1323e+00],\n",
      "         [ 8.1931e-02, -2.1305e+00, -3.4798e+00],\n",
      "         [ 1.5699e-01, -2.5179e+00, -2.6383e+00]],\n",
      "\n",
      "        [[-2.7544e-02, -1.7660e+00, -3.4350e+00],\n",
      "         [-3.0413e-03, -2.3789e+00, -2.2811e+00],\n",
      "         [ 6.7368e-02, -2.1027e+00, -2.0920e+00],\n",
      "         ...,\n",
      "         [ 5.1914e-03, -1.3193e+00, -2.9760e+00],\n",
      "         [ 8.0831e-02, -2.4074e+00, -3.2893e+00],\n",
      "         [ 1.5776e-01, -2.7713e+00, -2.4984e+00]]])\n",
      "\toutput_5: torch.Size([2, 52, 3])\n",
      "tensor([[[-4.9838e-02, -1.6220e+00, -3.4799e+00],\n",
      "         [ 1.5099e-02, -2.0005e+00, -2.8186e+00],\n",
      "         [ 9.8633e-02, -2.2935e+00, -2.8339e+00],\n",
      "         [ 1.9057e-01, -2.6611e+00, -3.5915e+00],\n",
      "         [-3.1666e-02, -1.8174e+00, -3.1504e+00],\n",
      "         [-1.3129e-02, -2.0319e+00, -3.2476e+00],\n",
      "         [ 1.1453e-01, -2.4812e+00, -2.7562e+00],\n",
      "         [-6.2476e-02, -3.1650e+00, -4.0638e+00],\n",
      "         [ 7.6203e-03, -2.4623e+00, -3.2921e+00],\n",
      "         [-5.6982e-02, -2.3192e+00, -2.5891e+00],\n",
      "         [-3.6531e-02, -1.6206e+00, -2.4850e+00],\n",
      "         [-8.0647e-02, -2.0838e+00, -2.9043e+00],\n",
      "         [ 5.0769e-02, -3.0515e+00, -2.0913e+00],\n",
      "         [ 5.7131e-02, -2.1426e+00, -2.8897e+00],\n",
      "         [-4.8809e-02, -1.9834e+00, -1.6723e+00],\n",
      "         [ 4.6566e-02, -2.1160e+00, -2.6696e+00],\n",
      "         [ 1.8060e-01, -2.5475e+00, -2.4715e+00],\n",
      "         [-5.6473e-03, -2.2540e+00, -3.2489e+00],\n",
      "         [ 1.0878e-01, -1.8172e+00, -2.8221e+00],\n",
      "         [-7.7684e-02, -2.7574e+00, -1.6434e+00],\n",
      "         [ 4.4126e-02, -1.9982e+00, -2.7171e+00],\n",
      "         [ 2.3329e-02, -2.6637e+00, -2.4747e+00],\n",
      "         [ 2.4208e-02, -2.0012e+00, -1.9697e+00],\n",
      "         [-1.3981e-01, -1.8337e+00, -3.0014e+00],\n",
      "         [-1.6864e-02, -2.8146e+00, -2.2297e+00],\n",
      "         [-6.2640e-02, -2.5129e+00, -3.5610e+00],\n",
      "         [-2.2866e-02, -2.4628e+00, -2.8558e+00],\n",
      "         [ 2.9258e-02, -1.5302e+00, -3.0363e+00],\n",
      "         [ 2.5585e-02, -1.7013e+00, -2.2440e+00],\n",
      "         [-6.7818e-02, -1.5509e+00, -2.7638e+00],\n",
      "         [-9.4109e-02, -2.2778e+00, -3.5153e+00],\n",
      "         [-2.3102e-02, -1.7834e+00, -3.5098e+00],\n",
      "         [-3.4016e-03, -1.8787e+00, -1.9154e+00],\n",
      "         [ 9.2505e-02, -2.1483e+00, -3.2362e+00],\n",
      "         [ 3.0665e-02, -1.8900e+00, -1.3139e+00],\n",
      "         [-7.9285e-03, -2.4258e+00, -2.8315e+00],\n",
      "         [ 4.8046e-02, -2.0168e+00, -2.0450e+00],\n",
      "         [ 5.4723e-02, -2.7249e+00, -2.7067e+00],\n",
      "         [ 2.9626e-02, -2.6161e+00, -3.2783e+00],\n",
      "         [-4.8354e-03, -1.5465e+00, -2.3467e+00],\n",
      "         [ 5.4889e-02, -2.9907e+00, -2.8952e+00],\n",
      "         [ 1.2463e-01, -2.5601e+00, -2.2357e+00],\n",
      "         [ 2.2632e-01, -2.4174e+00, -1.7508e+00],\n",
      "         [-2.1482e-02, -2.8699e+00, -1.6954e+00],\n",
      "         [ 1.8362e-01, -2.5366e+00, -1.6269e+00],\n",
      "         [ 2.4743e-02, -3.0083e+00, -2.1934e+00],\n",
      "         [-7.6625e-02, -2.4987e+00, -1.4260e+00],\n",
      "         [-5.0573e-03, -2.1801e+00, -2.4726e+00],\n",
      "         [ 2.0361e-02, -2.6286e+00, -1.8961e+00],\n",
      "         [-2.3225e-02, -1.3044e+00, -2.9606e+00],\n",
      "         [ 4.3588e-02, -2.3614e+00, -3.3280e+00],\n",
      "         [ 1.2339e-01, -2.7215e+00, -2.5184e+00]],\n",
      "\n",
      "        [[-2.0906e-02, -1.6934e+00, -3.2813e+00],\n",
      "         [ 6.1314e-02, -2.2553e+00, -3.4727e+00],\n",
      "         [ 6.6321e-02, -1.0254e+00, -2.4734e+00],\n",
      "         [ 1.4883e-01, -2.4118e+00, -2.5618e+00],\n",
      "         [ 3.1075e-03, -2.7808e+00, -3.2589e+00],\n",
      "         [ 1.3093e-01, -2.9692e+00, -3.2058e+00],\n",
      "         [ 1.6788e-01, -1.7049e+00, -2.0051e+00],\n",
      "         [-5.0606e-02, -1.7846e+00, -3.0517e+00],\n",
      "         [ 6.0846e-02, -1.9047e+00, -3.9321e+00],\n",
      "         [ 1.1982e-01, -2.7920e+00, -2.3940e+00],\n",
      "         [ 1.1224e-01, -1.9350e+00, -1.7652e+00],\n",
      "         [ 6.4673e-02, -1.9542e+00, -2.4687e+00],\n",
      "         [ 8.2106e-03, -2.6285e+00, -1.9977e+00],\n",
      "         [ 5.2760e-02, -1.9724e+00, -2.8963e+00],\n",
      "         [ 1.2695e-02, -2.3946e+00, -3.1948e+00],\n",
      "         [ 4.3640e-02, -1.6295e+00, -3.5505e+00],\n",
      "         [ 1.8048e-01, -2.7205e+00, -1.4677e+00],\n",
      "         [ 7.9240e-02, -2.5008e+00, -3.0165e+00],\n",
      "         [ 1.6160e-01, -1.6603e+00, -2.4475e+00],\n",
      "         [ 6.4003e-02, -2.1522e+00, -1.5396e+00],\n",
      "         [ 1.8436e-02, -2.0721e+00, -1.5172e+00],\n",
      "         [ 8.6775e-02, -2.0784e+00, -2.8734e+00],\n",
      "         [ 9.6365e-02, -2.3585e+00, -1.5895e+00],\n",
      "         [-1.5083e-01, -1.4890e+00, -3.5591e+00],\n",
      "         [ 1.0916e-02, -2.8961e+00, -1.9818e+00],\n",
      "         [-2.1516e-02, -2.5455e+00, -3.3184e+00],\n",
      "         [-2.1753e-03, -2.5856e+00, -2.7225e+00],\n",
      "         [ 7.4869e-02, -1.4214e+00, -2.9061e+00],\n",
      "         [ 5.7109e-02, -1.8648e+00, -2.1254e+00],\n",
      "         [-3.6030e-02, -1.4952e+00, -2.4840e+00],\n",
      "         [-5.6184e-02, -2.2799e+00, -3.2038e+00],\n",
      "         [ 2.4457e-02, -1.7908e+00, -3.1624e+00],\n",
      "         [ 4.1947e-02, -1.8127e+00, -1.6005e+00],\n",
      "         [ 1.2437e-01, -2.1374e+00, -3.1349e+00],\n",
      "         [ 6.0743e-02, -1.9339e+00, -1.2485e+00],\n",
      "         [ 3.6491e-02, -2.4373e+00, -2.6348e+00],\n",
      "         [ 1.0474e-01, -1.8840e+00, -1.7995e+00],\n",
      "         [ 9.8950e-02, -2.8243e+00, -2.5148e+00],\n",
      "         [ 7.0862e-02, -2.7081e+00, -3.0727e+00],\n",
      "         [ 3.4562e-02, -1.4849e+00, -2.1750e+00],\n",
      "         [ 1.1735e-01, -3.0060e+00, -2.6827e+00],\n",
      "         [ 1.6046e-01, -2.6691e+00, -1.8816e+00],\n",
      "         [ 2.8022e-01, -2.4569e+00, -1.4968e+00],\n",
      "         [ 2.6678e-02, -2.8799e+00, -1.5434e+00],\n",
      "         [ 2.2459e-01, -2.6141e+00, -1.2993e+00],\n",
      "         [ 6.5087e-02, -3.1938e+00, -1.8927e+00],\n",
      "         [-2.2547e-02, -2.5391e+00, -1.2896e+00],\n",
      "         [ 2.6338e-02, -2.2755e+00, -2.1467e+00],\n",
      "         [ 5.2213e-02, -2.7120e+00, -1.6897e+00],\n",
      "         [ 1.5146e-02, -1.2756e+00, -2.8724e+00],\n",
      "         [ 8.5549e-02, -2.3559e+00, -3.2608e+00],\n",
      "         [ 1.5876e-01, -2.8079e+00, -2.4166e+00]]])\n",
      "\n",
      "\tValidation Loss: 84.94931284586589\n",
      "\n",
      "\tValidation acc: 0.8349913158736687\n",
      "\n",
      "\tValidation prec: 0.6976155413844305\n",
      "\n",
      "\tValidation rec: 0.8349913158736687\n",
      "\n",
      "\tValidation f1: 0.7600378409716811\n",
      "Validation loss decreased (90.050072 --> 84.949313).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   5%|▌         | 3/55 [00:29<08:32,  9.86s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 4 ======================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 1/9 [00:00<00:05,  1.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.1851, -1.3361, -3.8667],\n",
      "         [-0.2041, -1.2432, -1.1487],\n",
      "         [ 0.2375, -1.6570, -1.1448],\n",
      "         ...,\n",
      "         [ 0.0124, -4.9833, -0.1320],\n",
      "         [ 0.2850, -2.4873, -0.5599],\n",
      "         [-0.0693, -2.8566,  0.0899]],\n",
      "\n",
      "        [[-0.0299, -2.2288, -3.2194],\n",
      "         [-0.2103, -2.2419, -3.1679],\n",
      "         [-0.0289, -4.2381, -1.2478],\n",
      "         ...,\n",
      "         [ 0.1389, -1.4128, -1.5451],\n",
      "         [ 0.0089, -2.4917, -1.8151],\n",
      "         [ 0.0361, -0.9302, -2.4614]],\n",
      "\n",
      "        [[-0.2154,  0.2230, -3.5994],\n",
      "         [ 0.1588,  1.2154, -1.5326],\n",
      "         [ 0.0904, -3.6414, -3.9480],\n",
      "         ...,\n",
      "         [ 0.1180, -1.5805, -1.1203],\n",
      "         [ 0.1039, -3.1904, -3.5784],\n",
      "         [-0.0282, -2.0113, -3.2574]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0984, -1.0064, -1.5616],\n",
      "         [ 0.0622,  0.9912, -2.2624],\n",
      "         [ 0.2613, -0.1935, -1.3104],\n",
      "         ...,\n",
      "         [-0.1192, -2.9461, -1.1647],\n",
      "         [ 0.3627, -1.3363, -1.9742],\n",
      "         [ 0.0052, -2.1942, -2.0494]],\n",
      "\n",
      "        [[ 0.0379, -0.0575, -4.7546],\n",
      "         [ 0.1052, -0.3601, -3.5483],\n",
      "         [ 0.1001, -2.6447, -4.9442],\n",
      "         ...,\n",
      "         [-0.2648, -0.9777, -3.1163],\n",
      "         [ 0.1679, -0.9632, -0.9051],\n",
      "         [ 0.1000, -2.3196, -1.3212]],\n",
      "\n",
      "        [[-0.0431, -3.4299, -4.7765],\n",
      "         [ 0.0547, -3.8046, -4.1959],\n",
      "         [ 0.0971, -2.6350, -3.1158],\n",
      "         ...,\n",
      "         [-0.0078, -2.7243, -1.6645],\n",
      "         [-0.0976, -1.0203, -1.5419],\n",
      "         [ 0.2090, -1.8702, -2.6307]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-151.9123, grad_fn=<SumBackward0>)\n",
      "loss: tensor(151.9123, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (219,)\n",
      "type(pred): <class 'list'> \t pred: 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 2/9 [00:01<00:05,  1.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 0.0730, -1.5718, -3.4434],\n",
      "         [-0.1739, -1.3991, -2.9275],\n",
      "         [ 0.1970, -1.5566, -2.6565],\n",
      "         ...,\n",
      "         [-0.0457, -1.4088, -0.0759],\n",
      "         [ 0.1068, -4.5658, -0.6342],\n",
      "         [ 0.0249,  0.5853, -3.9933]],\n",
      "\n",
      "        [[-0.2758,  0.1958, -5.6874],\n",
      "         [ 0.0101, -2.7573, -1.1916],\n",
      "         [ 0.0234, -1.8601, -1.3158],\n",
      "         ...,\n",
      "         [ 0.0166, -2.8736, -1.2076],\n",
      "         [ 0.0828, -0.1342, -2.3406],\n",
      "         [ 0.0538, -2.5758, -2.2431]],\n",
      "\n",
      "        [[-0.1133, -1.8268, -3.5229],\n",
      "         [-0.2664, -1.2328, -4.7304],\n",
      "         [ 0.0732, -2.3553,  0.3332],\n",
      "         ...,\n",
      "         [ 0.0623, -1.9030, -2.7267],\n",
      "         [ 0.1029, -1.4336,  0.3545],\n",
      "         [ 0.1406, -0.9506,  0.0904]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1317, -1.0617, -2.4086],\n",
      "         [-0.2677, -2.1530, -2.5696],\n",
      "         [ 0.0702, -0.5581, -1.9411],\n",
      "         ...,\n",
      "         [ 0.0134, -2.4403, -3.2176],\n",
      "         [ 0.0344, -1.8056, -1.0198],\n",
      "         [-0.0344, -2.1380, -1.1236]],\n",
      "\n",
      "        [[ 0.0605, -3.6223, -3.6415],\n",
      "         [ 0.0911, -0.5950, -1.7409],\n",
      "         [-0.0670, -0.7108, -2.9103],\n",
      "         ...,\n",
      "         [ 0.2018, -3.2888, -3.2849],\n",
      "         [-0.0254, -0.4715, -2.6143],\n",
      "         [-0.0431, -1.4041, -1.4924]],\n",
      "\n",
      "        [[-0.2150, -1.2678, -2.5017],\n",
      "         [-0.0109, -2.9674, -2.4855],\n",
      "         [ 0.2397, -1.8395, -0.5032],\n",
      "         ...,\n",
      "         [ 0.0395, -3.5402, -1.4359],\n",
      "         [ 0.1545, -2.0445, -1.6672],\n",
      "         [-0.0299, -3.6468, -0.1308]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-137.5672, grad_fn=<SumBackward0>)\n",
      "loss: tensor(137.5672, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (149,)\n",
      "type(pred): <class 'list'> \t pred: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 3/9 [00:02<00:04,  1.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 7.7539e-02, -2.5232e+00, -2.2820e+00],\n",
      "         [-7.2230e-02, -6.4799e-01, -1.4303e+00],\n",
      "         [ 1.3761e-01, -1.3002e+00, -2.4283e+00],\n",
      "         ...,\n",
      "         [ 1.9239e-01, -3.2601e+00,  6.3825e-01],\n",
      "         [ 1.1410e-01, -1.0343e+00, -2.6375e+00],\n",
      "         [-8.9167e-02, -3.6792e+00, -2.1227e+00]],\n",
      "\n",
      "        [[ 4.9285e-02, -8.5652e-01, -3.8004e+00],\n",
      "         [-8.2690e-02, -1.2314e+00, -4.8385e+00],\n",
      "         [-6.8334e-02, -2.2831e+00, -1.3256e+00],\n",
      "         ...,\n",
      "         [-8.6671e-02, -1.0843e+00, -3.1520e+00],\n",
      "         [ 3.8692e-01, -1.6246e+00, -2.2243e+00],\n",
      "         [-2.4891e-03, -1.2443e+00, -4.9481e+00]],\n",
      "\n",
      "        [[-1.2394e-01, -3.0059e+00, -8.2701e-01],\n",
      "         [-8.9606e-02, -2.1008e+00, -3.1109e+00],\n",
      "         [-5.0617e-02, -1.6209e+00, -2.4074e+00],\n",
      "         ...,\n",
      "         [-2.0721e-01, -5.9988e-01, -9.3303e-01],\n",
      "         [ 1.5679e-01, -3.8953e+00, -2.2424e+00],\n",
      "         [ 1.2532e-01, -2.6673e+00, -3.2052e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9415e-02, -2.6614e+00, -1.7329e+00],\n",
      "         [ 2.5083e-01,  6.2387e-01, -5.7794e+00],\n",
      "         [ 7.3174e-02, -3.1317e+00, -2.3180e+00],\n",
      "         ...,\n",
      "         [-1.1807e-01, -3.9629e+00, -2.2778e+00],\n",
      "         [ 3.7841e-02, -2.0762e+00, -1.4601e+00],\n",
      "         [-1.8629e-01, -3.7371e+00, -3.0189e+00]],\n",
      "\n",
      "        [[-5.3090e-02, -6.8886e-01, -2.5345e+00],\n",
      "         [ 2.5791e-01, -2.4481e+00, -2.6439e+00],\n",
      "         [ 3.3801e-01, -1.4531e+00, -1.9651e+00],\n",
      "         ...,\n",
      "         [ 4.9312e-02, -2.6316e+00,  3.6037e-01],\n",
      "         [ 4.4601e-02, -2.6508e+00, -2.0969e+00],\n",
      "         [-1.6606e-01, -3.3430e+00, -2.3495e+00]],\n",
      "\n",
      "        [[-2.7859e-01, -2.2744e+00, -4.3228e+00],\n",
      "         [ 4.1435e-02, -2.1143e+00,  3.6721e-01],\n",
      "         [ 3.0702e-01, -2.9523e+00, -3.0534e+00],\n",
      "         ...,\n",
      "         [ 5.2562e-02, -2.4589e+00, -1.1688e+00],\n",
      "         [ 1.6237e-01, -7.3186e-01, -2.0253e-01],\n",
      "         [ 3.2200e-01, -2.3405e+00, -3.2339e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-136.0648, grad_fn=<SumBackward0>)\n",
      "loss: tensor(136.0648, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (174,)\n",
      "type(pred): <class 'list'> \t pred: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 4/9 [00:02<00:03,  1.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-6.9619e-02, -1.2425e+00, -4.0983e+00],\n",
      "         [-2.3757e-01, -3.6797e+00, -2.8247e+00],\n",
      "         [ 2.9246e-01, -2.1150e+00, -2.7245e+00],\n",
      "         ...,\n",
      "         [ 4.4367e-03, -3.1577e+00, -4.7629e-01],\n",
      "         [ 7.6129e-02, -2.3145e+00, -1.6580e+00],\n",
      "         [ 9.1136e-02, -1.1967e+00, -1.6243e+00]],\n",
      "\n",
      "        [[-2.2823e-01, -1.6975e+00, -3.4500e+00],\n",
      "         [ 1.7758e-01, -5.2783e-01, -1.5670e+00],\n",
      "         [-5.3029e-02, -1.0564e+00, -1.2220e+00],\n",
      "         ...,\n",
      "         [ 1.5427e-01, -3.2241e+00, -1.1602e+00],\n",
      "         [-6.0018e-02, -2.1977e-01, -2.4421e+00],\n",
      "         [ 3.2540e-02, -1.9371e+00, -2.0958e+00]],\n",
      "\n",
      "        [[-7.9899e-03, -1.6457e+00, -3.3188e+00],\n",
      "         [-4.3081e-04, -2.9176e+00, -1.5425e+00],\n",
      "         [ 1.5717e-01, -2.9923e+00, -4.5138e+00],\n",
      "         ...,\n",
      "         [ 2.3443e-01, -3.5112e+00, -1.3713e+00],\n",
      "         [-1.3563e-02, -6.2075e-01, -3.4900e+00],\n",
      "         [-1.0869e-01, -1.8700e+00, -2.6894e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.0078e-02,  1.2977e+00, -2.4729e+00],\n",
      "         [ 7.9815e-02, -2.3153e+00, -2.0303e+00],\n",
      "         [-1.6928e-02, -2.0591e+00, -1.5431e+00],\n",
      "         ...,\n",
      "         [ 2.2881e-02, -5.5780e+00, -8.5331e-01],\n",
      "         [-1.8188e-01, -2.8742e+00,  8.0030e-01],\n",
      "         [-7.7950e-02, -5.3483e+00, -2.3578e+00]],\n",
      "\n",
      "        [[ 1.1332e-01, -1.0192e+00, -3.8063e+00],\n",
      "         [ 2.9391e-01, -3.7457e+00, -2.6442e+00],\n",
      "         [ 1.2083e-01, -3.0429e+00, -3.1297e+00],\n",
      "         ...,\n",
      "         [-3.9007e-02, -2.1314e+00, -9.1783e-01],\n",
      "         [-1.2992e-01, -2.0271e+00, -2.2496e+00],\n",
      "         [ 9.7588e-02, -1.5624e+00, -1.5224e+00]],\n",
      "\n",
      "        [[-2.9006e-02, -2.9186e+00, -4.8413e+00],\n",
      "         [ 1.7092e-02, -3.9717e+00, -2.0807e+00],\n",
      "         [-2.0315e-02, -7.3955e-01, -2.6350e+00],\n",
      "         ...,\n",
      "         [-3.6490e-01, -3.3388e+00, -2.2220e+00],\n",
      "         [ 3.4632e-01, -8.3556e-01, -2.6853e+00],\n",
      "         [-8.2094e-02,  5.4407e-02, -6.7059e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-130.7575, grad_fn=<SumBackward0>)\n",
      "loss: tensor(130.7575, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (163,)\n",
      "type(pred): <class 'list'> \t pred: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 5/9 [00:03<00:02,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.0909, -1.1463, -1.9881],\n",
      "         [ 0.5376, -1.2751, -4.3359],\n",
      "         [ 0.1548, -1.7161, -2.4405],\n",
      "         ...,\n",
      "         [ 0.1194, -3.8655, -1.6727],\n",
      "         [ 0.0423, -2.4193, -3.4472],\n",
      "         [-0.2919, -1.9072, -3.0500]],\n",
      "\n",
      "        [[ 0.1285, -2.1985, -2.0838],\n",
      "         [ 0.1722, -0.4222, -3.9535],\n",
      "         [ 0.3461, -1.3455, -0.2568],\n",
      "         ...,\n",
      "         [ 0.0448, -3.5530, -1.8029],\n",
      "         [-0.0460, -1.4812, -2.5301],\n",
      "         [ 0.1032, -3.2742, -2.9447]],\n",
      "\n",
      "        [[-0.1331, -0.1069, -4.1611],\n",
      "         [ 0.2765, -3.7668, -3.7821],\n",
      "         [ 0.2910,  0.0085, -5.2116],\n",
      "         ...,\n",
      "         [ 0.3325, -2.5419, -0.9444],\n",
      "         [-0.1787, -0.9768, -0.2594],\n",
      "         [ 0.1123, -3.1020, -1.8346]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0954, -2.9687, -1.6285],\n",
      "         [-0.1941, -4.1195, -3.2659],\n",
      "         [ 0.0098, -3.3605, -2.0789],\n",
      "         ...,\n",
      "         [ 0.4158, -4.9028, -3.1964],\n",
      "         [ 0.1537, -3.1426, -0.1400],\n",
      "         [-0.0923, -3.1481, -2.3448]],\n",
      "\n",
      "        [[-0.0486, -2.4461, -1.2232],\n",
      "         [ 0.2308, -3.6172, -1.8440],\n",
      "         [ 0.1300, -2.3537, -2.3696],\n",
      "         ...,\n",
      "         [-0.0818, -3.1195, -1.7661],\n",
      "         [ 0.1498, -1.5063, -1.6335],\n",
      "         [-0.0218, -0.6359, -3.0967]],\n",
      "\n",
      "        [[-0.0769, -0.2953, -3.5512],\n",
      "         [ 0.2841, -3.3951, -2.1453],\n",
      "         [ 0.2007, -2.3458, -4.9394],\n",
      "         ...,\n",
      "         [ 0.3528, -1.9662, -0.8983],\n",
      "         [-0.2221, -2.5702, -1.3208],\n",
      "         [-0.0918, -1.7491, -3.0192]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-151.4169, grad_fn=<SumBackward0>)\n",
      "loss: tensor(151.4169, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (179,)\n",
      "type(pred): <class 'list'> \t pred: 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 6/9 [00:04<00:02,  1.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-9.1021e-02, -3.7859e-01, -3.8068e+00],\n",
      "         [ 1.2076e-01, -1.6526e+00, -1.7702e+00],\n",
      "         [ 1.5275e-01, -1.1049e+00, -2.8180e+00],\n",
      "         ...,\n",
      "         [-1.5657e-01, -2.1210e+00, -3.4001e+00],\n",
      "         [ 1.4621e-01, -3.1625e+00, -1.7782e+00],\n",
      "         [ 1.5630e-01, -2.0193e+00, -2.4883e+00]],\n",
      "\n",
      "        [[ 4.7565e-04, -2.4938e+00, -4.0892e+00],\n",
      "         [ 2.0352e-01, -1.6028e+00, -5.0253e+00],\n",
      "         [-6.9135e-02, -1.2609e+00, -1.5520e+00],\n",
      "         ...,\n",
      "         [ 1.3261e-01, -2.6054e+00, -3.2973e+00],\n",
      "         [-3.6978e-04, -3.3927e+00, -1.9461e+00],\n",
      "         [-2.0271e-01, -6.0512e-01, -3.8477e+00]],\n",
      "\n",
      "        [[-1.5797e-01, -2.0264e+00, -3.4148e+00],\n",
      "         [-1.3138e-01, -3.7796e+00, -2.5546e+00],\n",
      "         [-2.2015e-02, -1.3140e+00, -2.7611e+00],\n",
      "         ...,\n",
      "         [ 1.0849e-01, -1.9322e+00, -1.4169e-01],\n",
      "         [ 2.6736e-01, -1.6828e+00,  1.9971e-01],\n",
      "         [-9.6384e-02, -3.0543e+00, -1.2798e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0037e-01, -3.1360e+00, -3.2808e+00],\n",
      "         [ 1.2880e-01, -1.8493e+00, -4.1881e+00],\n",
      "         [ 6.3403e-01, -1.1775e+00, -9.3597e-01],\n",
      "         ...,\n",
      "         [-7.4896e-02, -1.6164e+00, -9.8723e-01],\n",
      "         [ 4.6192e-03, -3.0022e+00, -1.5111e+00],\n",
      "         [-2.2282e-01, -1.6799e+00, -2.6184e+00]],\n",
      "\n",
      "        [[-1.6224e-01, -1.9272e+00, -3.8078e+00],\n",
      "         [-2.3678e-01, -2.0484e+00, -3.8175e+00],\n",
      "         [ 1.4296e-01, -2.4162e+00, -1.3354e+00],\n",
      "         ...,\n",
      "         [ 4.9697e-01, -4.7315e+00,  1.5651e-01],\n",
      "         [ 2.7571e-01, -2.3895e+00, -3.6556e+00],\n",
      "         [ 2.1338e-01, -1.5085e+00, -1.9451e+00]],\n",
      "\n",
      "        [[-1.7233e-01, -2.6385e+00, -4.8815e+00],\n",
      "         [ 1.2319e-01, -2.6154e+00, -1.6497e+00],\n",
      "         [ 9.4999e-02, -1.8716e+00, -3.5178e+00],\n",
      "         ...,\n",
      "         [ 1.6470e-01, -4.9553e-01, -2.9747e+00],\n",
      "         [ 2.8083e-01, -3.5194e+00, -2.8946e+00],\n",
      "         [ 3.8213e-02, -5.9076e-01, -1.9183e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-119.8387, grad_fn=<SumBackward0>)\n",
      "loss: tensor(119.8387, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (185,)\n",
      "type(pred): <class 'list'> \t pred: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 7/9 [00:05<00:01,  1.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 0.0953, -0.4997, -3.7237],\n",
      "         [-0.0070, -3.0579, -3.9499],\n",
      "         [ 0.1505, -1.1369, -0.8483],\n",
      "         ...,\n",
      "         [-0.0218, -2.9557, -1.7668],\n",
      "         [ 0.2134, -1.4800, -5.2057],\n",
      "         [-0.1336, -2.1251, -4.1442]],\n",
      "\n",
      "        [[-0.0225, -2.4613, -1.1412],\n",
      "         [-0.1664, -3.2207,  0.2738],\n",
      "         [-0.1841, -2.6735, -1.5859],\n",
      "         ...,\n",
      "         [-0.0313, -3.4915, -1.7994],\n",
      "         [ 0.1299, -4.3781, -0.4472],\n",
      "         [ 0.0421, -2.3844, -1.3450]],\n",
      "\n",
      "        [[-0.0746, -1.0954, -2.9710],\n",
      "         [ 0.3305, -0.1043, -0.9825],\n",
      "         [-0.0289, -2.1483, -2.0442],\n",
      "         ...,\n",
      "         [ 0.2269, -0.9105, -1.2824],\n",
      "         [-0.1355, -3.0825, -4.6367],\n",
      "         [-0.1333, -2.2756, -3.5990]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1785, -0.9743, -4.6100],\n",
      "         [ 0.0995, -4.9718, -3.8984],\n",
      "         [ 0.0700, -4.9644, -2.5214],\n",
      "         ...,\n",
      "         [-0.1595, -3.6095, -1.9642],\n",
      "         [ 0.2155, -3.4579, -3.3107],\n",
      "         [ 0.0851, -4.2540, -3.2138]],\n",
      "\n",
      "        [[ 0.2136, -1.8304, -4.3083],\n",
      "         [-0.1316, -1.7439, -1.6343],\n",
      "         [ 0.0890, -2.1068, -3.0114],\n",
      "         ...,\n",
      "         [ 0.1459, -3.0543, -2.3160],\n",
      "         [ 0.0481, -2.5274, -1.4686],\n",
      "         [-0.0617, -3.6642, -1.2511]],\n",
      "\n",
      "        [[ 0.0059, -0.8302, -1.9356],\n",
      "         [ 0.0465, -1.1458, -1.2080],\n",
      "         [ 0.3037,  0.3461, -3.8099],\n",
      "         ...,\n",
      "         [ 0.0053, -2.4937, -0.4057],\n",
      "         [ 0.0275, -1.5214, -2.8843],\n",
      "         [-0.2657, -2.9406,  0.6802]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-125.9810, grad_fn=<SumBackward0>)\n",
      "loss: tensor(125.9810, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (172,)\n",
      "type(pred): <class 'list'> \t pred: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 8/9 [00:05<00:00,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.1697, -4.1428, -3.0609],\n",
      "         [ 0.2448, -2.3178, -1.8999],\n",
      "         [ 0.3745, -1.2876, -4.9503],\n",
      "         ...,\n",
      "         [ 0.2309, -0.8465,  0.8122],\n",
      "         [-0.0574, -2.1634, -1.9664],\n",
      "         [ 0.0470, -3.0718, -2.2614]],\n",
      "\n",
      "        [[ 0.2565, -3.0629, -4.3734],\n",
      "         [ 0.2863, -1.5444, -3.5434],\n",
      "         [ 0.0817, -4.6265, -3.2113],\n",
      "         ...,\n",
      "         [ 0.0172, -3.3401, -2.3478],\n",
      "         [-0.2140, -0.1151,  0.0427],\n",
      "         [ 0.1470, -3.1268, -4.1743]],\n",
      "\n",
      "        [[-0.0253, -1.4728, -4.6413],\n",
      "         [ 0.1627, -3.8151, -4.6945],\n",
      "         [-0.0260, -1.6244, -1.6239],\n",
      "         ...,\n",
      "         [ 0.1645, -1.3211, -2.0043],\n",
      "         [-0.1444, -2.2649, -1.4568],\n",
      "         [ 0.2286, -3.6340, -0.1312]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0993, -1.6226, -4.1840],\n",
      "         [-0.1925, -2.8085, -1.9394],\n",
      "         [ 0.2853, -1.8078, -3.6803],\n",
      "         ...,\n",
      "         [-0.0924, -1.4994, -1.5318],\n",
      "         [ 0.0341, -3.3223, -2.4585],\n",
      "         [-0.0564, -2.0619, -1.5138]],\n",
      "\n",
      "        [[ 0.1913, -0.9341, -2.3374],\n",
      "         [-0.0787, -2.4089, -1.1720],\n",
      "         [ 0.1023, -2.9914, -4.7908],\n",
      "         ...,\n",
      "         [-0.1629, -2.5390, -3.1781],\n",
      "         [ 0.4040, -2.1204, -1.5027],\n",
      "         [-0.1385, -2.2703, -4.8051]],\n",
      "\n",
      "        [[ 0.0179, -2.5288, -3.8734],\n",
      "         [-0.2957, -4.4148, -3.3862],\n",
      "         [ 0.0998, -0.9492, -1.3549],\n",
      "         ...,\n",
      "         [-0.0940, -2.5332, -3.3995],\n",
      "         [ 0.0542, -2.7420, -4.1517],\n",
      "         [-0.1437, -2.7730, -2.5837]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-149.5617, grad_fn=<SumBackward0>)\n",
      "loss: tensor(149.5617, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (164,)\n",
      "type(pred): <class 'list'> \t pred: 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.38it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-1.5896e-02, -3.3970e+00, -5.2326e+00],\n",
      "         [ 2.2352e-01, -2.4423e+00, -3.0202e+00],\n",
      "         [ 2.1464e-01, -2.2293e+00, -3.6183e+00],\n",
      "         ...,\n",
      "         [ 5.7780e-02, -3.5945e+00, -2.4663e+00],\n",
      "         [-3.6316e-02, -3.6038e+00, -4.4765e+00],\n",
      "         [-1.2543e-01, -4.1533e+00, -4.4135e+00]],\n",
      "\n",
      "        [[-2.6967e-01, -1.5162e+00, -5.2024e+00],\n",
      "         [ 2.3567e-01, -2.6074e+00, -1.4636e+00],\n",
      "         [ 2.6106e-01, -1.0654e+00, -3.9589e+00],\n",
      "         ...,\n",
      "         [-7.0471e-02, -5.2367e+00, -1.9483e+00],\n",
      "         [ 8.6165e-02, -3.5651e+00, -2.4136e+00],\n",
      "         [-1.7553e-01, -4.0702e+00, -2.1901e+00]],\n",
      "\n",
      "        [[-3.3476e-01, -8.6336e-01, -2.4282e+00],\n",
      "         [-3.3052e-01, -1.1323e+00, -3.7934e+00],\n",
      "         [-2.2566e-02, -1.7576e+00, -1.6989e+00],\n",
      "         ...,\n",
      "         [-1.3102e-01, -7.8184e-01, -1.3861e+00],\n",
      "         [ 1.5264e-01, -3.4564e+00, -4.3978e+00],\n",
      "         [-1.5433e-01, -1.4518e+00, -1.3312e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.2184e-02, -1.6095e+00, -2.6080e+00],\n",
      "         [ 1.3447e-01, -4.6989e+00, -1.7592e+00],\n",
      "         [ 2.8863e-01, -2.8001e+00, -1.9276e+00],\n",
      "         ...,\n",
      "         [-2.4530e-01, -2.5629e+00, -6.2266e-01],\n",
      "         [ 2.1063e-01,  4.8419e-02, -3.7340e+00],\n",
      "         [-2.1005e-02, -3.9331e+00, -2.2404e+00]],\n",
      "\n",
      "        [[-1.5763e-01, -1.7465e+00, -2.7709e+00],\n",
      "         [ 4.0743e-02, -3.1354e+00, -5.8746e+00],\n",
      "         [ 3.7803e-01, -2.3409e+00, -3.0794e+00],\n",
      "         ...,\n",
      "         [ 4.6535e-01, -1.5329e+00, -2.6765e+00],\n",
      "         [-1.0728e-02, -2.5055e+00, -1.7178e+00],\n",
      "         [-2.2335e-03, -3.5360e+00, -1.3235e+00]],\n",
      "\n",
      "        [[ 3.7783e-02, -2.4576e+00, -9.9472e-01],\n",
      "         [-1.9641e-02, -3.4742e+00, -5.9902e+00],\n",
      "         [ 4.2566e-02, -2.8009e+00,  6.5100e-01],\n",
      "         ...,\n",
      "         [ 4.6791e-02, -1.5985e+00, -2.4359e+00],\n",
      "         [ 1.1755e-02, -1.6147e+00, -2.7789e+00],\n",
      "         [ 4.2244e-02, -4.7204e+00, -1.9139e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-144.5223, grad_fn=<SumBackward0>)\n",
      "loss: tensor(144.5223, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (166,)\n",
      "type(pred): <class 'list'> \t pred: 166\n",
      "\n",
      "\tTraining Loss: 138.6247075398763\n",
      "\n",
      "\tTraining acc: 0.7412311265123764\n",
      "\n",
      "\tTraining prec: 0.6537295079975973\n",
      "\n",
      "\tTraining rec: 0.7412311265123764\n",
      "\n",
      "\tTraining f1: 0.6907966422997374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[-0.0064, -1.9173, -3.9340],\n",
      "         [ 0.1018, -2.4849, -2.9956],\n",
      "         [ 0.0357, -2.0614, -3.1099],\n",
      "         ...,\n",
      "         [ 0.0301, -1.6037, -3.4176],\n",
      "         [ 0.0986, -2.6845, -3.7370],\n",
      "         [ 0.1767, -3.1479, -2.8431]],\n",
      "\n",
      "        [[-0.0582, -1.9518, -3.8292],\n",
      "         [ 0.0201, -2.8722, -2.2572],\n",
      "         [ 0.0734, -1.6541, -2.4780],\n",
      "         ...,\n",
      "         [-0.0862, -1.3466, -3.0048],\n",
      "         [ 0.0798, -2.8495, -3.7703],\n",
      "         [ 0.0105, -2.7395, -3.6900]],\n",
      "\n",
      "        [[-0.0324, -1.9782, -3.8001],\n",
      "         [-0.0260, -2.3355, -2.2645],\n",
      "         [ 0.1253, -0.7992, -3.5001],\n",
      "         ...,\n",
      "         [-0.0073, -1.6832, -3.3983],\n",
      "         [ 0.0697, -2.6787, -3.7323],\n",
      "         [ 0.1451, -3.0726, -2.9487]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0289, -2.2477, -3.8644],\n",
      "         [ 0.2262, -2.6819, -2.9998],\n",
      "         [ 0.1659, -2.8117, -3.6817],\n",
      "         ...,\n",
      "         [ 0.0106, -2.0159, -3.3314],\n",
      "         [ 0.0997, -2.8661, -3.6934],\n",
      "         [ 0.1612, -3.4599, -2.8243]],\n",
      "\n",
      "        [[-0.0369, -2.2093, -3.6541],\n",
      "         [-0.0141, -2.8396, -2.4037],\n",
      "         [ 0.0455, -2.7195, -2.1890],\n",
      "         ...,\n",
      "         [-0.0166, -1.9467, -3.1162],\n",
      "         [ 0.0664, -2.9384, -3.4729],\n",
      "         [ 0.1413, -3.3822, -2.5810]],\n",
      "\n",
      "        [[-0.0409, -1.7938, -3.6368],\n",
      "         [-0.0152, -2.8426, -2.6465],\n",
      "         [ 0.0635, -2.1636, -3.9598],\n",
      "         ...,\n",
      "         [-0.0234, -1.6241, -3.2878],\n",
      "         [ 0.0638, -2.5893, -3.6232],\n",
      "         [ 0.1385, -2.9942, -2.9093]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[ 2.7446e-02, -2.1133e+00, -3.4432e+00],\n",
      "         [ 3.6170e-02, -2.9178e+00, -2.2258e+00],\n",
      "         [ 9.7730e-02, -2.6936e+00, -2.1287e+00],\n",
      "         ...,\n",
      "         [ 3.6264e-02, -1.8179e+00, -2.9650e+00],\n",
      "         [ 1.0977e-01, -2.8440e+00, -3.3049e+00],\n",
      "         [ 1.9863e-01, -3.2948e+00, -2.4898e+00]],\n",
      "\n",
      "        [[-1.6446e-02, -2.1666e+00, -3.8256e+00],\n",
      "         [ 8.5817e-03, -2.7860e+00, -2.6861e+00],\n",
      "         [ 7.8426e-02, -2.5022e+00, -2.4766e+00],\n",
      "         ...,\n",
      "         [ 1.7515e-02, -1.7518e+00, -3.4102e+00],\n",
      "         [ 9.2297e-02, -2.8107e+00, -3.6907e+00],\n",
      "         [ 1.6984e-01, -3.1964e+00, -2.9222e+00]],\n",
      "\n",
      "        [[-1.4599e-02, -1.9527e+00, -3.5313e+00],\n",
      "         [ 5.7966e-03, -2.7386e+00, -2.3655e+00],\n",
      "         [ 5.9156e-02, -2.4955e+00, -2.1724e+00],\n",
      "         ...,\n",
      "         [ 4.8009e-03, -1.7427e+00, -3.1182e+00],\n",
      "         [ 8.4889e-02, -2.6695e+00, -3.4786e+00],\n",
      "         [ 1.5135e-01, -3.2006e+00, -2.6652e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.8032e-03, -2.0957e+00, -3.6734e+00],\n",
      "         [ 7.3810e-02, -2.6896e+00, -3.9102e+00],\n",
      "         [ 7.6904e-02, -1.4183e+00, -2.8390e+00],\n",
      "         ...,\n",
      "         [ 2.7561e-02, -1.7129e+00, -3.3117e+00],\n",
      "         [ 9.7127e-02, -2.7650e+00, -3.6667e+00],\n",
      "         [ 1.7105e-01, -3.2408e+00, -2.8515e+00]],\n",
      "\n",
      "        [[-3.9100e-02, -2.0129e+00, -3.8519e+00],\n",
      "         [ 2.6620e-02, -2.4073e+00, -3.2153e+00],\n",
      "         [ 1.0958e-01, -2.6809e+00, -3.2229e+00],\n",
      "         ...,\n",
      "         [-1.1119e-02, -1.7330e+00, -3.3834e+00],\n",
      "         [ 5.4785e-02, -2.7596e+00, -3.7157e+00],\n",
      "         [ 1.3535e-01, -3.1458e+00, -2.9347e+00]],\n",
      "\n",
      "        [[ 5.9371e-03, -2.0219e+00, -4.1892e+00],\n",
      "         [-1.0974e-03, -2.5148e+00, -2.4276e+00],\n",
      "         [ 1.2897e-01, -2.3492e+00, -3.6952e+00],\n",
      "         ...,\n",
      "         [ 2.9684e-02, -1.7106e+00, -3.7586e+00],\n",
      "         [ 1.1337e-01, -2.7836e+00, -3.9252e+00],\n",
      "         [ 1.9341e-01, -3.2486e+00, -3.1614e+00]]])\n",
      "\toutput_5: torch.Size([2, 52, 3])\n",
      "tensor([[[-4.7533e-02, -1.9184e+00, -3.8250e+00],\n",
      "         [ 5.2385e-02, -3.2009e+00, -3.5144e+00],\n",
      "         [ 6.6776e-02, -3.1825e+00, -3.5938e+00],\n",
      "         [-6.1406e-02, -2.5773e+00, -2.8765e+00],\n",
      "         [ 1.2292e-01, -3.1983e+00, -3.5707e+00],\n",
      "         [ 4.6960e-02, -2.3637e+00, -2.5685e+00],\n",
      "         [ 6.1001e-02, -2.4343e+00, -2.8938e+00],\n",
      "         [-3.8286e-03, -3.1218e+00, -4.1471e+00],\n",
      "         [ 3.6966e-02, -2.6135e+00, -3.5417e+00],\n",
      "         [ 9.6397e-02, -3.3939e+00, -2.5963e+00],\n",
      "         [ 5.0087e-02, -1.6375e+00, -2.0475e+00],\n",
      "         [-2.1299e-02, -2.6662e+00, -2.1631e+00],\n",
      "         [ 9.7459e-02, -2.9900e+00, -2.4617e+00],\n",
      "         [-5.8267e-02, -1.0438e+00, -2.1933e+00],\n",
      "         [-8.2273e-02, -2.4485e+00, -2.2025e+00],\n",
      "         [ 1.2577e-01, -3.0263e+00, -3.5865e+00],\n",
      "         [ 2.7477e-01, -2.6999e+00, -2.9373e+00],\n",
      "         [ 1.0279e-01, -2.5678e+00, -2.6576e+00],\n",
      "         [-1.8423e-02, -2.1974e+00, -3.3228e+00],\n",
      "         [ 1.6977e-02, -3.0466e+00, -2.3719e+00],\n",
      "         [ 1.6191e-01, -2.5855e+00, -2.9438e+00],\n",
      "         [-5.8099e-03, -2.5335e+00, -3.7715e+00],\n",
      "         [ 2.9079e-02, -2.5102e+00, -2.1383e+00],\n",
      "         [-1.5001e-01, -2.0625e+00, -3.4659e+00],\n",
      "         [-3.1177e-02, -3.2401e+00, -2.6802e+00],\n",
      "         [-4.6094e-02, -2.8920e+00, -3.7414e+00],\n",
      "         [-2.0508e-02, -2.9490e+00, -3.3107e+00],\n",
      "         [ 5.3661e-02, -1.8475e+00, -3.4896e+00],\n",
      "         [ 2.9316e-02, -2.1242e+00, -2.6582e+00],\n",
      "         [-6.9648e-02, -1.8215e+00, -3.0494e+00],\n",
      "         [-9.6933e-02, -2.6180e+00, -3.8508e+00],\n",
      "         [-1.7784e-02, -2.0757e+00, -3.7419e+00],\n",
      "         [ 1.0772e-02, -2.1677e+00, -2.0644e+00],\n",
      "         [ 9.1447e-02, -2.4703e+00, -3.6479e+00],\n",
      "         [ 2.1612e-02, -2.3384e+00, -1.7386e+00],\n",
      "         [ 1.0617e-02, -2.7584e+00, -3.1556e+00],\n",
      "         [ 6.7803e-02, -2.2742e+00, -2.3905e+00],\n",
      "         [ 6.7895e-02, -3.0579e+00, -3.0880e+00],\n",
      "         [ 3.4730e-02, -3.0504e+00, -3.5854e+00],\n",
      "         [ 2.7871e-03, -1.7914e+00, -2.6997e+00],\n",
      "         [ 7.5306e-02, -3.3189e+00, -3.3436e+00],\n",
      "         [ 1.2555e-01, -2.9662e+00, -2.4193e+00],\n",
      "         [ 2.4865e-01, -2.7195e+00, -2.0578e+00],\n",
      "         [-1.6070e-02, -3.1400e+00, -2.0994e+00],\n",
      "         [ 1.8796e-01, -2.8997e+00, -1.8885e+00],\n",
      "         [ 2.7503e-02, -3.3948e+00, -2.4246e+00],\n",
      "         [-5.2699e-02, -2.8528e+00, -1.7543e+00],\n",
      "         [ 9.6904e-03, -2.5613e+00, -2.6631e+00],\n",
      "         [ 1.2627e-02, -2.9640e+00, -2.2110e+00],\n",
      "         [-2.6256e-02, -1.6394e+00, -3.5975e+00],\n",
      "         [ 4.1346e-02, -2.6711e+00, -3.8573e+00],\n",
      "         [ 1.1813e-01, -3.1625e+00, -3.0133e+00]],\n",
      "\n",
      "        [[-2.1853e-02, -1.8041e+00, -4.0356e+00],\n",
      "         [ 9.3430e-02, -2.2895e+00, -3.1051e+00],\n",
      "         [ 7.7394e-02, -2.1966e+00, -2.5792e+00],\n",
      "         [ 1.1178e-01, -2.5889e+00, -2.7371e+00],\n",
      "         [ 1.7525e-01, -3.0175e+00, -3.7879e+00],\n",
      "         [ 1.3426e-01, -3.0389e+00, -3.8915e+00],\n",
      "         [ 9.0069e-02, -1.5705e+00, -4.0542e+00],\n",
      "         [-6.0735e-02, -1.2514e+00, -4.3776e+00],\n",
      "         [ 1.0708e-01, -2.6636e+00, -4.0324e+00],\n",
      "         [-1.7971e-03, -3.3494e+00, -2.9183e+00],\n",
      "         [ 4.9873e-02, -1.6347e+00, -2.1596e+00],\n",
      "         [ 6.7020e-02, -2.3021e+00, -3.2715e+00],\n",
      "         [ 1.6587e-01, -2.8267e+00, -2.4007e+00],\n",
      "         [ 8.2096e-03, -2.1206e+00, -2.5025e+00],\n",
      "         [-1.3788e-02, -2.7685e+00, -1.8174e+00],\n",
      "         [ 1.0433e-01, -1.7584e+00, -2.9394e+00],\n",
      "         [ 1.6944e-01, -2.7639e+00, -3.4499e+00],\n",
      "         [-2.8430e-02, -1.9068e+00, -2.7457e+00],\n",
      "         [ 2.1925e-01, -2.2567e+00, -2.9329e+00],\n",
      "         [ 3.6420e-02, -3.1765e+00, -2.7325e+00],\n",
      "         [ 1.7891e-01, -2.6368e+00, -2.8500e+00],\n",
      "         [ 1.1505e-02, -2.4353e+00, -2.8209e+00],\n",
      "         [ 6.4045e-02, -1.7726e+00, -3.1236e+00],\n",
      "         [ 1.6638e-02, -1.1761e+00, -3.5570e+00],\n",
      "         [ 1.7039e-01, -2.7548e+00, -2.7711e+00],\n",
      "         [-3.3960e-02, -2.1253e+00, -2.9162e+00],\n",
      "         [ 1.8361e-01, -2.0691e+00, -3.9854e+00],\n",
      "         [ 1.4988e-01, -1.9018e+00, -3.5560e+00],\n",
      "         [ 3.4516e-02, -1.5643e+00, -2.8133e+00],\n",
      "         [ 1.1296e-02, -9.3780e-01, -3.8033e+00],\n",
      "         [-6.1668e-03, -2.8442e+00, -3.8009e+00],\n",
      "         [ 6.4886e-02, -1.6683e+00, -3.6151e+00],\n",
      "         [ 1.7565e-01, -1.0266e+00, -2.7508e+00],\n",
      "         [ 2.0744e-01, -2.4297e+00, -3.5079e+00],\n",
      "         [ 5.9346e-02, -2.3856e+00, -2.8945e+00],\n",
      "         [ 2.4420e-02, -2.6741e+00, -3.4920e+00],\n",
      "         [ 1.5014e-01, -2.4245e+00, -2.5451e+00],\n",
      "         [ 1.7197e-01, -1.6915e+00, -3.2438e+00],\n",
      "         [ 2.1170e-01, -2.7787e+00, -3.7321e+00],\n",
      "         [ 1.7991e-01, -7.0884e-01, -3.1925e+00],\n",
      "         [ 1.3168e-01, -3.1247e+00, -3.1558e+00],\n",
      "         [ 6.6199e-02, -2.8533e+00, -1.7084e+00],\n",
      "         [ 7.6992e-02, -1.9355e+00, -1.8965e+00],\n",
      "         [ 1.1618e-01, -3.0877e+00, -2.2858e+00],\n",
      "         [ 1.3183e-01, -2.2672e+00, -2.9673e+00],\n",
      "         [ 7.2289e-02, -3.2809e+00, -2.5864e+00],\n",
      "         [-2.2051e-02, -2.6230e+00, -1.8824e+00],\n",
      "         [ 3.7594e-02, -2.3519e+00, -2.9041e+00],\n",
      "         [ 4.9325e-02, -2.8483e+00, -2.2914e+00],\n",
      "         [ 2.3348e-02, -1.4046e+00, -3.5661e+00],\n",
      "         [ 9.3453e-02, -2.5380e+00, -3.8783e+00],\n",
      "         [ 1.6931e-01, -2.9510e+00, -3.0670e+00]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\u001b[A\n",
      "Epoch:   7%|▋         | 4/55 [00:37<07:46,  9.15s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Loss: 85.18372408548991\n",
      "\n",
      "\tValidation acc: 0.8599845824558683\n",
      "\n",
      "\tValidation prec: 0.7404621980146011\n",
      "\n",
      "\tValidation rec: 0.8599845824558683\n",
      "\n",
      "\tValidation f1: 0.7955232028608256\n",
      "EarlyStopping counter: 1 out of 10\n",
      "<====================== Epoch 5 ======================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 1/9 [00:01<00:09,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 0.1629, -3.7497, -3.5134],\n",
      "         [-0.0821, -0.9331, -3.8235],\n",
      "         [ 0.3986, -0.9370, -3.0846],\n",
      "         ...,\n",
      "         [-0.2482, -4.0095, -2.4878],\n",
      "         [ 0.0679, -0.2487, -1.8749],\n",
      "         [ 0.2189, -0.8829, -4.5293]],\n",
      "\n",
      "        [[-0.1396, -1.7391, -4.3639],\n",
      "         [-0.0501, -4.7535, -3.1988],\n",
      "         [ 0.0693, -1.5599, -3.5301],\n",
      "         ...,\n",
      "         [-0.0476, -1.8136, -1.0758],\n",
      "         [-0.1698, -1.8153,  0.4626],\n",
      "         [-0.1211, -2.2378, -3.0038]],\n",
      "\n",
      "        [[ 0.0880, -2.5423, -3.8367],\n",
      "         [-0.2386, -1.9068, -4.9508],\n",
      "         [ 0.0763, -2.2278, -2.8102],\n",
      "         ...,\n",
      "         [ 0.0203, -4.4959, -0.2899],\n",
      "         [ 0.0079, -1.4239, -1.5351],\n",
      "         [-0.1474, -1.5375, -0.1797]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0993,  0.0157, -5.0838],\n",
      "         [-0.2071, -2.2819, -3.7920],\n",
      "         [ 0.3245, -2.4410, -4.1053],\n",
      "         ...,\n",
      "         [-0.0339, -1.5935, -0.3014],\n",
      "         [ 0.2398, -1.9871, -1.5712],\n",
      "         [-0.1760, -4.3280, -3.0145]],\n",
      "\n",
      "        [[-0.1024, -1.7496, -3.2651],\n",
      "         [-0.0831, -3.8699, -1.7455],\n",
      "         [-0.1233, -1.7945, -2.4404],\n",
      "         ...,\n",
      "         [ 0.2509, -4.3690, -0.2053],\n",
      "         [-0.0298,  0.9697, -1.5766],\n",
      "         [-0.2348, -4.2552, -1.9423]],\n",
      "\n",
      "        [[ 0.2597, -1.9088, -3.1604],\n",
      "         [ 0.4106, -2.7066, -3.1876],\n",
      "         [ 0.2041, -1.4658, -4.2277],\n",
      "         ...,\n",
      "         [-0.1742, -3.5180, -2.5135],\n",
      "         [ 0.4844, -1.9763, -2.2287],\n",
      "         [ 0.0828, -1.9803, -0.2550]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-173.4568, grad_fn=<SumBackward0>)\n",
      "loss: tensor(173.4568, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (190,)\n",
      "type(pred): <class 'list'> \t pred: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 2/9 [00:02<00:08,  1.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 0.1920, -3.4970, -4.6041],\n",
      "         [-0.0880, -3.0295, -3.5162],\n",
      "         [ 0.4899, -1.2988, -2.1431],\n",
      "         ...,\n",
      "         [ 0.1685, -2.3965, -3.5720],\n",
      "         [-0.2186, -2.0421, -4.6057],\n",
      "         [ 0.1028, -2.1858,  0.2692]],\n",
      "\n",
      "        [[-0.0551,  0.1375, -4.3631],\n",
      "         [ 0.0262, -1.8601, -4.6904],\n",
      "         [ 0.1378, -2.5242, -1.9859],\n",
      "         ...,\n",
      "         [ 0.1018, -4.0779, -4.7042],\n",
      "         [ 0.1198, -1.6210, -3.5640],\n",
      "         [-0.0216, -3.8088, -4.2638]],\n",
      "\n",
      "        [[ 0.0675,  0.2676, -5.1499],\n",
      "         [ 0.2066, -1.8723, -3.2260],\n",
      "         [-0.1021, -3.1541, -1.2249],\n",
      "         ...,\n",
      "         [ 0.0599, -2.6446, -1.4296],\n",
      "         [-0.1388, -2.1124, -3.1052],\n",
      "         [-0.0955, -2.5550, -3.2038]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0175, -0.6011, -4.0238],\n",
      "         [-0.1498, -1.7243, -3.0033],\n",
      "         [ 0.0103, -2.2145, -3.7385],\n",
      "         ...,\n",
      "         [ 0.1175, -4.5349, -3.8475],\n",
      "         [ 0.1597, -2.5360, -3.0959],\n",
      "         [-0.3283, -0.8401, -3.8538]],\n",
      "\n",
      "        [[-0.0155, -1.8080, -5.3413],\n",
      "         [-0.2476, -1.5942, -1.9954],\n",
      "         [ 0.3423, -0.2512, -3.5171],\n",
      "         ...,\n",
      "         [ 0.0161, -2.4071, -0.3946],\n",
      "         [ 0.0878, -0.9284, -2.1024],\n",
      "         [ 0.1549, -2.6917, -0.6878]],\n",
      "\n",
      "        [[-0.2311, -2.3129, -4.4011],\n",
      "         [ 0.0880, -3.7723, -2.0222],\n",
      "         [-0.1978, -4.9857, -1.1987],\n",
      "         ...,\n",
      "         [-0.0836, -2.8239, -2.9055],\n",
      "         [-0.0627, -2.3626, -0.2457],\n",
      "         [-0.0877, -2.4530, -2.6341]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-152.2940, grad_fn=<SumBackward0>)\n",
      "loss: tensor(152.2940, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (171,)\n",
      "type(pred): <class 'list'> \t pred: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 3/9 [00:03<00:07,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-1.8541e-01, -1.4147e+00, -2.6607e+00],\n",
      "         [-1.9047e-01, -6.2438e-01, -6.3760e-01],\n",
      "         [ 3.5010e-01, -1.8619e+00, -5.8399e-01],\n",
      "         ...,\n",
      "         [ 9.3041e-02, -3.4030e+00, -1.2275e+00],\n",
      "         [ 4.1018e-02, -1.7502e+00, -1.7539e+00],\n",
      "         [-9.0552e-02, -2.8897e+00, -2.2275e+00]],\n",
      "\n",
      "        [[ 7.9899e-02, -2.4448e+00, -1.2557e+00],\n",
      "         [-1.1081e-01, -8.0481e-01, -1.3137e+00],\n",
      "         [ 3.0051e-01, -2.5025e+00, -1.9488e+00],\n",
      "         ...,\n",
      "         [-1.9024e-01, -2.6005e+00, -2.3096e+00],\n",
      "         [ 2.4929e-01, -3.3141e+00, -2.1692e+00],\n",
      "         [-1.4806e-01, -3.9362e+00, -2.2959e+00]],\n",
      "\n",
      "        [[-2.2525e-03, -3.6214e+00, -4.2859e+00],\n",
      "         [ 8.5563e-02, -2.6448e+00, -3.0561e+00],\n",
      "         [-3.1205e-02, -2.4773e+00, -2.3989e+00],\n",
      "         ...,\n",
      "         [ 4.1567e-03, -2.2402e+00, -1.2713e+00],\n",
      "         [-6.2934e-03, -1.3983e+00, -1.6743e+00],\n",
      "         [-9.5846e-02, -3.4500e+00, -3.1313e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.5966e-02, -2.4752e+00, -3.6005e+00],\n",
      "         [-1.1646e-01, -2.3151e+00,  6.2597e-02],\n",
      "         [-3.0142e-02, -1.8479e+00, -2.9610e+00],\n",
      "         ...,\n",
      "         [ 3.2851e-01, -2.9377e+00, -3.1105e+00],\n",
      "         [ 1.3714e-01, -2.7373e+00, -2.1568e+00],\n",
      "         [-7.6889e-02, -3.8105e+00, -1.6574e+00]],\n",
      "\n",
      "        [[-1.0127e-01, -8.1652e-02, -2.9566e+00],\n",
      "         [ 1.4532e-01, -3.2276e+00, -2.3371e+00],\n",
      "         [ 4.9386e-02, -2.1441e+00, -2.5027e+00],\n",
      "         ...,\n",
      "         [ 2.0004e-01, -3.1947e+00,  2.2568e+00],\n",
      "         [-1.1835e-02, -2.5748e+00, -4.5016e+00],\n",
      "         [-9.5084e-02, -3.1755e+00, -2.2200e+00]],\n",
      "\n",
      "        [[ 1.9393e-01, -7.6525e-01, -5.6122e+00],\n",
      "         [ 6.9771e-02, -1.2473e+00, -5.2762e+00],\n",
      "         [-3.9595e-02, -2.2186e+00, -1.2750e+00],\n",
      "         ...,\n",
      "         [-3.0014e-02, -3.9876e+00, -1.9774e+00],\n",
      "         [ 2.3771e-01, -1.5880e+00, -5.4212e+00],\n",
      "         [-1.1355e-01, -1.4600e+00, -3.0370e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-132.4843, grad_fn=<SumBackward0>)\n",
      "loss: tensor(132.4843, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (150,)\n",
      "type(pred): <class 'list'> \t pred: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 4/9 [00:04<00:05,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 1.7861e-01, -3.3973e+00, -4.2662e+00],\n",
      "         [ 2.7493e-03, -1.6413e+00, -4.9461e+00],\n",
      "         [ 2.1997e-01, -1.5539e+00, -9.9953e-01],\n",
      "         ...,\n",
      "         [-1.1152e-01, -2.2590e+00, -2.0293e+00],\n",
      "         [ 1.6035e-01, -2.8331e+00, -1.2400e+00],\n",
      "         [-1.4815e-01, -1.5056e+00, -2.7773e+00]],\n",
      "\n",
      "        [[-3.0426e-02,  2.7070e-01, -3.3766e+00],\n",
      "         [ 1.8915e-01, -7.3322e-01, -5.4290e-01],\n",
      "         [ 1.2219e-01, -4.6716e+00, -2.0747e+00],\n",
      "         ...,\n",
      "         [-8.4501e-02, -3.0503e+00, -2.9329e+00],\n",
      "         [-2.6227e-02, -1.5201e+00, -9.7166e-01],\n",
      "         [ 2.3499e-01, -2.5462e+00, -1.4092e+00]],\n",
      "\n",
      "        [[-1.3317e-01, -1.8205e+00, -3.7858e+00],\n",
      "         [ 4.9480e-01, -3.5993e+00, -3.7132e+00],\n",
      "         [ 8.1522e-03, -1.2167e+00, -3.6721e+00],\n",
      "         ...,\n",
      "         [ 1.2291e-01, -1.7000e+00, -2.2528e+00],\n",
      "         [ 1.4175e-02, -2.9784e+00, -3.0968e+00],\n",
      "         [ 4.3880e-02, -2.9510e+00, -2.3208e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.2408e-01, -2.7591e+00, -2.4833e+00],\n",
      "         [ 1.2390e-01, -3.7919e+00, -3.5003e+00],\n",
      "         [ 1.1555e-01, -2.5257e-01, -3.7507e+00],\n",
      "         ...,\n",
      "         [ 9.1726e-02, -2.6034e+00, -9.7602e-01],\n",
      "         [ 1.5344e-02, -1.2928e+00, -2.0390e+00],\n",
      "         [-1.2237e-01, -1.5964e+00, -2.6291e+00]],\n",
      "\n",
      "        [[-6.7869e-02, -1.7504e+00, -2.8823e+00],\n",
      "         [ 1.5085e-01, -2.7309e+00, -2.0943e+00],\n",
      "         [ 4.3174e-02, -6.4764e-01, -5.1561e+00],\n",
      "         ...,\n",
      "         [ 1.7219e-01, -3.0161e+00, -1.7754e+00],\n",
      "         [ 1.9180e-01, -1.2453e+00, -1.4966e+00],\n",
      "         [-8.5629e-03, -2.2815e+00, -3.3394e+00]],\n",
      "\n",
      "        [[ 8.2128e-02,  1.9719e-01, -1.7792e+00],\n",
      "         [-1.3415e-01, -2.8793e+00, -5.1248e+00],\n",
      "         [ 4.3497e-01, -2.7219e+00, -1.3757e+00],\n",
      "         ...,\n",
      "         [-5.7445e-02, -4.7370e+00, -8.4162e-02],\n",
      "         [-7.3006e-02, -2.1148e+00, -4.0088e+00],\n",
      "         [ 1.4312e-02, -2.9301e+00, -2.8762e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-147.8209, grad_fn=<SumBackward0>)\n",
      "loss: tensor(147.8209, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (171,)\n",
      "type(pred): <class 'list'> \t pred: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 5/9 [00:05<00:03,  1.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-3.2882e-01, -2.3174e+00, -4.7331e+00],\n",
      "         [-1.5714e-02, -2.8607e+00, -3.1775e+00],\n",
      "         [-3.9218e-02, -8.8037e-01, -4.3157e+00],\n",
      "         ...,\n",
      "         [-7.5788e-02, -3.6992e+00, -3.7389e+00],\n",
      "         [ 1.9659e-01, -3.9416e+00, -1.1167e+00],\n",
      "         [-1.3434e-01, -1.5364e+00, -2.1350e+00]],\n",
      "\n",
      "        [[-2.2779e-01, -6.9311e-01, -1.5758e-01],\n",
      "         [ 1.2150e-01, -2.9422e+00, -2.1422e+00],\n",
      "         [-7.2590e-02, -1.9265e+00, -3.6583e+00],\n",
      "         ...,\n",
      "         [ 1.5360e-02, -2.2464e+00, -1.7421e+00],\n",
      "         [ 1.4055e-01, -3.9583e+00, -3.5181e+00],\n",
      "         [-3.9528e-02, -1.7856e+00, -2.5899e+00]],\n",
      "\n",
      "        [[-7.6444e-02, -2.7333e+00, -3.5447e+00],\n",
      "         [-3.1466e-02, -1.3418e+00, -1.7434e+00],\n",
      "         [ 7.4626e-02, -1.4399e+00, -1.5334e+00],\n",
      "         ...,\n",
      "         [-7.0873e-04, -4.0005e+00, -2.4685e+00],\n",
      "         [ 2.9851e-01, -1.2728e+00,  2.0172e+00],\n",
      "         [-1.4989e-01, -2.0024e+00, -2.5299e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.6675e-03, -2.1592e+00, -5.6053e+00],\n",
      "         [ 2.2697e-01, -8.6243e-01, -1.5765e-02],\n",
      "         [ 2.7723e-01, -8.4443e-01, -3.8884e+00],\n",
      "         ...,\n",
      "         [-1.1950e-01, -4.5525e+00, -1.4895e+00],\n",
      "         [ 2.8027e-01, -1.9234e+00, -2.9371e+00],\n",
      "         [-2.6165e-01, -3.7958e+00, -7.2382e-01]],\n",
      "\n",
      "        [[ 6.2862e-02, -2.4679e+00, -2.8178e+00],\n",
      "         [-2.4843e-01, -2.8006e+00, -2.7071e+00],\n",
      "         [-5.7423e-02, -2.0806e+00, -1.7983e+00],\n",
      "         ...,\n",
      "         [ 9.8492e-02, -4.2553e+00, -1.8381e+00],\n",
      "         [ 1.0812e-01, -2.3690e+00, -3.0039e+00],\n",
      "         [ 3.5076e-01, -2.2337e+00, -1.2649e+00]],\n",
      "\n",
      "        [[ 8.6612e-02, -3.8102e+00, -2.5171e+00],\n",
      "         [ 4.3629e-01, -2.2626e+00, -2.5284e+00],\n",
      "         [ 2.8720e-01, -1.9294e+00, -3.0677e+00],\n",
      "         ...,\n",
      "         [ 2.3827e-01, -3.3108e+00,  3.8284e-01],\n",
      "         [ 1.8885e-01, -1.4283e+00, -1.9222e+00],\n",
      "         [-1.2437e-01, -2.0612e+00, -1.8830e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-101.8785, grad_fn=<SumBackward0>)\n",
      "loss: tensor(101.8785, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (171,)\n",
      "type(pred): <class 'list'> \t pred: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 6/9 [00:06<00:02,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-2.6824e-01, -2.0354e+00, -1.1924e+00],\n",
      "         [ 1.9879e-01, -4.4276e+00, -3.3462e+00],\n",
      "         [ 2.0383e-01, -3.0788e+00, -4.8725e+00],\n",
      "         ...,\n",
      "         [-8.7913e-02, -4.2190e+00, -4.6151e+00],\n",
      "         [-7.8732e-02, -1.5694e+00, -5.8789e+00],\n",
      "         [-2.7885e-01, -3.5513e+00, -3.7354e+00]],\n",
      "\n",
      "        [[-9.7328e-02, -7.8735e-01, -2.3706e+00],\n",
      "         [ 1.4805e-01, -1.8432e+00, -1.9034e+00],\n",
      "         [ 1.5933e-01, -3.0159e+00, -2.4947e+00],\n",
      "         ...,\n",
      "         [-2.0444e-01, -4.9778e+00, -2.2888e-01],\n",
      "         [-3.8368e-01, -2.2144e+00, -4.2280e-01],\n",
      "         [ 1.2659e-01, -3.8849e+00, -1.7882e+00]],\n",
      "\n",
      "        [[ 7.4765e-02, -2.9404e+00, -4.4281e+00],\n",
      "         [ 2.8599e-02, -1.3461e+00,  5.1755e-01],\n",
      "         [ 4.1074e-01,  2.4213e-01, -4.2040e+00],\n",
      "         ...,\n",
      "         [ 3.0312e-01, -3.8433e+00, -3.0910e+00],\n",
      "         [ 2.6852e-01, -3.6843e+00, -1.7525e+00],\n",
      "         [-4.0629e-02, -2.8742e+00,  9.0771e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.6345e-01, -1.7674e+00, -2.6192e+00],\n",
      "         [-1.9812e-02, -3.3273e+00, -3.9778e-01],\n",
      "         [ 4.6063e-01, -6.8820e-01, -1.3240e+00],\n",
      "         ...,\n",
      "         [ 1.0984e-02, -4.0751e+00, -2.0762e+00],\n",
      "         [ 2.4556e-01, -1.2285e+00, -5.0074e+00],\n",
      "         [ 1.0664e-01, -3.0772e+00, -3.9452e+00]],\n",
      "\n",
      "        [[ 4.6773e-02, -1.7071e+00, -1.6799e+00],\n",
      "         [ 2.0826e-01, -4.0056e+00, -1.3350e+00],\n",
      "         [-3.8572e-01,  5.4635e-01, -5.1387e+00],\n",
      "         ...,\n",
      "         [ 1.8480e-01, -6.6724e-01, -6.7589e-01],\n",
      "         [ 1.8361e-01, -1.1917e+00, -1.6403e+00],\n",
      "         [ 1.2009e-01, -4.1769e+00, -2.7742e+00]],\n",
      "\n",
      "        [[-1.3464e-01, -2.6517e+00, -3.6635e+00],\n",
      "         [-1.3688e-03, -3.3526e+00, -3.1217e+00],\n",
      "         [ 3.9844e-01, -1.8170e+00, -1.3193e+00],\n",
      "         ...,\n",
      "         [ 2.1222e-01, -3.9305e+00, -2.2957e+00],\n",
      "         [-4.1189e-02, -3.2505e+00, -3.0458e+00],\n",
      "         [ 2.2925e-01, -3.5913e+00, -1.1510e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-151.9967, grad_fn=<SumBackward0>)\n",
      "loss: tensor(151.9967, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (222,)\n",
      "type(pred): <class 'list'> \t pred: 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 7/9 [00:06<00:01,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 1.7400e-01, -6.8675e-01, -5.0701e+00],\n",
      "         [ 1.8335e-01, -2.7968e+00, -2.0572e+00],\n",
      "         [-1.6295e-02, -2.5590e+00,  2.5296e-01],\n",
      "         ...,\n",
      "         [ 1.2028e-01, -2.6500e+00, -2.8441e+00],\n",
      "         [ 2.2995e-01, -3.6331e+00, -9.7637e-01],\n",
      "         [-2.8657e-01, -2.4206e+00, -2.6562e+00]],\n",
      "\n",
      "        [[-5.3082e-02, -2.9898e+00, -6.6033e+00],\n",
      "         [-2.5189e-01, -2.4479e+00,  4.3708e-01],\n",
      "         [ 2.0740e-01, -1.8484e+00, -3.8208e+00],\n",
      "         ...,\n",
      "         [ 2.1176e-01, -2.9474e+00, -1.9130e+00],\n",
      "         [ 7.0085e-02, -4.5499e+00, -2.5405e+00],\n",
      "         [-1.0733e-01, -3.7549e+00, -1.9452e+00]],\n",
      "\n",
      "        [[ 1.0066e-01, -1.3073e+00, -2.6115e+00],\n",
      "         [ 2.1777e-01, -3.6501e+00, -1.6246e+00],\n",
      "         [-1.0616e-01, -2.5695e+00, -5.2192e+00],\n",
      "         ...,\n",
      "         [ 1.4434e-03, -2.1456e+00, -4.3626e+00],\n",
      "         [ 1.2030e-01, -2.2418e+00, -4.3891e+00],\n",
      "         [ 4.2718e-01, -3.7037e+00, -3.7918e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.0830e-02, -2.1589e+00, -2.0842e+00],\n",
      "         [-9.1081e-02, -1.4723e+00, -3.0260e+00],\n",
      "         [ 3.4321e-02, -3.0772e+00, -2.5981e+00],\n",
      "         ...,\n",
      "         [ 1.7469e-01, -7.3387e-01, -1.7583e+00],\n",
      "         [ 5.8297e-02, -4.3487e+00, -7.2204e-01],\n",
      "         [ 1.1582e-01, -4.2519e+00, -8.4554e-01]],\n",
      "\n",
      "        [[ 1.0572e-02,  9.0052e-01, -3.3296e+00],\n",
      "         [-3.5073e-02, -4.1103e+00, -3.0802e+00],\n",
      "         [ 1.0327e-01, -1.1240e+00, -5.9967e+00],\n",
      "         ...,\n",
      "         [ 3.7986e-01, -4.7438e-01, -2.4490e+00],\n",
      "         [ 6.9921e-02, -1.9881e+00, -1.8245e+00],\n",
      "         [-9.3455e-02, -2.2118e+00, -1.2014e+00]],\n",
      "\n",
      "        [[ 2.9480e-01, -3.5254e+00, -5.6335e+00],\n",
      "         [-2.4549e-02, -3.0057e+00, -2.4327e+00],\n",
      "         [ 1.6502e-01, -1.1113e+00, -3.6960e+00],\n",
      "         ...,\n",
      "         [-8.5796e-02, -5.1030e+00, -1.1434e+00],\n",
      "         [ 2.7211e-01, -2.7436e+00, -1.4894e+00],\n",
      "         [ 1.4734e-01, -3.1049e+00, -1.5809e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-113.4533, grad_fn=<SumBackward0>)\n",
      "loss: tensor(113.4533, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (118,)\n",
      "type(pred): <class 'list'> \t pred: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 8/9 [00:07<00:00,  1.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[ 2.7956e-01, -1.4159e+00, -3.7885e+00],\n",
      "         [ 4.0026e-02, -3.2405e+00, -4.2524e+00],\n",
      "         [ 1.6889e-01, -3.1537e+00, -3.7882e+00],\n",
      "         ...,\n",
      "         [ 2.0330e-01, -3.4828e+00, -1.5885e+00],\n",
      "         [ 1.9797e-01, -4.5429e-01, -1.3852e+00],\n",
      "         [-2.4368e-01, -3.0547e+00, -4.5795e+00]],\n",
      "\n",
      "        [[-1.2698e-01, -2.5242e+00, -5.9507e+00],\n",
      "         [ 1.6843e-01, -3.2501e+00,  1.3203e+00],\n",
      "         [ 3.1707e-01, -2.6804e+00, -3.7136e+00],\n",
      "         ...,\n",
      "         [ 3.9845e-02, -3.1003e+00, -1.7620e+00],\n",
      "         [ 7.0550e-02,  7.3342e-02, -2.8498e+00],\n",
      "         [-5.1577e-02, -5.4928e+00,  9.1244e-01]],\n",
      "\n",
      "        [[ 1.0209e-01, -3.0349e+00, -4.2562e+00],\n",
      "         [ 2.1112e-01, -2.3264e+00, -3.8951e+00],\n",
      "         [ 1.1931e-01, -3.1052e+00, -2.9595e+00],\n",
      "         ...,\n",
      "         [-1.0267e-01, -4.3698e+00, -2.2700e+00],\n",
      "         [ 1.2472e-02, -2.1099e+00, -6.6330e-01],\n",
      "         [ 6.3568e-02, -4.4632e+00, -2.1232e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4455e-01, -1.6808e+00, -2.8127e+00],\n",
      "         [ 5.1415e-02, -2.8933e+00, -2.1779e+00],\n",
      "         [ 1.4893e-01, -9.1686e-01, -1.5223e+00],\n",
      "         ...,\n",
      "         [-2.8320e-01, -3.3446e+00, -1.6173e+00],\n",
      "         [ 1.7407e-01, -3.2552e+00, -1.0495e+00],\n",
      "         [-1.5761e-01, -3.7201e+00, -1.5062e+00]],\n",
      "\n",
      "        [[ 2.0491e-01, -1.2320e+00, -4.8896e+00],\n",
      "         [-1.2142e-01, -3.0152e+00, -2.6671e+00],\n",
      "         [-1.1095e-01, -3.4387e+00, -2.6742e+00],\n",
      "         ...,\n",
      "         [-2.9400e-02, -4.5921e+00,  7.9426e-01],\n",
      "         [-1.8741e-01, -7.0124e-01, -2.4757e+00],\n",
      "         [ 3.2478e-01, -3.9507e+00, -2.3789e+00]],\n",
      "\n",
      "        [[ 6.5666e-03, -1.5625e+00, -5.2280e+00],\n",
      "         [ 7.8238e-02, -2.2534e+00, -4.5346e+00],\n",
      "         [-2.6872e-01, -3.3019e+00,  1.0031e-02],\n",
      "         ...,\n",
      "         [ 1.6642e-02, -4.3770e+00, -1.2433e+00],\n",
      "         [ 5.3541e-03, -1.1131e+00, -4.3118e+00],\n",
      "         [ 1.9698e-02, -3.0865e+00, -2.6685e+00]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-133.3609, grad_fn=<SumBackward0>)\n",
      "loss: tensor(133.3609, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (176,)\n",
      "type(pred): <class 'list'> \t pred: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9/9 [00:08<00:00,  1.09it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 57, 3])\n",
      "tensor([[[-0.3357, -1.2747, -3.3778],\n",
      "         [-0.1446, -1.7214, -1.3014],\n",
      "         [ 0.3785, -3.4543, -3.1776],\n",
      "         ...,\n",
      "         [ 0.1058, -3.4163, -3.0824],\n",
      "         [ 0.1044, -1.4072,  0.3865],\n",
      "         [ 0.2328, -2.0098, -1.8733]],\n",
      "\n",
      "        [[-0.1231, -1.4941, -3.0913],\n",
      "         [ 0.0257, -3.0413, -3.2591],\n",
      "         [-0.1393,  0.3115, -3.8680],\n",
      "         ...,\n",
      "         [-0.0698, -2.4427, -2.3479],\n",
      "         [ 0.1223, -2.9133, -2.7517],\n",
      "         [-0.1633, -3.7756, -3.1006]],\n",
      "\n",
      "        [[-0.2861, -2.7657, -1.9914],\n",
      "         [-0.2224, -3.3761, -0.5491],\n",
      "         [ 0.0828, -1.4127, -5.6487],\n",
      "         ...,\n",
      "         [-0.1302, -1.5727, -2.6153],\n",
      "         [ 0.1012, -2.3567, -2.5096],\n",
      "         [-0.0652, -0.8777, -2.5072]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0667, -2.8984, -2.2320],\n",
      "         [ 0.4005, -3.7507, -3.1709],\n",
      "         [ 0.1995, -1.1697, -3.1437],\n",
      "         ...,\n",
      "         [ 0.0573, -4.9352, -2.5080],\n",
      "         [-0.0754, -1.9467, -1.3323],\n",
      "         [ 0.1408, -3.5633, -4.3539]],\n",
      "\n",
      "        [[-0.0337, -0.3687, -3.6368],\n",
      "         [-0.2753, -3.4957, -1.2760],\n",
      "         [ 0.3826, -2.9975, -2.5669],\n",
      "         ...,\n",
      "         [ 0.0097, -3.5394, -2.1629],\n",
      "         [-0.0467, -4.1114, -2.6829],\n",
      "         [-0.0422, -4.0890, -2.6801]],\n",
      "\n",
      "        [[-0.2176, -1.9104, -3.8499],\n",
      "         [ 0.2079, -1.4284, -0.2230],\n",
      "         [ 0.0352, -2.6699, -1.1773],\n",
      "         ...,\n",
      "         [-0.1323, -3.8651, -3.7063],\n",
      "         [ 0.1084, -2.0726, -3.3134],\n",
      "         [ 0.0735, -2.7946, -3.3973]]], grad_fn=<StackBackward>)\n",
      "log_likelihood: tensor(-147.3395, grad_fn=<SumBackward0>)\n",
      "loss: tensor(147.3395, grad_fn=<MulBackward0>)\n",
      "mask_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS: (8, 56)\n",
      "bio_tags_without_CLS[mask_tags_without_CLS]: (8, 56, 56)\n",
      "type(true_tags): <class 'numpy.ndarray'> \t true_tags: (202,)\n",
      "type(pred): <class 'list'> \t pred: 202\n",
      "\n",
      "\tTraining Loss: 139.3427793714735\n",
      "\n",
      "\tTraining acc: 0.7509276041984859\n",
      "\n",
      "\tTraining prec: 0.6558267523634468\n",
      "\n",
      "\tTraining rec: 0.7509276041984859\n",
      "\n",
      "\tTraining f1: 0.6949836133238255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[-3.1817e-02, -2.0305e+00, -4.2820e+00],\n",
      "         [-1.3154e-02, -2.4226e+00, -3.0492e+00],\n",
      "         [ 6.2584e-02, -1.7216e+00, -2.7941e+00],\n",
      "         ...,\n",
      "         [-1.0344e-03, -1.8145e+00, -3.9297e+00],\n",
      "         [ 6.2653e-02, -2.6992e+00, -4.3198e+00],\n",
      "         [ 1.5656e-01, -3.2899e+00, -3.5780e+00]],\n",
      "\n",
      "        [[ 1.1125e-02, -2.2395e+00, -4.3338e+00],\n",
      "         [ 5.0902e-03, -2.7494e+00, -2.6284e+00],\n",
      "         [ 1.3445e-01, -2.5584e+00, -3.8704e+00],\n",
      "         ...,\n",
      "         [ 3.5912e-02, -1.9489e+00, -3.9451e+00],\n",
      "         [ 1.1884e-01, -3.0021e+00, -4.0882e+00],\n",
      "         [ 1.9942e-01, -3.4889e+00, -3.3351e+00]],\n",
      "\n",
      "        [[-3.2231e-02, -2.2480e+00, -4.0407e+00],\n",
      "         [-1.9376e-03, -2.9286e+00, -3.0139e+00],\n",
      "         [ 5.7804e-02, -2.6783e+00, -2.8185e+00],\n",
      "         ...,\n",
      "         [ 3.5285e-03, -1.9648e+00, -3.6829e+00],\n",
      "         [ 7.7386e-02, -2.9789e+00, -3.9162e+00],\n",
      "         [ 1.4751e-01, -3.3993e+00, -3.1240e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.5541e-02, -2.0188e+00, -3.7830e+00],\n",
      "         [-8.9730e-03, -3.0732e+00, -2.8434e+00],\n",
      "         [ 6.9442e-02, -2.4115e+00, -4.1261e+00],\n",
      "         ...,\n",
      "         [-1.6995e-02, -1.8689e+00, -3.4785e+00],\n",
      "         [ 6.9395e-02, -2.8185e+00, -3.7878e+00],\n",
      "         [ 1.4468e-01, -3.2448e+00, -3.0870e+00]],\n",
      "\n",
      "        [[-9.1286e-03, -2.1822e+00, -3.6870e+00],\n",
      "         [ 1.2008e-02, -2.9772e+00, -2.5672e+00],\n",
      "         [ 6.5114e-02, -2.7432e+00, -2.3571e+00],\n",
      "         ...,\n",
      "         [ 1.1214e-02, -1.9877e+00, -3.3147e+00],\n",
      "         [ 9.0653e-02, -2.9011e+00, -3.6523e+00],\n",
      "         [ 1.5760e-01, -3.4508e+00, -2.8484e+00]],\n",
      "\n",
      "        [[-3.1257e-02, -2.4416e+00, -3.8165e+00],\n",
      "         [-7.7000e-03, -3.0824e+00, -2.6135e+00],\n",
      "         [ 5.1669e-02, -2.9704e+00, -2.3835e+00],\n",
      "         ...,\n",
      "         [-1.0042e-02, -2.1954e+00, -3.3209e+00],\n",
      "         [ 7.2366e-02, -3.1732e+00, -3.6559e+00],\n",
      "         [ 1.4774e-01, -3.6356e+00, -2.7727e+00]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.62it/s]\u001b[A\n",
      "Epoch:   7%|▋         | 4/55 [00:46<09:54, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\toutput_5: torch.Size([8, 52, 3])\n",
      "tensor([[[ 3.2883e-02, -2.3364e+00, -3.5995e+00],\n",
      "         [ 4.2367e-02, -3.1510e+00, -2.4286e+00],\n",
      "         [ 1.0358e-01, -2.9338e+00, -2.3116e+00],\n",
      "         ...,\n",
      "         [ 4.2651e-02, -2.0574e+00, -3.1618e+00],\n",
      "         [ 1.1552e-01, -3.0694e+00, -3.4802e+00],\n",
      "         [ 2.0484e-01, -3.5386e+00, -2.6737e+00]],\n",
      "\n",
      "        [[-4.2068e-02, -2.1470e+00, -3.9802e+00],\n",
      "         [ 5.8267e-02, -3.4294e+00, -3.6950e+00],\n",
      "         [ 7.2243e-02, -3.4000e+00, -3.7645e+00],\n",
      "         ...,\n",
      "         [-1.9823e-02, -1.8848e+00, -3.7942e+00],\n",
      "         [ 4.7099e-02, -2.9014e+00, -4.0301e+00],\n",
      "         [ 1.2437e-01, -3.4118e+00, -3.1951e+00]],\n",
      "\n",
      "        [[-3.5500e-03, -2.2339e+00, -3.8869e+00],\n",
      "         [ 2.0741e-02, -2.9264e+00, -2.8122e+00],\n",
      "         [ 8.7468e-02, -2.9011e+00, -2.5658e+00],\n",
      "         ...,\n",
      "         [ 2.2035e-02, -2.0335e+00, -3.3835e+00],\n",
      "         [ 1.0810e-01, -3.0286e+00, -3.7887e+00],\n",
      "         [ 1.8873e-01, -3.4513e+00, -2.9560e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.3350e-02, -2.4799e+00, -4.0249e+00],\n",
      "         [ 2.3238e-01, -2.9231e+00, -3.1943e+00],\n",
      "         [ 1.7190e-01, -3.0601e+00, -3.8598e+00],\n",
      "         ...,\n",
      "         [ 1.7074e-02, -2.2648e+00, -3.5334e+00],\n",
      "         [ 1.0556e-01, -3.1016e+00, -3.8731e+00],\n",
      "         [ 1.6754e-01, -3.7131e+00, -3.0121e+00]],\n",
      "\n",
      "        [[-3.3845e-02, -2.2322e+00, -3.9975e+00],\n",
      "         [ 3.2600e-02, -2.6275e+00, -3.4044e+00],\n",
      "         [ 1.1533e-01, -2.9144e+00, -3.3976e+00],\n",
      "         ...,\n",
      "         [-4.8629e-03, -1.9719e+00, -3.5717e+00],\n",
      "         [ 6.0366e-02, -2.9835e+00, -3.8813e+00],\n",
      "         [ 1.4143e-01, -3.3886e+00, -3.1089e+00]],\n",
      "\n",
      "        [[-8.9236e-04, -2.1457e+00, -4.0917e+00],\n",
      "         [ 1.0835e-01, -2.7343e+00, -3.2000e+00],\n",
      "         [ 4.1267e-02, -2.2829e+00, -3.2844e+00],\n",
      "         ...,\n",
      "         [ 3.6573e-02, -1.8489e+00, -3.6167e+00],\n",
      "         [ 1.0433e-01, -2.9145e+00, -3.9142e+00],\n",
      "         [ 1.8291e-01, -3.3964e+00, -3.0290e+00]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-376be3bd73c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Evaluate data for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# batch to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mv_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_token_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_bio_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m  \u001b[0;31m# unpack inputs from dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a7b5e9115285>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mbio_tags_extended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbio_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbio_tags_extended\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token ids (N: {}) and IO tags (N: {}) lengths do not match!\\nids[idx]: {}\\nbio_tags: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbio_tags_extended\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbio_tags_extended\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a7b5e9115285>\u001b[0m in \u001b[0;36mextend_tags\u001b[0;34m(self, tokens_old, tags_old, ids_tokenized_padded)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m#print(F\"\\ntoken_old: {token_old};    tag: {tag}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# first sub token of a word keeps the original bio tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mfirstTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msub_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msub_text\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                         \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_on_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                         \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_token\u001b[0;34m(tok, text)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mtok_extended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_special_tokens_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0msplit_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mfull_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################ TRAINING ######################\n",
    "\n",
    "# initialise the early_stopping object\n",
    "early_stopping = EarlyStopping(patience=early_patience, verbose=True)\n",
    "\n",
    "train_avg_loss = [] # avg training loss per epoch\n",
    "val_avg_loss = [] # avg validation loss per epoch\n",
    "train_avg_acc = [] # avg training accuracy per epoch\n",
    "val_avg_acc = [] # avg val accuracy per epoch\n",
    "n_trained_epochs = 0\n",
    "\n",
    "for epoch in trange(1, epochs+1, desc='Epoch'):\n",
    "    print(\"<\" + \"=\"*22 + F\" Epoch {epoch} \"+ \"=\"*22 + \">\")\n",
    "\n",
    "    \n",
    "    ############ training eval metrics ######################\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    train_prec = []\n",
    "    train_rec = []\n",
    "    train_f1 = []\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad() # gradients get accumulated by default -> clear previous accumulated gradients\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        bio_tags = batch['bio_tags'].to(device)\n",
    "        \n",
    "        # crf in model requires to start with a positive mask label => ignore first token [CLS]\n",
    "        bio_tags_without_CLS = torch.cat([bio_tags[i][1:] for i in range(len(bio_tags))]).view(bio_tags.shape[0],-1)\n",
    "        mask_tags_without_CLS = torch.cat([bio_tags[i][1:] != -100 for i in range(len(bio_tags))]).view(bio_tags.shape[0],-1).byte().to(device) # byte() casts boolean tensor to tensor with 1 and 0 \n",
    "\n",
    "\n",
    "        ################################################\n",
    "        model.train() # set model to training mode\n",
    "#        logits = model(**{\"input_ids\":input_ids, \"attention_mask\":attention_mask, \"token_type_ids\":token_type_ids}) # forward pass\n",
    "        log_likelihood, sequence_of_tags = model(**{\"input_ids\":input_ids\n",
    "                        , \"attention_mask\":attention_mask\n",
    "                        , \"token_type_ids\":token_type_ids\n",
    "                        , \"tags\":bio_tags\n",
    "                        , \"mask_tags_without_CLS\":mask_tags_without_CLS}) # forward pass        \n",
    "\n",
    "        ################################################ \n",
    "        loss = -1 * log_likelihood           \n",
    "        print(\"loss:\", loss)     \n",
    "        loss.backward() # backward pass\n",
    "        ## gradient clipping to control the exploding gradient problem \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optim.step()    # update parameters and take a steup using the computed gradient\n",
    "        scheduler.step()# update learning rate scheduler\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    \n",
    "\n",
    "        ################## Training Performance Measures ##########\n",
    "        bio_tags_without_CLS = bio_tags_without_CLS.detach().to(\"cpu\").numpy()\n",
    "        mask_tags_without_CLS = mask_tags_without_CLS.detach().to(\"cpu\").numpy()\n",
    "        \n",
    "        tags_ids = bio_tags.to('cpu').numpy()\n",
    "        true_tags = bio_tags_without_CLS[mask_tags_without_CLS.astype(bool)] # get Bio tags for tokens only\n",
    "        pred = [item for elem in sequence_of_tags for item in elem] # flatten list of lists\n",
    "\n",
    "        metrics = compute_metrics(pred, true_tags)\n",
    "        train_acc.append(metrics[\"accuracy\"])\n",
    "        train_prec.append(metrics[\"precision\"])\n",
    "        train_rec.append(metrics[\"recall\"])\n",
    "        train_f1.append(metrics[\"f1\"])\n",
    "                          \n",
    "    train_avg_loss.append(np.mean(train_loss))\n",
    "    train_avg_acc.append(np.mean(train_acc))           \n",
    "    print(F'\\n\\tTraining Loss: {np.mean(train_loss)}')\n",
    "    print(F'\\n\\tTraining acc: {np.mean(train_acc)}')\n",
    "    print(F'\\n\\tTraining prec: {np.mean(train_prec)}')\n",
    "    print(F'\\n\\tTraining rec: {np.mean(train_rec)}')\n",
    "    print(F'\\n\\tTraining f1: {np.mean(train_f1)}')\n",
    "\n",
    "    n_trained_epochs += 1\n",
    "\n",
    "                          \n",
    "    ###################################################################################\n",
    "\n",
    "    \n",
    "    ## ---- Validation ------    \n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    val_prec = []\n",
    "    val_rec = []\n",
    "    val_f1 = []\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in tqdm(validation_loader):\n",
    "        batch = tuple(batch[t].to(device) for t in batch)      # batch to GPU\n",
    "        v_input_ids, v_input_mask, v_token_type_ids, v_labels, v_bio_tags = batch  # unpack inputs from dataloader\n",
    "\n",
    "        # crf in model requires to start with a positive mask label => ignore first token [CLS]\n",
    "        v_mask_tags_without_CLS = torch.cat([v_bio_tags[i][1:] != -100 for i in range(len(v_bio_tags))]).view(v_bio_tags.shape[0],-1).byte() # byte() casts boolean tensor to tensor with 1 and 0         \n",
    "        v_bio_tags_without_CLS = torch.cat([v_bio_tags[i][1:] for i in range(len(v_bio_tags))]).view(v_bio_tags.shape[0],-1)\n",
    "   \n",
    "        with torch.no_grad(): # tell model not to compute or store gradients -> saves memory + speeds up validation\n",
    "            model.eval() # put model in evaluation mode for validation set\n",
    "            #logits = model(**{\"input_ids\":v_input_ids, \"attention_mask\":v_input_mask, \"token_type_ids\":v_token_type_ids}) # forward pass, calculates logit predictions\n",
    "            log_likelihood, sequence_of_tags = model(**{\"input_ids\":v_input_ids\n",
    "                                                    , \"attention_mask\":v_input_mask\n",
    "                                                    , \"token_type_ids\":v_token_type_ids\n",
    "                                                    , \"tags\": v_bio_tags\n",
    "                                                    , \"mask_tags_without_CLS\":v_mask_tags_without_CLS}) # forward pass, calculates logit predictions\n",
    "        ######################################################\n",
    "          \n",
    "        v_loss = -1 * log_likelihood        \n",
    "        val_loss.append(v_loss.item())\n",
    "              \n",
    "        #########################################################\n",
    "        # calculate performance measures only on tokens and not subwords or special tokens       \n",
    "        v_bio_tags_without_CLS = v_bio_tags_without_CLS.detach().to(\"cpu\").numpy()\n",
    "        v_mask_tags_without_CLS = v_mask_tags_without_CLS.detach().to(\"cpu\").numpy()\n",
    "        #sequence_of_tags = sequence_of_tags.detach().to(\"cpu\").numpy()\n",
    "        \n",
    "        true_tags = v_bio_tags_without_CLS[v_mask_tags_without_CLS.astype(bool)] # get Bio tags for tokens only\n",
    "        pred = [item for elem in sequence_of_tags for item in elem] # flatten list of lists\n",
    "        \n",
    "        metrics = compute_metrics(pred, true_tags)\n",
    "        val_acc.append(metrics[\"accuracy\"])\n",
    "        val_prec.append(metrics[\"precision\"])\n",
    "        val_rec.append(metrics[\"recall\"])\n",
    "        val_f1.append(metrics[\"f1\"])\n",
    "                              \n",
    "    val_avg_loss.append(np.mean(val_loss))\n",
    "    val_avg_acc.append(np.mean(val_acc))        \n",
    "    print(F'\\n\\tValidation Loss: {np.mean(val_loss)}')\n",
    "    print(F'\\n\\tValidation acc: {np.mean(val_acc)}')\n",
    "    print(F'\\n\\tValidation prec: {np.mean(val_prec)}')\n",
    "    print(F'\\n\\tValidation rec: {np.mean(val_rec)}')\n",
    "    print(F'\\n\\tValidation f1: {np.mean(val_f1)}')\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decreased,\n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    saveModelName = \"./model-causal-span/{}_model_{}_finetuned-{}-epochs-lr_{}.pth\".format(type_, attempt_, n_trained_epochs-early_patience, lr) \n",
    "    early_stopping.path = saveModelName\n",
    "    early_stopping(np.average(val_loss), model)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d7f223",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c43404bb1430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trained_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_avg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trained_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_avg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Curve (lr={})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2838\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2839\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2840\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2841\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (4,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, n_trained_epochs+1), train_avg_loss, label=\"train loss\")\n",
    "plt.plot(range(1, n_trained_epochs+1), val_avg_loss, label=\"val loss\")\n",
    "plt.title(\"Training Curve (lr={})\".format(lr))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, n_trained_epochs+1), train_avg_acc, label=\"train acc\")\n",
    "plt.plot(range(1, n_trained_epochs+1), val_avg_acc, label=\"val acc\")\n",
    "plt.title(\"Training Curve (lr={})\".format(lr))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Train/val Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ed8db3",
   "metadata": {},
   "source": [
    "## Evaluation on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ test eval metrics ######################\n",
    "test_true_labels = []\n",
    "test_predict_labels = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "test_prec = []\n",
    "test_rec = []\n",
    "test_f1 = []\n",
    "\n",
    "########################################################\n",
    "for batch in tqdm(test_loader):\n",
    "    batch = tuple(batch[t].to(device) for t in batch)      # batch to GPU\n",
    "    t_input_ids, t_input_mask, t_token_type_ids, t_labels, t_bio_tags = batch     # unpack inputs from dataloader\n",
    "\n",
    "\n",
    "    # crf in model requires to start with a positive mask label => ignore first token [CLS]\n",
    "    t_mask_tags_without_CLS = torch.cat([t_bio_tags[i][1:] != -100 for i in range(len(t_bio_tags))]).view(t_bio_tags.shape[0],-1).byte() # byte() casts boolean tensor to tensor with 1 and 0         \n",
    "    t_bio_tags_without_CLS = torch.cat([t_bio_tags[i][1:] for i in range(len(t_bio_tags))]).view(t_bio_tags.shape[0],-1)\n",
    "\n",
    "    with torch.no_grad(): # tell model not to compute or store gradients -> saves memory + speeds up validation\n",
    "        model.eval() # put model in evaluation mode for validation set\n",
    "        #logits = model(**{\"input_ids\":v_input_ids, \"attention_mask\":v_input_mask, \"token_type_ids\":v_token_type_ids}) # forward pass, calculates logit predictions\n",
    "        log_likelihood, sequence_of_tags = model(**{\"input_ids\":t_input_ids\n",
    "                                                , \"attention_mask\":t_input_mask\n",
    "                                                , \"token_type_ids\":t_token_type_ids\n",
    "                                                , \"tags\": t_bio_tags\n",
    "                                                , \"mask_tags_without_CLS\":t_mask_tags_without_CLS}) # forward pass, calculates logit predictions\n",
    "\n",
    "    ######################################################\n",
    "\n",
    "    t_loss = -1 * log_likelihood            \n",
    "    test_loss.append(t_loss.item())\n",
    "\n",
    "    #########################################################\n",
    "\n",
    "    # calculate performance measures only on tokens and not subwords or special tokens                        \n",
    "    t_bio_tags_without_CLS = t_bio_tags_without_CLS.detach().to(\"cpu\").numpy()\n",
    "    t_mask_tags_without_CLS = t_mask_tags_without_CLS.detach().to(\"cpu\").numpy()\n",
    "\n",
    "    true_tags = t_bio_tags_without_CLS[t_mask_tags_without_CLS.astype(bool)] # get Bio tags for tokens only\n",
    "    pred = [item for elem in sequence_of_tags for item in elem] # flatten list of lists\n",
    "\n",
    "    test_true_labels.append(true_tags) # appends true labels for batch\n",
    "    test_predict_labels.append(pred) # # appends predicted labels for batch\n",
    "    \n",
    "    metrics = compute_metrics(pred, true_tags)\n",
    "    test_acc.append(metrics[\"accuracy\"])\n",
    "    test_prec.append(metrics[\"precision\"])\n",
    "    test_rec.append(metrics[\"recall\"])\n",
    "    test_f1.append(metrics[\"f1\"])\n",
    "\n",
    "\n",
    "print(F'\\n\\tTest Loss: {np.mean(test_loss)}')\n",
    "print(F'\\n\\tTest acc: {np.mean(test_acc)}')\n",
    "print(F'\\n\\tTest prec: {np.mean(test_prec)}')\n",
    "print(F'\\n\\tTest rec: {np.mean(test_rec)}')\n",
    "print(F'\\n\\tTest f1: {np.mean(test_f1)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c87f4",
   "metadata": {},
   "source": [
    "### Classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_true_tag = [id2tag[ID] for ID in np.concatenate(test_true_labels)]#\n",
    "test_predict_tag = [id2tag[ID] for ID in np.concatenate(test_predict_labels)]\n",
    "print(classification_report(test_true_tag, test_predict_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The metrics we are seeing in this report are designed specifically for NLP tasks such as NER and POS tagging,\n",
    "#in which all words of an entity need to be predicted correctly to be counted as one correct prediction. \n",
    "#Therefore, the metrics in this classification report are much lower than in scikit-learn's classification report.\n",
    "test_true_tag = [[id2tag[ID] for ID in IDS] for IDS in test_true_labels]\n",
    "test_predict_tag = [[id2tag[ID] for ID in IDS] for IDS in test_predict_labels]\n",
    "print(classification_report_seqeval(test_true_tag, test_predict_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4170320",
   "metadata": {},
   "source": [
    "### Example: see predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take last batch of test set:\n",
    "t_input_ids, t_input_mask, t_token_type_ids, t_labels, t_bio_tags = batch \n",
    "\n",
    "for i in range(len(batch)):\n",
    "    tags_mask = t_bio_tags[i].to(\"cpu\").numpy() != -100 # only get token labels and not labels from subwords or special tokens\n",
    "    pred = np.argmax(logits[i], axis=1)[tags_mask]\n",
    "    true_tags = t_bio_tags[i][tags_mask].to(\"cpu\").numpy()    \n",
    "    \n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(t_input_ids[i])\n",
    "\n",
    "    print(\"\\n\\nPadded Sentence:\")\n",
    "    print(tokens)\n",
    "    print(\"true labels:\")\n",
    "    print(t_bio_tags[i], \"-> \", id2tag[t_bio_tags[i]])\n",
    "    for token, true_label, pred in zip(np.array(tokens)[tags_mask], true_tags, pred):\n",
    "        print(token, \"\\t\\ttrue:\", true_label, \"  pred:\", pred)\n",
    "\n",
    "    \n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2e2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
