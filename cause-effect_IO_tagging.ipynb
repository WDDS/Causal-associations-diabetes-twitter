{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25788515",
   "metadata": {},
   "source": [
    "## A model build using TweetBERT to identify cause-effect pairs in sentences of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75586b5c",
   "metadata": {},
   "source": [
    "The cause-effect pair sentence prediction model will be trained on the dataset which got augmented in an active learning approach in 5 steps.\n",
    "\n",
    "Load already preprocessed file with sentence containing either cause or effect or both. Sentences labeled as Jokes, questions or having negations are removed.\n",
    "\n",
    "IO tagging is used instead of BIO tagging. The assumption is that the attention mechanism already encodes information about the postion (B-.). In consequence the training should be simplified with only 3 classes: I-C, I-E, O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689f9f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from seqeval.metrics import classification_report as classification_report_seqeval\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from tqdm import tqdm, trange\n",
    "from utils import normalizeTweet, split_into_sentences, bio_tagging, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "%matplotlib inline\n",
    "\n",
    "########################### Check if cuda available ############################\n",
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "########################### DATA FILE ###################################\n",
    "dataPath = \"data/cause_effect_sentences_with_IO_tags.csv\"\n",
    "#dataPath = \"data/Causality_tweets_data.xlsx\"\n",
    "#dataPath = \"Causality_tweets_data.xlsx\"\n",
    "\n",
    "\n",
    "########################### MODEL PARAMETERS ############################\n",
    "lr = 1e-5 # earlier 1e-3    \n",
    "adam_eps = 1e-8\n",
    "epochs = 55\n",
    "num_warmup_steps = 0\n",
    "early_patience = 10 # earlier 5, how long to wait after last time validation loss improved\n",
    "\n",
    "train_batch_size = 1#8\n",
    "val_batch_size = 8\n",
    "test_batch_size = 8\n",
    "train_to_test_ratio = 0.9 # 10% test and 90% train\n",
    "val_to_train_ratio = 0.2\n",
    "type_ = \"cause-or-effect\"\n",
    "attempt_ = \"test\"\n",
    "\n",
    "n_labels = 3 # 0, I-C, I-E\n",
    "tag2id = {label: idx for idx, label in enumerate([\"O\", \"I-C\", \"I-E\"])}\n",
    "tag2id[-100] = -100\n",
    "id2tag = {id:tag for tag,id in tag2id.items()}\n",
    "\n",
    "# if True, only sentences containing both cause and effect are considered.\n",
    "# if False, all sentences containing either cause or effect are considered\n",
    "requireCauseAndEffect = True \n",
    "\n",
    "# Each token has its associated IO tag (\"O\", \"I-C\", \"I-E\").\n",
    "# The Bertweet tokenizer splits words into sub-words\n",
    "# if True => assign IO tag of word to all sub-words\n",
    "# if False => assign IO tag of word to first sub-word and all other sub-words get -100 (loss function ignores this index)\n",
    "subwordTagEqualFirstwordTag = False \n",
    "\n",
    "metric_choice = \"weighted\" # micro, macro, samples or weighted \n",
    "# metrics_average = \"binary\" # this will give measure for class_1,i.e., causal class\n",
    "\n",
    "# saveModelName = \"./model-causal-span/cause-and-effect_model_1_finetuned-{}-epochs-lr_{}.pth\".format(epochs, lr) # it should be epoch so that the name shows at what epoch teh mdel ws saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c3521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Causal association</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER Additionally the medicines are being char...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medicines are being charged at MRP</td>\n",
       "      <td>costing much higher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, Additionally, the, medicines, are, bein...</td>\n",
       "      <td>[O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hear \" I hate being a diabetic \" .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diabetic</td>\n",
       "      <td>hate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[I, hear, \", I, hate, being, a, diabetic, \", .]</td>\n",
       "      <td>[O, O, O, O, I-E, O, O, I-C, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got lime for my glucose test , was n't that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glucose test</td>\n",
       "      <td>nauseous</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, got, lime, for, my, glucose, test, ,, was,...</td>\n",
       "      <td>[O, O, O, O, O, I-C, I-C, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sounds like Willow 's blood sugar level is rea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blood sugar level is real low</td>\n",
       "      <td>reduce her insulin shots</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sounds, like, Willow, 's, blood, sugar, level...</td>\n",
       "      <td>[O, O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER I 've always found it too sweet mustvsay ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaded diabetes</td>\n",
       "      <td>sauces are used sparingly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, I, 've, always, found, it, too, sweet, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, I-E, I-E,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Intent  \\\n",
       "0  USER Additionally the medicines are being char...    NaN   \n",
       "1               I hear \" I hate being a diabetic \" .    NaN   \n",
       "2  i got lime for my glucose test , was n't that ...    NaN   \n",
       "3  Sounds like Willow 's blood sugar level is rea...    NaN   \n",
       "4  USER I 've always found it too sweet mustvsay ...    NaN   \n",
       "\n",
       "                                Cause                     Effect  \\\n",
       "0  medicines are being charged at MRP        costing much higher   \n",
       "1                            diabetic                       hate   \n",
       "2                        glucose test                   nauseous   \n",
       "3       blood sugar level is real low   reduce her insulin shots   \n",
       "4                    dreaded diabetes  sauces are used sparingly   \n",
       "\n",
       "   Causal association                                          tokenized  \\\n",
       "0                 1.0  [USER, Additionally, the, medicines, are, bein...   \n",
       "1                 1.0    [I, hear, \", I, hate, being, a, diabetic, \", .]   \n",
       "2                 1.0  [i, got, lime, for, my, glucose, test, ,, was,...   \n",
       "3                 1.0  [Sounds, like, Willow, 's, blood, sugar, level...   \n",
       "4                 1.0  [USER, I, 've, always, found, it, too, sweet, ...   \n",
       "\n",
       "                                            bio_tags  \n",
       "0  [O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, O, ...  \n",
       "1                 [O, O, O, O, I-E, O, O, I-C, O, O]  \n",
       "2  [O, O, O, O, O, I-C, I-C, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, I-E, I-E,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### DATA TO LOAD ######\n",
    "\n",
    "data = pd.read_csv(dataPath, sep=\";\", converters={\"tokenized\":literal_eval, \"bio_tags\":literal_eval})\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bbaef",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec45cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2118, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Cause</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Causal association</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER Additionally the medicines are being char...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medicines are being charged at MRP</td>\n",
       "      <td>costing much higher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, Additionally, the, medicines, are, bein...</td>\n",
       "      <td>[O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hear \" I hate being a diabetic \" .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>diabetic</td>\n",
       "      <td>hate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[I, hear, \", I, hate, being, a, diabetic, \", .]</td>\n",
       "      <td>[O, O, O, O, I-E, O, O, I-C, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got lime for my glucose test , was n't that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glucose test</td>\n",
       "      <td>nauseous</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, got, lime, for, my, glucose, test, ,, was,...</td>\n",
       "      <td>[O, O, O, O, O, I-C, I-C, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sounds like Willow 's blood sugar level is rea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blood sugar level is real low</td>\n",
       "      <td>reduce her insulin shots</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sounds, like, Willow, 's, blood, sugar, level...</td>\n",
       "      <td>[O, O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER I 've always found it too sweet mustvsay ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dreaded diabetes</td>\n",
       "      <td>sauces are used sparingly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[USER, I, 've, always, found, it, too, sweet, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, I-E, I-E,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Intent  \\\n",
       "0  USER Additionally the medicines are being char...    NaN   \n",
       "1               I hear \" I hate being a diabetic \" .    NaN   \n",
       "2  i got lime for my glucose test , was n't that ...    NaN   \n",
       "3  Sounds like Willow 's blood sugar level is rea...    NaN   \n",
       "4  USER I 've always found it too sweet mustvsay ...    NaN   \n",
       "\n",
       "                                Cause                     Effect  \\\n",
       "0  medicines are being charged at MRP        costing much higher   \n",
       "1                            diabetic                       hate   \n",
       "2                        glucose test                   nauseous   \n",
       "3       blood sugar level is real low   reduce her insulin shots   \n",
       "4                    dreaded diabetes  sauces are used sparingly   \n",
       "\n",
       "   Causal association                                          tokenized  \\\n",
       "0                 1.0  [USER, Additionally, the, medicines, are, bein...   \n",
       "1                 1.0    [I, hear, \", I, hate, being, a, diabetic, \", .]   \n",
       "2                 1.0  [i, got, lime, for, my, glucose, test, ,, was,...   \n",
       "3                 1.0  [Sounds, like, Willow, 's, blood, sugar, level...   \n",
       "4                 1.0  [USER, I, 've, always, found, it, too, sweet, ...   \n",
       "\n",
       "                                            bio_tags  \n",
       "0  [O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, O, ...  \n",
       "1                 [O, O, O, O, I-E, O, O, I-C, O, O]  \n",
       "2  [O, O, O, O, O, I-C, I-C, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, I-C, I-C, I-C, I-C, I-C, I-C, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, I-E, I-E,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Choose only sentences with both cause and effect or only sentences with either cause or effect (or both) #######\n",
    "\n",
    "\n",
    "if requireCauseAndEffect: # cause and effect in sentence\n",
    "    dataSentFiltered = data[(data[\"Cause\"].notnull()) & (data[\"Effect\"].notnull())]\n",
    "else: # cause or effect or both in sentence\n",
    "    dataSentFiltered = data[(data[\"Cause\"].notnull()) | (data[\"Effect\"].notnull())]\n",
    "\n",
    "print(dataSentFiltered.shape)\n",
    "dataSentFiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2739c3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([137., 494., 672., 402., 179., 115.,  79.,  30.,   9.,   1.]),\n",
       " array([ 3. , 10.2, 17.4, 24.6, 31.8, 39. , 46.2, 53.4, 60.6, 67.8, 75. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## Distribution of sentences length ########################\n",
    "\n",
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in dataSentFiltered[\"sentence\"]]\n",
    "plt.hist(seq_len)\n",
    "#pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a7b2d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f806e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (72, 7)\n",
      "Validate: (18, 7)\n",
      "Test: (10, 7)\n"
     ]
    }
   ],
   "source": [
    "trainingDataSample = dataSentFiltered #.sample(n=100)   # Only for testing\n",
    "train = trainingDataSample.sample(frac=train_to_test_ratio, random_state=0)\n",
    "test = trainingDataSample.drop(train.index)\n",
    "validate = train.sample(frac=val_to_train_ratio, random_state=0)\n",
    "train = train.drop(validate.index)\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Validate:\", validate.shape)\n",
    "print(\"Test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cdc4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<ipython-input-7-6ea249dd8a91>:18: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(ids[idx]) == len(bio_tags_extended), \"token ids and IO tags lengths do not match!\")\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "18\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "######### BERTWEET TOKENIZER + PYTORCH DATASET/DATALOADER STRUCTURE ##################\n",
    "\n",
    "class TweetDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, labels, bio_tags, tokenizer):\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bio_tags = bio_tags\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.text, padding=True, truncation=True, return_token_type_ids=True)\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        bio_tags_extended = self.extend_tags(self.text[idx], self.bio_tags[idx], ids[idx])\n",
    "        \n",
    "        assert(len(ids[idx]) == len(bio_tags_extended), \"token ids and IO tags lengths do not match!\")\n",
    "        return {\n",
    "                \"input_ids\" : torch.tensor(ids[idx], dtype=torch.long)\n",
    "              , \"attention_mask\" : torch.tensor(mask[idx], dtype=torch.long)\n",
    "              , \"token_type_ids\" : torch.tensor(token_type_ids[idx], dtype=torch.long)\n",
    "              , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "              , \"bio_tags\" : torch.tensor(list(map(lambda bioTags: tag2id[bioTags], bio_tags_extended))\n",
    ", dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    def extend_tags(self, tokens_old, tags_old, ids_tokenized_padded):\n",
    "        \"\"\" \n",
    "            Each token has a IO tag label. \n",
    "            However BERT's tokenization splits tokens into subwords. How to label those subwords?\n",
    "            \n",
    "            Option 1:\n",
    "            ---------\n",
    "            \n",
    "            add the same label to each subword than the first subword\n",
    "            Ex. \n",
    "            #lowbloodsugar => '#low@@', 'blood@@', 'sugar@@'\n",
    "               \"I-C\"       =>   \"I-C\" ,   \"I-C\"  ,   \"I-C\"\n",
    "            \n",
    "            Option 2:      \n",
    "            ---------\n",
    "            \n",
    "            From : https://huggingface.co/transformers/custom_datasets.html#token-classification-with-w-nut-emerging-entities\n",
    "            A common obstacle with using pre-trained models for token-level classification: many of the tokens in\n",
    "            the W-NUT corpus are not in DistilBertâ€™s vocabulary. Bert and many models like it use a method called \n",
    "            WordPiece Tokenization, meaning that single words are split into multiple tokens such that each token\n",
    "            is likely to be in the vocabulary. For example, DistilBertâ€™s tokenizer would split the Twitter \n",
    "            handle @huggingface into the tokens ['@', 'hugging', '##face']. This is a problem for us because we \n",
    "            have exactly one tag per token. If the tokenizer splits a token into multiple sub-tokens, then we will\n",
    "            end up with a mismatch between our tokens and our labels.\n",
    "\n",
    "            One way to handle this is to only train on the tag labels for the first subtoken of a split token. \n",
    "            We can do this in ðŸ¤— Transformers by setting the labels we wish to ignore to -100. \n",
    "            In the example above, if the label for @HuggingFace is 3 (indexing B-corporation), we would set \n",
    "            the labels of ['@', 'hugging', '##face'] to [3, -100, -100].\n",
    "        \"\"\"\n",
    "        tags = [-100] # add for start token <CLS>\n",
    "        for token_old, tag in zip(tokens_old.split(\" \"), tags_old):\n",
    "            #print(F\"\\ntoken_old: {token_old};    tag: {tag}\")\n",
    "            for i, sub_token in enumerate(self.tokenizer.tokenize(token_old)):\n",
    "                if (i == 0): # first sub token of a word keeps the original bio tag\n",
    "                    firstTag = tag\n",
    "                    tags.append(tag)\n",
    "                    #print(F\"\\tsubToken: {sub_token};    tag: {tag}\")\n",
    "                else: \n",
    "                    if subwordTagEqualFirstwordTag: # the other sub tokens get the first bio tag than the first sub token\n",
    "                        tags.append(firstTag)\n",
    "                        #print(F\"\\tsubToken: {sub_token};    tag: {firstTag}\")\n",
    "                    else: # to other sub tokens get the tag -100 (ignored in loss function)\n",
    "                        tags.append(-100)\n",
    "                        #print(F\"\\tsubToken: {sub_token};    tag: {-100}\")\n",
    "\n",
    "        tags.append(-100) # 0 for end of sentence token\n",
    "    \n",
    "        # append -100 for all padded elements\n",
    "        padded_elements = ids_tokenized_padded.count(1) # id 1 is <PAD> ; Alternative: where attention_mask == 0 add -100\n",
    "        tags.extend([-100]*padded_elements)\n",
    "        \n",
    "        return tags\n",
    "        \n",
    "        \n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", padding = \"max_length\", truncation = True, max_length = 60 )\n",
    "\n",
    "train_dataset = TweetDataSet(train[\"sentence\"].values.tolist()\n",
    "                           , train[\"Causal association\"].values.tolist()\n",
    "                           , train[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "val_dataset = TweetDataSet(validate[\"sentence\"].values.tolist()\n",
    "                           , validate[\"Causal association\"].values.tolist()\n",
    "                           , validate[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "test_dataset = TweetDataSet(test[\"sentence\"].values.tolist()\n",
    "                           , test[\"Causal association\"].values.tolist()\n",
    "                           , test[\"bio_tags\"].values.tolist()\n",
    "                           , tokenizer)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "# put data to batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d072dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_bio_tags: [0 0 0 ... 0 0 0]\n",
      "train_bio_tags_count_info: 0    0.834225\n",
      "1    0.087166\n",
      "2    0.078610\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.399573\n",
       "1    3.824131\n",
       "2    4.240363\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ class weights #####################\n",
    "\n",
    "# Since -100 will anyway be ignored by loss func, drop it\n",
    "train_bio_tags = np.hstack([t[\"bio_tags\"][t[\"bio_tags\"]!=-100].numpy() for t in train_dataset])\n",
    "print(\"train_bio_tags:\", train_bio_tags)\n",
    "\n",
    "train_bio_tags_count_info = (pd.Series(train_bio_tags).value_counts(normalize=True))\n",
    "print(\"train_bio_tags_count_info:\", train_bio_tags_count_info)\n",
    "\n",
    "# for class-imbalanced dataset, the class weight for a ith class\n",
    "# to be specified for balancing in the loss function is given by:\n",
    "# weight[i] = num_samples / (num_classes * num_samples[i])\n",
    "# since train_bio_tags_count_info obtained above has fraction of \n",
    "# samples for ith class, hence the corresponding weight calculation is:\n",
    "class_weight = (1/train_bio_tags_count_info)/len(train_bio_tags_count_info)\n",
    "class_weight = class_weight[sorted(class_weight.index)]\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d48a7",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afbc15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, labels):\n",
    "    \"\"\"\n",
    "        Dataset is unbalanced -> measure weighted metrics\n",
    "        Calculate metrics for each label, and find their average wieghted by support (Number of true instances for each label)\n",
    "        This alters 'macro' to account for label imbalance;\n",
    "        it can result in an F-Score taht is not between precision and recall\n",
    "    \"\"\"\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average= metric_choice) # TODO: check weightin\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c6df4",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c83b3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalNER(torch.nn.Module):\n",
    "    \"\"\" Model Bert\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CausalNER, self).__init__()\n",
    "        self.bert = transformers.AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        #self.bert = transformers.BertModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear1 = torch.nn.Linear(768, 256)\n",
    "        self.linear2 = torch.nn.Linear(256, n_labels)\n",
    "        self.softmax = torch.nn.Softmax(-1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "#        _, output_1 = self.bert(input_ids, attention_mask = attention_mask, token_type_ids=token_type_ids, return_dict=False) # if output 1 is our cls token\n",
    "        output_seq, _ = self.bert(input_ids, attention_mask = attention_mask, token_type_ids=token_type_ids, return_dict=False) # if output 1 is our cls token\n",
    "        output_2 = self.dropout(output_seq)\n",
    "        output_3 = self.linear1(output_2)\n",
    "        output_4 = self.dropout(output_3)\n",
    "        output_5 = self.linear2(output_4)\n",
    "        return output_5 # 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feeaf062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing BertModel: ['roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.dense.weight', 'lm_head.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.pooler.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['embeddings.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'pooler.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CausalNER()\n",
    "model.to(device)\n",
    "\n",
    "# fine-tune only the task-specific parameters \n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "#     param[:-1].requires_grad = False\n",
    "#     param[-1].requires_grad = True\n",
    "\n",
    "num_training_steps = np.ceil(len(train_dataset)/train_batch_size)*epochs\n",
    "optim = AdamW(model.parameters(), lr=lr, eps=adam_eps)\n",
    "# scheduler with a linearly decreasing learning rate from the initial lr set in the optimizer to 0;\n",
    "# after a warmup period during which it increases linearly from to the initial lr set in the optimizer\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps) \n",
    "\n",
    "\n",
    "## adding weight to the loss function \n",
    "loss_fn = CrossEntropyLoss(\n",
    "    weight=torch.tensor(class_weight.to_list()).to(device),\n",
    "    ignore_index=-100 # ignore subwords/tokens with label -100 \n",
    ")\n",
    "\n",
    "#loss_fn = CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d5ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/55 [00:00<?, ?it/s]\n",
      "  0%|          | 0/72 [00:00<?, ?it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  1%|â–         | 1/72 [00:00<00:12,  5.90it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<====================== Epoch 1 ======================>\n",
      "loss: tensor(1.1941, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|â–Ž         | 2/72 [00:00<00:10,  6.46it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "  4%|â–         | 3/72 [00:00<00:10,  6.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1161, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.2217, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "  6%|â–Œ         | 4/72 [00:00<00:10,  6.62it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "  7%|â–‹         | 5/72 [00:00<00:09,  6.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.4239, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.1744, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "  8%|â–Š         | 6/72 [00:00<00:09,  6.85it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1085, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|â–‰         | 7/72 [00:01<00:10,  6.05it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 11%|â–ˆ         | 8/72 [00:01<00:10,  5.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.0309, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.2900, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 12%|â–ˆâ–Ž        | 9/72 [00:01<00:10,  5.96it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.2047, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.0913, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|â–ˆâ–        | 10/72 [00:01<00:10,  5.69it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 15%|â–ˆâ–Œ        | 11/72 [00:01<00:11,  5.22it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 17%|â–ˆâ–‹        | 12/72 [00:02<00:10,  5.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.2400, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.1452, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 18%|â–ˆâ–Š        | 13/72 [00:02<00:10,  5.69it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9079, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|â–ˆâ–‰        | 14/72 [00:02<00:10,  5.35it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1835, grad_fn=<NllLossBackward>)\n",
      "loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|â–ˆâ–ˆ        | 15/72 [00:02<00:10,  5.23it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 22%|â–ˆâ–ˆâ–       | 16/72 [00:02<00:10,  5.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1095, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.0460, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 24%|â–ˆâ–ˆâ–Ž       | 17/72 [00:02<00:09,  5.74it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 18/72 [00:03<00:08,  6.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1047, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.5066, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 26%|â–ˆâ–ˆâ–‹       | 19/72 [00:03<00:08,  6.16it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9979, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|â–ˆâ–ˆâ–Š       | 20/72 [00:03<00:10,  4.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1667, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 29%|â–ˆâ–ˆâ–‰       | 21/72 [00:03<00:13,  3.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.8485, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 22/72 [00:04<00:14,  3.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.0840, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 23/72 [00:04<00:17,  2.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1234, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24/72 [00:05<00:19,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.4776, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 25/72 [00:05<00:16,  2.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1657, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/72 [00:05<00:15,  2.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1766, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 27/72 [00:06<00:14,  3.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.4185, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 28/72 [00:06<00:13,  3.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.2346, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 29/72 [00:06<00:12,  3.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1771, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/72 [00:06<00:10,  3.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.2205, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 31/72 [00:07<00:10,  4.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9197, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/72 [00:07<00:09,  4.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.3444, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/72 [00:07<00:09,  3.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.0988, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/72 [00:07<00:09,  3.95it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/72 [00:07<00:08,  4.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(0.9318, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 36/72 [00:08<00:07,  4.82it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/72 [00:08<00:06,  5.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.4417, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.1913, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 38/72 [00:08<00:06,  5.42it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/72 [00:08<00:05,  5.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1102, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.3710, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 40/72 [00:08<00:05,  5.60it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 41/72 [00:08<00:05,  5.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.0687, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.0074, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/72 [00:09<00:04,  6.09it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/72 [00:09<00:04,  6.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9283, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.0565, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/72 [00:09<00:04,  5.60it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 45/72 [00:09<00:04,  5.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1142, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.0565, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/72 [00:09<00:04,  5.89it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 47/72 [00:09<00:04,  6.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9814, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.2471, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 48/72 [00:10<00:03,  6.22it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "/home/adrian/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 49/72 [00:10<00:03,  6.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1417, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.2633, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 50/72 [00:10<00:03,  6.01it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 51/72 [00:10<00:03,  5.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1227, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.3908, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 52/72 [00:10<00:03,  5.55it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 53/72 [00:10<00:03,  5.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9541, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.2205, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 54/72 [00:11<00:03,  5.73it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 55/72 [00:11<00:02,  5.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.0758, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.0654, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 56/72 [00:11<00:02,  5.76it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 57/72 [00:11<00:02,  5.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9403, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.2058, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 58/72 [00:11<00:02,  6.01it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 59/72 [00:11<00:02,  6.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.2501, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.0411, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 60/72 [00:12<00:01,  6.32it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/72 [00:12<00:01,  6.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.0965, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.3354, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 62/72 [00:12<00:01,  6.09it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1958, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 63/72 [00:12<00:01,  5.63it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 64/72 [00:12<00:01,  5.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1670, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.3580, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 65/72 [00:13<00:01,  5.54it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 66/72 [00:13<00:01,  5.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1361, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.1523, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 67/72 [00:13<00:00,  5.66it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/72 [00:13<00:00,  5.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.2596, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(0.9114, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 69/72 [00:13<00:00,  5.40it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 70/72 [00:13<00:00,  5.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.3501, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.5052, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 71/72 [00:14<00:00,  5.26it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:14<00:00,  5.03it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.4295, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.0455, grad_fn=<NllLossBackward>)\n",
      "\n",
      "\tTraining Loss: 1.1635427085889711\n",
      "\n",
      "\tTraining acc: 0.4694996112886941\n",
      "\n",
      "\tTraining prec: 0.6925991863677567\n",
      "\n",
      "\tTraining rec: 0.4694996112886941\n",
      "\n",
      "\tTraining f1: 0.538056296069829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.44it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.47it/s]\u001b[A<ipython-input-7-6ea249dd8a91>:23: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  , \"labels\" : torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.90it/s]\u001b[A\n",
      "Epoch:   0%|          | 0/55 [00:15<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tValidation Loss: 1.1065971453984578\n",
      "\n",
      "\tValidation acc: 0.5769634436992496\n",
      "\n",
      "\tValidation prec: 0.6768672476701793\n",
      "\n",
      "\tValidation rec: 0.5769634436992496\n",
      "\n",
      "\tValidation f1: 0.6113702241342978\n",
      "Validation loss decreased (inf --> 1.106597).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model-causal-span/cause-or-effect_model_test_finetuned--9-epochs-lr_1e-05.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e44aa633a81f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0msaveModelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./model-causal-span/{}_model_{}_finetuned-{}-epochs-lr_{}.pth\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trained_epochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mearly_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mearly_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveModelName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mearly_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/causality/Causal-associations-diabetes-twitter/utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, val_loss, model)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/causality/Causal-associations-diabetes-twitter/utils.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, val_loss, model)\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model-causal-span/cause-or-effect_model_test_finetuned--9-epochs-lr_1e-05.pth'"
     ]
    }
   ],
   "source": [
    "################ TRAINING ######################\n",
    "\n",
    "# initialise the early_stopping object\n",
    "early_stopping = EarlyStopping(patience=early_patience, verbose=True)\n",
    "\n",
    "train_avg_loss = [] # avg training loss per epoch\n",
    "val_avg_loss = [] # avg validation loss per epoch\n",
    "train_avg_acc = [] # avg training accuracy per epoch\n",
    "val_avg_acc = [] # avg val accuracy per epoch\n",
    "n_trained_epochs = 0\n",
    "\n",
    "for epoch in trange(1, epochs+1, desc='Epoch'):\n",
    "    print(\"<\" + \"=\"*22 + F\" Epoch {epoch} \"+ \"=\"*22 + \">\")\n",
    "\n",
    "    \n",
    "    ############ training eval metrics ######################\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    train_prec = []\n",
    "    train_rec = []\n",
    "    train_f1 = []\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad() # gradients get accumulated by default -> clear previous accumulated gradients\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        bio_tags = batch['bio_tags'].to(device)\n",
    "        \n",
    "        ################################################\n",
    "        model.train() # set model to training mode\n",
    "        logits = model(**{\"input_ids\":input_ids, \"attention_mask\":attention_mask, \"token_type_ids\":token_type_ids}) # forward pass\n",
    "\n",
    "        ################################################ \n",
    "        # similar to the class RobertaForToken classification in transformers: https://github.com/huggingface/transformers/blob/master/src/transformers/models/roberta/modeling_roberta.py\n",
    "        active_loss = attention_mask.view(-1) == 1  # either based on attention_mask (includes <CLS>, <SEP> token)\n",
    "        active_logits = logits.view(-1, n_labels)[active_loss] # n_labels=53\n",
    "        active_tags = bio_tags.view(-1)[active_loss]\n",
    "        loss = loss_fn(active_logits, active_tags)             \n",
    "        print(\"loss:\", loss)       ## TODO VIVEK: check loss function calculation\n",
    "        loss.backward() # backward pass\n",
    "        ## gradient clipping to control the exploding gradient problem \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optim.step()    # update parameters and take a steup using the computed gradient\n",
    "        scheduler.step()# update learning rate scheduler\n",
    "        train_loss.append(loss.item())\n",
    "            \n",
    "            \n",
    "        ################## Training Performance Measures ##########\n",
    "        logits = logits.detach().to('cpu').numpy()\n",
    "        tags_ids = bio_tags.to('cpu').numpy()\n",
    "\n",
    "        # calculate performance measures only on tokens and not subwords or special tokens\n",
    "        tags_mask = tags_ids != -100 # only get token labels and not labels from subwords or special tokens\n",
    "        pred = np.argmax(logits, axis=2)[tags_mask] #.flatten() # convert logits to list of predicted labels\n",
    "        tags = tags_ids[tags_mask]                      \n",
    "                \n",
    "        metrics = compute_metrics(pred, tags)\n",
    "        train_acc.append(metrics[\"accuracy\"])\n",
    "        train_prec.append(metrics[\"precision\"])\n",
    "        train_rec.append(metrics[\"recall\"])\n",
    "        train_f1.append(metrics[\"f1\"])\n",
    "                          \n",
    "    train_avg_loss.append(np.mean(train_loss))\n",
    "    train_avg_acc.append(np.mean(train_acc))           \n",
    "    print(F'\\n\\tTraining Loss: {np.mean(train_loss)}')\n",
    "    print(F'\\n\\tTraining acc: {np.mean(train_acc)}')\n",
    "    print(F'\\n\\tTraining prec: {np.mean(train_prec)}')\n",
    "    print(F'\\n\\tTraining rec: {np.mean(train_rec)}')\n",
    "    print(F'\\n\\tTraining f1: {np.mean(train_f1)}')\n",
    "\n",
    "    n_trained_epochs += 1\n",
    "\n",
    "                          \n",
    "    ###################################################################################\n",
    "\n",
    "    \n",
    "    ## ---- Validation ------    \n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    val_prec = []\n",
    "    val_rec = []\n",
    "    val_f1 = []\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in tqdm(validation_loader):\n",
    "        batch = tuple(batch[t].to(device) for t in batch)      # batch to GPU\n",
    "        v_input_ids, v_input_mask, v_token_type_ids, v_labels, v_bio_tags = batch  # unpack inputs from dataloader\n",
    "        \n",
    "        with torch.no_grad(): # tell model not to compute or store gradients -> saves memory + speeds up validation\n",
    "            model.eval() # put model in evaluation mode for validation set\n",
    "            logits = model(**{\"input_ids\":v_input_ids, \"attention_mask\":v_input_mask, \"token_type_ids\":v_token_type_ids}) # forward pass, calculates logit predictions\n",
    "\n",
    "        ######################################################\n",
    "        \n",
    "        # similar to the class RobertaForToken classification in transformers: https://github.com/huggingface/transformers/blob/master/src/transformers/models/roberta/modeling_roberta.py\n",
    "        v_active_loss = v_input_mask.view(-1) == 1  # either based on attention_mask (includes <CLS>, <SEP> token)\n",
    "        v_active_logits = logits.view(-1, n_labels)[v_active_loss] # n_labels=3 \n",
    "        v_active_tags = v_bio_tags.view(-1)[v_active_loss]\n",
    "        v_loss = loss_fn(v_active_logits, v_active_tags)             \n",
    "        val_loss.append(v_loss.item())\n",
    "              \n",
    "        #########################################################\n",
    "        logits = logits.detach().to('cpu').numpy()\n",
    "        tags_ids = v_bio_tags.to('cpu').numpy()\n",
    "\n",
    "        # calculate performance measures only on tokens and not subwords or special tokens\n",
    "        tags_mask = tags_ids != -100 # only get token labels and not labels from subwords or special tokens\n",
    "        pred = np.argmax(logits, axis=2)[tags_mask] #.flatten() # convert logits to list of predicted labels\n",
    "        tags = tags_ids[tags_mask]#.flatten()        \n",
    "        \n",
    "        metrics = compute_metrics(pred, tags)\n",
    "        val_acc.append(metrics[\"accuracy\"])\n",
    "        val_prec.append(metrics[\"precision\"])\n",
    "        val_rec.append(metrics[\"recall\"])\n",
    "        val_f1.append(metrics[\"f1\"])\n",
    "                              \n",
    "    val_avg_loss.append(np.mean(val_loss))\n",
    "    val_avg_acc.append(np.mean(val_acc))        \n",
    "    print(F'\\n\\tValidation Loss: {np.mean(val_loss)}')\n",
    "    print(F'\\n\\tValidation acc: {np.mean(val_acc)}')\n",
    "    print(F'\\n\\tValidation prec: {np.mean(val_prec)}')\n",
    "    print(F'\\n\\tValidation rec: {np.mean(val_rec)}')\n",
    "    print(F'\\n\\tValidation f1: {np.mean(val_f1)}')\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decreased,\n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    saveModelName = \"./model-causal-span/{}_model_{}_finetuned-{}-epochs-lr_{}.pth\".format(type_, attempt_, n_trained_epochs-early_patience, lr) \n",
    "    early_stopping.path = saveModelName\n",
    "    early_stopping(np.average(val_loss), model)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8f46001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N trained epochs: 1\n",
      "[1.1464665209253628]\n",
      "[1.0927389860153198]\n"
     ]
    }
   ],
   "source": [
    "print(\"N trained epochs:\", n_trained_epochs)\n",
    "print(train_avg_loss)\n",
    "print(val_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, n_trained_epochs+1), train_avg_loss, label=\"train loss\")\n",
    "plt.plot(range(1, n_trained_epochs+1), val_avg_loss, label=\"val loss\")\n",
    "plt.title(\"Training Curve (lr={})\".format(lr))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, n_trained_epochs+1), train_avg_acc, label=\"train acc\")\n",
    "plt.plot(range(1, n_trained_epochs+1), val_avg_acc, label=\"val acc\")\n",
    "plt.title(\"Training Curve (lr={})\".format(lr))\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Train/val Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ed8db3",
   "metadata": {},
   "source": [
    "## Evaluation on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ test eval metrics ######################\n",
    "test_true_labels = []\n",
    "test_predict_labels = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "test_prec = []\n",
    "test_rec = []\n",
    "test_f1 = []\n",
    "\n",
    "########################################################\n",
    "for batch in tqdm(test_loader):\n",
    "    batch = tuple(batch[t].to(device) for t in batch)      # batch to GPU\n",
    "    t_input_ids, t_input_mask, t_token_type_ids, t_labels, t_bio_tags = batch     # unpack inputs from dataloader\n",
    "\n",
    "    with torch.no_grad(): # tell model not to compute or store gradients -> saves memory + speeds up validation\n",
    "        model.eval() # put model in evaluation mode for validation set\n",
    "        logits = model(**{\"input_ids\":t_input_ids, \"attention_mask\":t_input_mask, \"token_type_ids\":t_token_type_ids}) # forward pass, calculates logit predictions\n",
    "\n",
    "    ######################################################\n",
    "\n",
    "    # similar to the class RobertaForToken classification in transformers: https://github.com/huggingface/transformers/blob/master/src/transformers/models/roberta/modeling_roberta.py\n",
    "    t_active_loss = t_input_mask.view(-1) == 1  # either based on attention_mask (includes <CLS>, <SEP> token)\n",
    "    t_active_logits = logits.view(-1, n_labels)[t_active_loss] # n_labels=3\n",
    "    t_active_tags = t_bio_tags.view(-1)[t_active_loss]\n",
    "    t_loss = loss_fn(t_active_logits, t_active_tags)             \n",
    "    test_loss.append(t_loss.item())\n",
    "\n",
    "    #########################################################\n",
    "    logits = logits.detach().to('cpu').numpy()\n",
    "    tags_ids = t_bio_tags.to('cpu').numpy()\n",
    "\n",
    "    # calculate performance measures only on tokens and not subwords or special tokens\n",
    "    tags_mask = tags_ids != -100 # only get token labels and not labels from subwords or special tokens\n",
    "    pred = np.argmax(logits, axis=2)[tags_mask] #.flatten() # convert logits to list of predicted labels\n",
    "    tags = tags_ids[tags_mask]#.flatten()                          \n",
    "    test_true_labels.append(tags) # appends true labels for batch\n",
    "    test_predict_labels.append(pred) # # appends predicted labels for batch\n",
    "    \n",
    "    metrics = compute_metrics(pred, tags)\n",
    "    test_acc.append(metrics[\"accuracy\"])\n",
    "    test_prec.append(metrics[\"precision\"])\n",
    "    test_rec.append(metrics[\"recall\"])\n",
    "    test_f1.append(metrics[\"f1\"])\n",
    "\n",
    "\n",
    "print(F'\\n\\tTest Loss: {np.mean(test_loss)}')\n",
    "print(F'\\n\\tTest acc: {np.mean(test_acc)}')\n",
    "print(F'\\n\\tTest prec: {np.mean(test_prec)}')\n",
    "print(F'\\n\\tTest rec: {np.mean(test_rec)}')\n",
    "print(F'\\n\\tTest f1: {np.mean(test_f1)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c87f4",
   "metadata": {},
   "source": [
    "### Classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_true_tag = [id2tag[ID] for ID in np.concatenate(test_true_labels)]#\n",
    "test_predict_tag = [id2tag[ID] for ID in np.concatenate(test_predict_labels)]\n",
    "print(classification_report(test_true_tag, test_predict_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The metrics we are seeing in this report are designed specifically for NLP tasks such as NER and POS tagging,\n",
    "#in which all words of an entity need to be predicted correctly to be counted as one correct prediction. \n",
    "#Therefore, the metrics in this classification report are much lower than in scikit-learn's classification report.\n",
    "test_true_tag = [[id2tag[ID] for ID in IDS] for IDS in test_true_labels]\n",
    "test_predict_tag = [[id2tag[ID] for ID in IDS] for IDS in test_predict_labels]\n",
    "print(classification_report_seqeval(test_true_tag, test_predict_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4170320",
   "metadata": {},
   "source": [
    "### Example: see predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take last batch of test set:\n",
    "t_input_ids, t_input_mask, t_token_type_ids, t_labels, t_bio_tags = batch \n",
    "\n",
    "for i in range(len(batch)):\n",
    "    tags_mask = t_bio_tags[i].to(\"cpu\").numpy() != -100 # only get token labels and not labels from subwords or special tokens\n",
    "    pred = np.argmax(logits[i], axis=1)[tags_mask]\n",
    "    true_tags = t_bio_tags[i][tags_mask].to(\"cpu\").numpy()    \n",
    "    \n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(t_input_ids[i])\n",
    "\n",
    "    print(\"\\n\\nPadded Sentence:\")\n",
    "    print(tokens)\n",
    "    print(\"true labels:\")\n",
    "    print(t_bio_tags[i], \"-> \", id2tag[t_bio_tags[i]])\n",
    "    for token, true_label, pred in zip(np.array(tokens)[tags_mask], true_tags, pred):\n",
    "        print(token, \"\\t\\ttrue:\", true_label, \"  pred:\", pred)\n",
    "\n",
    "    \n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2e2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
